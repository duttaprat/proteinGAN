{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import json\n",
    "import fastai\n",
    "from random import randint\n",
    "from fastai.text import SortishSampler\n",
    "from fastai.basic_data import DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"../../data/protein/structure/secondary_structure/\"\n",
    "DATA_PATH = ROOT+\"cullpdb\"\n",
    "EMBEDDING_PATH = \"../../data/protein/classification/data_sources/protVec_100d_3grams.csv\"\n",
    "MODEL_PATH = \"../../weights/protein/structure/secondary_structure/1_kmers/\"\n",
    "SEQUENCE_LENGTH=729\n",
    "NUM_CLASSES = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([16, 32, 64, 128, 256])*2\n",
    "num_workers = 8 # On cloud 8\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32,  64, 128, 256, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnzymeDataSet(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data[idx]\n",
    "        return np.int64(row[0]), np.int64(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.eye(22,22)\n",
    "#embeddings = np.loadtxt(open(EMBEDDING_PATH, \"rb\"), delimiter=\"\\t\", skiprows=1, usecols=[i for i in range(1,101)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(DATA_PATH+\"/train/data.npy\")\n",
    "val = np.load(DATA_PATH+\"/val/data.npy\")\n",
    "test = np.concatenate([np.load(DATA_PATH+\"/test/data.npy\"),np.load(DATA_PATH+\"/test/data.npy\")],axis=0)\n",
    "#test = np.load(DATA_PATH+\"/test/data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([2751851,   12150,  225660,  253710,   45607,  401508,     222,   96906,  132386]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)\n",
    "np.unique(np.concatenate(train[:,1]).ravel(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SortishSampler(train, key=lambda x: len(train[x][0]), bs=batch_size//2)\n",
    "val_sampler = SortishSampler(val, key=lambda x: len(val[x][0]), bs=batch_size//2)\n",
    "test_sampler = SortishSampler(test, key=lambda x: len(test[x][0]), bs=batch_size//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(seq, label, length):\n",
    "    seq_len = len(seq)\n",
    "    to_pad = length - seq_len\n",
    "    end_padding = randint(0, to_pad)\n",
    "    begin_padding = to_pad - end_padding\n",
    "    seq = np.pad(seq, mode=\"constant\", pad_width=(begin_padding,end_padding))\n",
    "    label = np.pad(label, mode=\"constant\", pad_width=(begin_padding,end_padding))\n",
    "    return seq,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(samples, random=True):\n",
    "    \"Function that collect samples and adds padding.\"\n",
    "    max_len = max(64 ,max(map(lambda x: len(x[0]), samples)))\n",
    "    batch = list(map(lambda x: pad_tensor(x[0], x[1], max_len), samples))\n",
    "    # stack all\n",
    "    x = torch.stack([torch.from_numpy(b[0]) for b in batch], 0)\n",
    "    y = torch.stack([torch.from_numpy(b[1]) for b in batch], 0)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ds = EnzymeDataSet(train)\n",
    "val_ds = EnzymeDataSet(val)\n",
    "test_ds = EnzymeDataSet(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dls = [DataLoader(*o, num_workers=num_workers) for o in\n",
    "       zip((train_ds, val_ds, test_ds), (batch_size,batch_size*2,batch_size*2), \n",
    "           (False,False,False), (train_sampler, val_sampler, test_sampler))]\n",
    "data = DataBunch(*dls, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetDown(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, kernel_size, strides, dilation_rate=1, dropout=0.2, act=F.selu, pool=True):\n",
    "        super(UnetDown, self).__init__()\n",
    "        self.act = act\n",
    "        self.conv1 = nn.Conv1d(num_inputs, num_inputs, kernel_size, stride=1, dilation = 1)\n",
    "        self.conv2 = nn.Conv1d(num_inputs, num_inputs, kernel_size, stride=1, dilation = dilation_rate)\n",
    "        self.pool = nn.Conv1d(num_inputs, num_outputs, kernel_size, stride=strides, dilation = 1)\n",
    "        self.bn1 = nn.BatchNorm1d(num_inputs)\n",
    "        self.bn2 = nn.BatchNorm1d(num_inputs)\n",
    "        self.to_pool = pool\n",
    "        before = (kernel_size -1) // 2\n",
    "        after = (kernel_size -1) - before\n",
    "        self.padding = nn.ConstantPad1d((before,after), 0)\n",
    "        stride_padding = (strides - 1) // 2\n",
    "        self.padding_stride = nn.ConstantPad1d((before-stride_padding, after -((strides - 1)-stride_padding)), 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.padding(x))\n",
    "        before_pooling = self.act(self.bn1(out))\n",
    "#         out = self.conv2(self.padding(out))\n",
    "#         before_pooling = self.act(self.bn2(out))\n",
    "        if self.to_pool:\n",
    "            out = self.pool(self.padding_stride(before_pooling))\n",
    "            return out, before_pooling\n",
    "        else:\n",
    "            return before_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetUp(nn.Module):\n",
    "    def __init__(self,  num_inputs, num_outputs, kernel_size, strides, dilation_rate=1, dropout=0.2, act=F.relu):\n",
    "        super(UnetUp, self).__init__()\n",
    "        self.act = act\n",
    "        self.up = nn.ConvTranspose1d(num_inputs, num_outputs, kernel_size, stride=strides, dilation = 1, padding=kernel_size-1)\n",
    "        self.conv1 = nn.Conv1d(num_outputs*2, num_outputs, kernel_size, stride=1, dilation = dilation_rate)\n",
    "        self.conv2 = nn.Conv1d(num_inputs, num_outputs, kernel_size, stride=1, dilation = 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(num_outputs)\n",
    "        self.bn2 = nn.BatchNorm1d(num_outputs)\n",
    "        self.before = (kernel_size -1) // 2\n",
    "        self.after = (kernel_size -1) - self.before\n",
    "        self.padding = nn.ConstantPad1d((self.before,self.after), 0)\n",
    "        self.strides = strides\n",
    "        \n",
    "    def forward(self, x, across):  \n",
    "#         stride_padding = self.strides//2\n",
    "#         extra = 1- across.shape[2]%2\n",
    "#         self.padding_stride = nn.ConstantPad1d((self.before-(stride_padding+extra), \n",
    "#                                                   self.after -((self.strides+1)-stride_padding)), 0)\n",
    "        out = self.act(self.bn2(self.conv2((self.padding(x)))))\n",
    "#         print(x.shape, out.shape, across.shape)\n",
    "#         if out.shape[2] != across.shape[2]:\n",
    "#             out = nn.ReflectionPad1d((0, 1))(out)\n",
    "        \n",
    "        out = torch.cat([out, across], 1)\n",
    "\n",
    "        out = self.conv1(self.padding(out))\n",
    "        out = self.act(self.bn1(out))\n",
    "#         out = self.conv2(self.padding(out))\n",
    "#         out = self.act(self.bn2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        #Encoder\n",
    "        self.embedding = nn.Embedding(embeddings.shape[0], embeddings.shape[1])\n",
    "        self.embedding.from_pretrained(torch.from_numpy(embeddings)) \n",
    "        self.emb_cov = nn.Conv1d(embeddings.shape[1], features[0], 1)\n",
    "        self.unet_down1 = UnetDown(features[0], features[1], 5, 1)   \n",
    "        self.unet_down2 = UnetDown(features[1], features[2], 5, 1)  \n",
    "        self.unet_down3 = UnetDown(features[2], features[3], 7, 1)\n",
    "        self.unet_down4 = UnetDown(features[3], features[4], 9, 1)        \n",
    "        \n",
    "        self.center = UnetDown(features[3], features[3], 9, 1, pool=False)        \n",
    "        #Decoder\n",
    "        self.unet_block1 = UnetUp(features[4], features[3], 9, 1)   \n",
    "        self.unet_block2 = UnetUp(features[3], features[2], 7, 1)  \n",
    "        self.unet_block3 = UnetUp(features[2], features[1], 5, 1)\n",
    "        self.unet_block4 = UnetUp(features[1], features[0], 5, 1)\n",
    "        self.classification = nn.Conv1d(features[0], NUM_CLASSES, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded_seq = self.embedding(x)\n",
    "        embedded_seq.transpose_(1, 2)\n",
    "        embedded_seq = self.emb_cov(embedded_seq)\n",
    "        d1, before_pooling1 = self.unet_down1(embedded_seq)\n",
    "        d1 = nn.Dropout(p=0.3)(d1)\n",
    "        d2, before_pooling2 = self.unet_down2(d1)\n",
    "        d2 = nn.Dropout(p=0.4)(d2)\n",
    "        d3, before_pooling3 = self.unet_down3(d2)\n",
    "        d3 = nn.Dropout(p=0.5)(d3)\n",
    "        #d4, before_pooling4 = self.unet_down4(d3)\n",
    "        \n",
    "        c = self.center(d3)\n",
    "        \n",
    "        #u1 = self.unet_block1(c, before_pooling4)\n",
    "        c = nn.Dropout(p=0.5)(c)\n",
    "        u2 = self.unet_block2(c, before_pooling3)\n",
    "        u2 = nn.Dropout(p=0.4)(u2)\n",
    "        u3 = self.unet_block3(u2, before_pooling2) \n",
    "        u3 = nn.Dropout(p=0.3)(u3)\n",
    "        u4 = self.unet_block4(u3, before_pooling1) \n",
    "        u4 = nn.Dropout(p=0.2)(u4)\n",
    "        output = self.classification(u4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(input, targs):\n",
    "    \"Compute accuracy with `targs` when `input` is bs * n_classes.\"\n",
    "    mask = (targs > 0)\n",
    "    targs = targs.masked_select(mask)\n",
    "    input = input.argmax(dim=1)\n",
    "    input = input.masked_select(mask)\n",
    "    return (input==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unet = Unet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.1, 1, 1, 1, 1, 1, 1, 1, 1]).cuda())\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.1, 4.4, 1.2, 1.4, 3.1, 1, 8.5, 2.4, 2]).cuda())\n",
    "optimizer = optim.Adam(unet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = fastai.basic_train.Learner(data, unet, \n",
    "        loss_func=criterion, \n",
    "        metrics=accuracy, \n",
    "        path=None, \n",
    "        model_dir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:40\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.956740    1.965885    0.349779  (00:08)\n",
      "2      1.823577    1.840537    0.418104  (00:08)\n",
      "3      1.722737    1.600625    0.495742  (00:07)\n",
      "4      1.640784    1.509838    0.482521  (00:07)\n",
      "5      1.571316    1.452152    0.509797  (00:08)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 04:00\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      1.428238    1.415173    0.517290  (00:08)\n",
      "2      1.413039    1.389913    0.510252  (00:08)\n",
      "3      1.391551    1.388196    0.521880  (00:08)\n",
      "4      1.365236    1.323021    0.524024  (00:08)\n",
      "5      1.336712    1.288753    0.532218  (00:07)\n",
      "6      1.311779    1.316239    0.541456  (00:08)\n",
      "7      1.288687    1.245313    0.531118  (00:07)\n",
      "8      1.269979    1.278062    0.537757  (00:08)\n",
      "9      1.255617    1.276133    0.531080  (00:07)\n",
      "10     1.246099    1.230438    0.544965  (00:08)\n",
      "11     1.235908    1.353615    0.548986  (00:08)\n",
      "12     1.226104    1.212207    0.539483  (00:08)\n",
      "13     1.217496    1.208717    0.544699  (00:08)\n",
      "14     1.210322    1.206868    0.550807  (00:07)\n",
      "15     1.204957    1.210585    0.546596  (00:07)\n",
      "16     1.200524    1.193573    0.550579  (00:07)\n",
      "17     1.196165    1.205618    0.557598  (00:08)\n",
      "18     1.191939    1.187074    0.560500  (00:08)\n",
      "19     1.188269    1.191825    0.560140  (00:07)\n",
      "20     1.184743    1.189496    0.561695  (00:07)\n",
      "21     1.181862    1.186717    0.559779  (00:07)\n",
      "22     1.178267    1.180445    0.562378  (00:08)\n",
      "23     1.174931    1.180995    0.555473  (00:07)\n",
      "24     1.171807    1.223615    0.557712  (00:08)\n",
      "25     1.169401    1.177464    0.564540  (00:08)\n",
      "26     1.167036    1.178513    0.562473  (00:08)\n",
      "27     1.164841    1.175865    0.565337  (00:08)\n",
      "28     1.163292    1.178637    0.559798  (00:07)\n",
      "29     1.161939    1.174832    0.564009  (00:08)\n",
      "30     1.160603    1.173667    0.562643  (00:08)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, truth = learner.get_preds(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5637)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5853871591714788\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "min_element = 0\n",
    "min_score = 1\n",
    "s = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "s_t = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "total = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "for row in range(len(truth)):\n",
    "\n",
    "    a = preds.argmax(dim=1)[row]\n",
    "    correct = 0\n",
    "    actual = 0\n",
    "    for i, t in enumerate(truth[row]):\n",
    "        s[t] = s[t]+1\n",
    "        total[a[i]] = total[a[i]]+1\n",
    "        if t != 0: # and t != 1:\n",
    "            actual += 1\n",
    "            if a[i] == t:        \n",
    "                correct += 1\n",
    "                s_t[t] = s_t[t]+1\n",
    "    score = correct/actual\n",
    "    if min_score > score:\n",
    "        min_score = score\n",
    "        min_element = row\n",
    "    acc.append(score)\n",
    "\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donatas_repecka/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.      , 0.007987, 0.348927, 0.704149, 0.175282, 0.752782,      nan, 0.244321, 0.468413])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s_t)/np.array(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     |10    |7347  |17208 |807   |30444 |0     |2194  |5902  \n",
      "267428|1252  |21056 |24438 |4604  |40442 |0     |8980  |12600 \n",
      "267415|47    |13667 |30250 |4121  |39828 |0     |8813  |16659 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"|\".join([\"{0: <6}\".format(x) for x in s_t]))\n",
    "print(\"|\".join([\"{0: <6}\".format(x) for x in s]))\n",
    "print(\"|\".join([\"{0: <6}\".format(x) for x in total]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26262626262626265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([2, 2, 2, 2, 5, 5, 5, 5, 2, 8, 8, 7, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8,\n",
       "         7, 2, 4, 4, 4, 3, 3, 3, 3, 8, 8, 7, 3, 3, 2, 4, 8, 8, 7, 2, 3, 3, 3, 3,\n",
       "         3, 5, 8, 2, 3, 3, 7, 7, 2, 7, 7, 7, 8, 7, 2, 2, 2, 4, 8, 3, 3, 3, 3, 3,\n",
       "         8, 8, 7, 8, 7, 2, 3, 3, 7, 2, 8, 8, 7, 8, 8, 2, 2, 8, 8, 7, 7, 2, 3, 3,\n",
       "         3, 3, 3, 3, 3, 7, 7, 2, 8, 7, 3, 3, 2, 3, 5, 7, 2, 5, 3, 3, 8, 8, 8, 8,\n",
       "         8, 3, 3, 3, 2, 2, 8, 8, 7, 2, 1, 7, 2, 7, 7, 3, 4, 8, 3, 3, 8, 7, 7, 8,\n",
       "         8, 2, 2, 8, 8, 8, 2, 4, 8, 3, 2, 7, 8, 8, 2, 3, 3, 2, 4, 4, 4, 4, 7, 8,\n",
       "         2, 3, 3, 3, 3, 7, 2, 4, 4, 4, 8, 8, 7, 7, 7, 7, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " tensor([2, 2, 2, 2, 8, 5, 5, 5, 5, 5, 5, 7, 2, 8, 8, 2, 3, 3, 3, 3, 7, 7, 7, 7,\n",
       "         2, 7, 7, 8, 8, 3, 3, 3, 7, 1, 7, 2, 1, 2, 2, 8, 8, 8, 2, 5, 5, 5, 5, 5,\n",
       "         5, 8, 8, 8, 8, 8, 7, 1, 2, 7, 7, 7, 1, 1, 2, 2, 1, 2, 8, 8, 2, 2, 2, 2,\n",
       "         2, 7, 7, 2, 2, 5, 5, 5, 5, 2, 4, 4, 4, 7, 7, 1, 2, 8, 8, 7, 2, 1, 2, 8,\n",
       "         8, 8, 8, 2, 2, 2, 2, 7, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         7, 2, 2, 2, 7, 7, 7, 2, 2, 8, 8, 2, 2, 2, 2, 7, 7, 7, 2, 2, 2, 2, 7, 7,\n",
       "         2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 7, 7, 2, 4, 4, 4, 2, 2,\n",
       "         4, 4, 4, 2, 2, 7, 7, 8, 8, 2, 7, 7, 7, 2, 2, 2, 2, 7, 2, 2, 2, 2, 3, 3,\n",
       "         3, 3, 3, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(min_score)\n",
    "preds.argmax(dim=1)[min_element], truth[min_element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2333333244455555555555588733333337772721227333337255555555551288233333377722772233444555555555882233333333333388333337733333228872233333338872233333733333284444888444822222882233333337278822223333882233333333333338833333333333333333333332882255555555522722\n",
      "2333333332222885555333288333333333778727233333333785555555555888233333388888233372555555555555888223333333333358873333333333338887333333333338333333883333788723333333333332883333332877873333333332882333333777333338833382333333388733333322882333333355888822\n"
     ]
    }
   ],
   "source": [
    "t_s = \"\"\n",
    "p_s = \"\"\n",
    "element = 4\n",
    "p = preds.argmax(dim=1)[element]\n",
    "for i, t in enumerate(truth[element]):\n",
    "    if t != 0:\n",
    "        t_s += str(int(t))\n",
    "        p_s += str(int(p[i]))\n",
    "print(t_s)\n",
    "print(p_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
