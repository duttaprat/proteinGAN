{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading preprosed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"saved_models/attention/version_1/version.cpkt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"regression.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_path, sep=',', header=(0), skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8588609431999998, -1.9754904544999998)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Y'].max(), data['Y'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = data.copy()\n",
    "#norm_data['Y']=(norm_data['Y']-norm_data['Y'].min())/(norm_data['Y'].max()-norm_data['Y'].min())\n",
    "norm_data['Y']=(norm_data['Y']-norm_data['Y'].mean())/norm_data['Y'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.150541397957692, -6.28618553626624)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_data['Y'].max(), norm_data['Y'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data.iloc[:,:-1] = norm_data.iloc[:,:-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(norm_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51260, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.iloc[:,:-1].values\n",
    "train_label = train.iloc[:,-1].values\n",
    "val_data = test.iloc[:,:-1].values\n",
    "val_label = test.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51260, 20), (51260,), (12816, 20), (12816,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_label.shape, val_data.shape, val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 1, 0, 2, 3, 1, 2, 2, 3, 0, 1, 0, 0, 2, 1, 2, 1, 3, 1]),\n",
       " -2.7490868759706966)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "NUM_OF_ACIDS = 4\n",
    "EMBEDDING_SIZE = 32\n",
    "NUM_CLASSES = np.amax(val_label, axis=0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input():\n",
    "    return (tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
    "            .shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "            .batch(64)\n",
    "            .repeat(NUM_EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input():\n",
    "    return (tf.data.Dataset.from_tensor_slices((val_data, val_label))\n",
    "            .batch(64).repeat(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, is_training):\n",
    "    acid_embeddings = tf.get_variable(\"acid_embeddings\", [NUM_OF_ACIDS, EMBEDDING_SIZE])\n",
    "    embedded_acids = tf.nn.embedding_lookup(acid_embeddings, features)\n",
    "    embedded_acids_flatten = tf.layers.flatten(embedded_acids)\n",
    "   # Build RNN cell\n",
    "    encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "\n",
    "    # Run Dynamic RNN\n",
    "    #   encoder_outputs: [max_time, batch_size, num_units]\n",
    "    #   encoder_state: [batch_size, num_units]\n",
    "    encoder_outputs, encoder_state = tf.nn.dynamic_rnn(encoder_cell, encoder_emb_inp,\n",
    "                                                       sequence_length=source_sequence_length, time_major=True)\n",
    "    \n",
    "    # Build RNN cell\n",
    "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "\n",
    "    # Helper\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(decoder_emb_inp, decoder_lengths, time_major=True)\n",
    "    # Decoder\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper, encoder_state,\n",
    "                                              output_layer=projection_layer)\n",
    "    # Dynamic decoding\n",
    "    outputs, _ = tf.contrib.seq2seq.dynamic_decode(decoder, ...)\n",
    "    logits = outputs.rnn_output\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \"\"\"The model_fn argument for creating an Estimator.\"\"\"\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        logits = model(features, is_training=False)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.PREDICT,\n",
    "            predictions=logits)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "        logits = model(features, is_training=True)\n",
    "        loss = tf.losses.absolute_difference(labels=labels, predictions=logits)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            loss=loss,\n",
    "            train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        logits = model(features, is_training=False)\n",
    "        loss = tf.losses.absolute_difference(labels=labels, predictions=logits)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'saved_models/regression/version_1/version.cpkt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001AA6A3F77B8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x000001AA6A3F8268>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "enzyme_classifier = tf.estimator.Estimator(\n",
    "      model_fn=model_fn,\n",
    "      model_dir=PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from saved_models/regression/version_1/version.cpkt\\model.ckpt-8010\n",
      "INFO:tensorflow:Saving checkpoints for 8011 into saved_models/regression/version_1/version.cpkt\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6924429, step = 8011\n",
      "INFO:tensorflow:global_step/sec: 79.1329\n",
      "INFO:tensorflow:loss = 0.737671, step = 8111 (1.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7774\n",
      "INFO:tensorflow:loss = 0.5827149, step = 8211 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7883\n",
      "INFO:tensorflow:loss = 0.654294, step = 8311 (1.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7258\n",
      "INFO:tensorflow:loss = 0.7169365, step = 8411 (1.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.0494\n",
      "INFO:tensorflow:loss = 0.883518, step = 8511 (1.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3069\n",
      "INFO:tensorflow:loss = 0.7001387, step = 8611 (1.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.856\n",
      "INFO:tensorflow:loss = 0.8358129, step = 8711 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.3747\n",
      "INFO:tensorflow:loss = 0.7165817, step = 8811 (1.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.1388\n",
      "INFO:tensorflow:loss = 0.859923, step = 8911 (1.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7278\n",
      "INFO:tensorflow:loss = 0.8407184, step = 9011 (1.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.8881\n",
      "INFO:tensorflow:loss = 0.7856238, step = 9111 (1.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.7594\n",
      "INFO:tensorflow:loss = 0.72677803, step = 9211 (1.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0311\n",
      "INFO:tensorflow:loss = 0.7325362, step = 9311 (1.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5646\n",
      "INFO:tensorflow:loss = 0.73952067, step = 9411 (1.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1614\n",
      "INFO:tensorflow:loss = 0.76325583, step = 9511 (1.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.1085\n",
      "INFO:tensorflow:loss = 0.8390527, step = 9611 (1.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8554\n",
      "INFO:tensorflow:loss = 0.6545929, step = 9711 (1.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.7356\n",
      "INFO:tensorflow:loss = 0.8124777, step = 9811 (1.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.4653\n",
      "INFO:tensorflow:loss = 0.8824291, step = 9911 (1.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.6508\n",
      "INFO:tensorflow:loss = 0.63243437, step = 10011 (1.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.084\n",
      "INFO:tensorflow:loss = 0.83540845, step = 10111 (1.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2411\n",
      "INFO:tensorflow:loss = 0.6805927, step = 10211 (1.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8999\n",
      "INFO:tensorflow:loss = 0.81109655, step = 10311 (1.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1552\n",
      "INFO:tensorflow:loss = 0.6538009, step = 10411 (1.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5633\n",
      "INFO:tensorflow:loss = 0.6495924, step = 10511 (1.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.0452\n",
      "INFO:tensorflow:loss = 0.6901778, step = 10611 (1.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9068\n",
      "INFO:tensorflow:loss = 0.61661637, step = 10711 (1.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1406\n",
      "INFO:tensorflow:loss = 0.7047043, step = 10811 (1.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2345\n",
      "INFO:tensorflow:loss = 0.8998549, step = 10911 (1.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.8803\n",
      "INFO:tensorflow:loss = 0.70915985, step = 11011 (1.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1638\n",
      "INFO:tensorflow:loss = 0.7535382, step = 11111 (1.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0142\n",
      "INFO:tensorflow:loss = 0.801728, step = 11211 (1.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3575\n",
      "INFO:tensorflow:loss = 0.9632319, step = 11311 (1.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8593\n",
      "INFO:tensorflow:loss = 0.66640294, step = 11411 (1.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.711\n",
      "INFO:tensorflow:loss = 0.6606142, step = 11511 (1.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2076\n",
      "INFO:tensorflow:loss = 0.7316604, step = 11611 (1.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2985\n",
      "INFO:tensorflow:loss = 0.7548385, step = 11711 (1.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.7777\n",
      "INFO:tensorflow:loss = 0.8173318, step = 11811 (1.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9847\n",
      "INFO:tensorflow:loss = 0.49273825, step = 11911 (1.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7157\n",
      "INFO:tensorflow:loss = 0.7025827, step = 12011 (1.287 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12015 into saved_models/regression/version_1/version.cpkt\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.65632266.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1aa6a3f74a8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enzyme_classifier.train(input_fn=train_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-07-19:48:24\n",
      "INFO:tensorflow:Restoring parameters from saved_models/regression/version_1/version.cpkt\\model.ckpt-12015\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-07-19:48:26\n",
      "INFO:tensorflow:Saving dict for global step 12015: global_step = 12015, loss = 0.791159\n",
      "\n",
      "Evaluation results:\n",
      "\t{'loss': 0.791159, 'global_step': 12015}\n"
     ]
    }
   ],
   "source": [
    "eval_results = enzyme_classifier.evaluate(input_fn=eval_input)\n",
    "print()\n",
    "print('Evaluation results:\\n\\t%s' % eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_input():\n",
    "    index = 10\n",
    "    print (val_data[0:index])\n",
    "    print (val_label[0:index])\n",
    "    return (tf.data.Dataset.from_tensor_slices((val_data[0:index], val_label[0:index])).batch(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Estimator.predict at 0x000002A493B3A6D0>\n",
      "[[2 2 2 3 0 0 0 2 1 1 1 0 0 1 2 2 2 1 0 0]\n",
      " [1 3 0 0 3 2 1 3 1 3 1 0 2 3 0 3 1 3 1 3]\n",
      " [1 2 0 2 3 0 3 2 1 3 2 1 1 0 1 3 1 1 1 1]\n",
      " [1 0 3 2 1 3 2 1 0 1 1 0 0 2 2 1 0 3 0 1]\n",
      " [1 2 1 0 1 1 3 2 2 1 1 2 2 3 0 2 3 0 2 3]\n",
      " [3 3 3 2 1 1 2 2 3 0 2 1 1 1 2 2 0 2 0 1]\n",
      " [1 3 0 1 0 3 1 2 3 1 3 2 3 2 1 2 1 1 1 0]\n",
      " [1 2 2 3 1 2 2 1 3 2 1 1 2 3 2 3 1 2 1 3]\n",
      " [0 3 3 2 2 2 0 1 1 2 3 1 1 1 2 3 2 1 3 0]\n",
      " [3 2 0 2 1 0 2 2 3 1 2 1 1 1 0 2 3 1 3 1]]\n",
      "[ 1.8371417  -0.76188853 -1.00000062 -0.99341339 -1.06843164  1.06686331\n",
      " -0.74164628  0.72892113  0.36989805  0.81223369]\n",
      "INFO:tensorflow:Restoring parameters from saved_models/regression/version_1/version.cpkt\\model.ckpt-4005\n",
      "0.22486427\n",
      "0.11091128\n",
      "-0.090491116\n",
      "0.014593732\n",
      "0.048556305\n",
      "-0.07160731\n",
      "0.0857504\n",
      "-0.035996374\n",
      "-0.06441446\n",
      "-0.27501512\n"
     ]
    }
   ],
   "source": [
    "predict = enzyme_classifier.predict(input_fn=prod_input)\n",
    "print (predict)\n",
    "for p in predict:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
