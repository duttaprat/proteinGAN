{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading preprosed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVEL=\"Level_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data = np.load(\"..//data//train_features_\"+LEVEL+\".npy\")\n",
    "train_label = np.load(\"..//data//train_labels_\"+LEVEL+\".npy\")\n",
    "val_data = np.load(\"..//data//val_features_\"+LEVEL+\".npy\")\n",
    "val_label = np.load(\"..//data//val_labels_\"+LEVEL+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"..//weights//cnn_{}_v2//version8.ckpt\".format(LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((164674, 500), (164674,), (41169, 500), (41169,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_label.shape, val_data.shape, val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ACIDS = 21\n",
    "EMBEDDING_SIZE = 8\n",
    "NUM_CLASSES = np.amax(val_label, axis=0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH=7\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donatasrep/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, is_training):\n",
    "    acid_embeddings = tf.get_variable(\"acid_embeddings\", [NUM_OF_ACIDS, EMBEDDING_SIZE])\n",
    "    embedded_acids = tf.nn.embedding_lookup(acid_embeddings, features)\n",
    "    embedded_acids = tf.expand_dims(embedded_acids, 3)\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=embedded_acids,\n",
    "      filters=32,\n",
    "      kernel_size=(3,EMBEDDING_SIZE),\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.selu)\n",
    "\n",
    "      # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=2, strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=(3,EMBEDDING_SIZE),\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.selu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=2, strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.layers.flatten(pool2)\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.selu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=is_training)\n",
    "\n",
    "    # Logits Layer\n",
    "    x = tf.layers.dense(inputs=dropout, units=NUM_CLASSES)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \"\"\"The model_fn argument for creating an Estimator.\"\"\"\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        logits = model(features, is_training=False)\n",
    "        predictions = {\n",
    "            'classes': tf.argmax(logits, axis=1),\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.PREDICT,\n",
    "            predictions=predictions,\n",
    "            export_outputs={\n",
    "                'classify': tf.estimator.export.PredictOutput(predictions)\n",
    "            })\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "        logits = model(features, is_training=True)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        accuracy = tf.metrics.accuracy(labels=labels, predictions=tf.argmax(logits, axis=1))\n",
    "        # Name the accuracy tensor 'train_accuracy' to demonstrate the\n",
    "        # LoggingTensorHook.\n",
    "        tf.identity(accuracy[1], name='train_accuracy')\n",
    "        tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            loss=loss,\n",
    "            train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        logits = model(features, is_training=False)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            loss=loss,\n",
    "            eval_metric_ops={\n",
    "                'accuracy': tf.metrics.accuracy(labels=labels, predictions=tf.argmax(logits, axis=1))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '..//weights//cnn_Level_1_v2//version8.ckpt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbdc8a67860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7fbdd60b81e0>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "enzyme_classifier = tf.estimator.Estimator(\n",
    "      model_fn=model_fn,\n",
    "      model_dir=PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input():\n",
    "    return (tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
    "            .shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .repeat(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ..//weights//cnn_Level_1_v2//version8.ckpt/model.ckpt-9009\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 9010 into ..//weights//cnn_Level_1_v2//version8.ckpt/model.ckpt.\n",
      "INFO:tensorflow:train_accuracy = 0.9296875\n",
      "INFO:tensorflow:loss = 0.25511307, step = 9010\n",
      "INFO:tensorflow:global_step/sec: 45.9907\n",
      "INFO:tensorflow:train_accuracy = 0.93359375 (2.176 sec)\n",
      "INFO:tensorflow:loss = 0.20976786, step = 9110 (2.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5782\n",
      "INFO:tensorflow:train_accuracy = 0.9427083 (2.101 sec)\n",
      "INFO:tensorflow:loss = 0.16500229, step = 9210 (2.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.6559\n",
      "INFO:tensorflow:train_accuracy = 0.9394531 (2.099 sec)\n",
      "INFO:tensorflow:loss = 0.23634267, step = 9310 (2.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.9071\n",
      "INFO:tensorflow:train_accuracy = 0.934375 (2.088 sec)\n",
      "INFO:tensorflow:loss = 0.20455964, step = 9410 (2.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8602\n",
      "INFO:tensorflow:train_accuracy = 0.93098956 (2.088 sec)\n",
      "INFO:tensorflow:loss = 0.23760758, step = 9510 (2.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8142\n",
      "INFO:tensorflow:train_accuracy = 0.93191963 (2.093 sec)\n",
      "INFO:tensorflow:loss = 0.19174632, step = 9610 (2.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.7125\n",
      "INFO:tensorflow:train_accuracy = 0.9296875 (2.095 sec)\n",
      "INFO:tensorflow:loss = 0.21559557, step = 9710 (2.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.6116\n",
      "INFO:tensorflow:train_accuracy = 0.9279514 (2.100 sec)\n",
      "INFO:tensorflow:loss = 0.27396557, step = 9810 (2.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8825\n",
      "INFO:tensorflow:train_accuracy = 0.93046874 (2.088 sec)\n",
      "INFO:tensorflow:loss = 0.1502693, step = 9910 (2.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5779\n",
      "INFO:tensorflow:train_accuracy = 0.93039775 (2.102 sec)\n",
      "INFO:tensorflow:loss = 0.1764364, step = 10010 (2.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.6992\n",
      "INFO:tensorflow:train_accuracy = 0.9316406 (2.097 sec)\n",
      "INFO:tensorflow:loss = 0.15421954, step = 10110 (2.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5825\n",
      "INFO:tensorflow:train_accuracy = 0.9332933 (2.101 sec)\n",
      "INFO:tensorflow:loss = 0.22446254, step = 10210 (2.101 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10296 into ..//weights//cnn_Level_1_v2//version8.ckpt/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.29072845.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fbdc8a67748>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors_to_log = {'train_accuracy': 'train_accuracy'}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "enzyme_classifier.train(input_fn=train_input, hooks=[logging_hook])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input():\n",
    "    return (tf.data.Dataset.from_tensor_slices((val_data, val_label))\n",
    "            .batch(BATCH_SIZE).repeat(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-22-10:14:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ..//weights//cnn_Level_1_v2//version8.ckpt/model.ckpt-10296\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-22-10:14:27\n",
      "INFO:tensorflow:Saving dict for global step 10296: accuracy = 0.83120793, global_step = 10296, loss = 0.6537026\n",
      "\n",
      "Evaluation results: {'accuracy': 0.83120793, 'loss': 0.6537026, 'global_step': 10296}\n"
     ]
    }
   ],
   "source": [
    "eval_results = enzyme_classifier.evaluate(input_fn=eval_input)\n",
    "print()\n",
    "print('Evaluation results: %s' % eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, array([[ 0,  0,  0, ...,  1,  7,  3],\n",
       "        [ 0,  0,  0, ..., 16, 18, 16],\n",
       "        [ 0,  0,  0, ...,  9,  2, 10],\n",
       "        [ 0,  0,  0, ..., 18, 17, 13],\n",
       "        [ 0,  0,  0, ..., 13, 16, 10]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"..//data//test_sequences.csv\", sep='\\t', skipinitialspace=True)\n",
    "data[\"Sequence\"] = data.Sequence.str.rjust(500, '0')\n",
    "letterToIndex = {'0': 0, 'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12,\n",
    "                 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20}\n",
    "data[\"Sequence_vector\"] = [[letterToIndex[char] for char in val ] for index, val in data.Sequence.iteritems()]\n",
    "test_data= np.asarray([ np.asarray(element) for element in data[\"Sequence_vector\"].values])\n",
    "len(test_data), test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input():\n",
    "    test_data_for_tensorflow = np.append(test_data, np.zeros((BATCH_SIZE-len(test_data), 500)), axis=0).astype(int)\n",
    "    return (tf.data.Dataset.from_tensor_slices((test_data_for_tensorflow))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ..//weights//cnn_Level_1_v2//version8.ckpt/model.ckpt-10296\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "\n",
      "Oxidoreductases Transferases Hydrolases Lyases Isomerases Ligases\n",
      "[0.02524485 0.42460245 0.3180151  0.08731605 0.1447798  0.0000418 ]\n",
      "2\n",
      "[0.01956985 0.63964903 0.10866959 0.23204246 0.00002328 0.00004582]\n",
      "2\n",
      "[0.15433058 0.20506094 0.6196978  0.00744062 0.00508434 0.00838569]\n",
      "3\n",
      "[0.00855853 0.9912123  0.00000528 0.00011529 0.00000593 0.0001026 ]\n",
      "2\n",
      "[0.07928088 0.457729   0.4544403  0.0002656  0.0073913  0.0008929 ]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "predict = enzyme_classifier.predict(input_fn=test_input)\n",
    "count = 0\n",
    "for p in predict:\n",
    "    if count == 0:\n",
    "        print(\"\\n\\r\")\n",
    "        print(\"Oxidoreductases Transferases Hydrolases Lyases Isomerases Ligases\")\n",
    "    count = count + 1\n",
    "    print(p[\"probabilities\"])\n",
    "    print( p[\"classes\"]+1)\n",
    "    if (count == 5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
