{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqicde8-y-fW"
   },
   "source": [
    "### Temporal Convolutional Networks Overview\n",
    "\n",
    "![TCNs](https://cdn-images-1.medium.com/max/1000/1*1cK-UEWHGaZLM-4ITCeqdQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeeOZueJy-fW"
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1220,
     "status": "ok",
     "timestamp": 1522629683286,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "5zj3MnAMy-fq",
    "outputId": "85b5cede-11ac-4182-f7e5-8deffffce67b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "suffix = \"all\"\n",
    "train_data = np.load(\"../../data/protein/classification/train_features_\"+suffix+\".npy\")\n",
    "train_label = np.load(\"../../data/protein/classification/train_labels_\"+suffix+\".npy\")\n",
    "val_data = np.load(\"../../data/protein/classification/val_features_\"+suffix+\".npy\")\n",
    "val_label = np.load(\"../../data/protein/classification/val_labels_\"+suffix+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = np.asarray([ np.asarray(element) for element in train_data[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_data = np.asarray([ np.asarray(element) for element in val_data[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((185137, 600), (46285, 600))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_label_dict(labels):\n",
    "    one_label_dict = {}\n",
    "    i = 0\n",
    "    for label in labels:\n",
    "        if label[0] not in one_label_dict:\n",
    "            one_label_dict[label[0]] = {}\n",
    "        if label[1] not in one_label_dict[label[0]]:\n",
    "            one_label_dict[label[0]][label[1]] = {}\n",
    "        if label[2] not in one_label_dict[label[0]][label[1]]:\n",
    "            one_label_dict[label[0]][label[1]][label[2]] = {}\n",
    "        if label[3] in one_label_dict[label[0]][label[1]][label[2]]:\n",
    "            continue\n",
    "        else:\n",
    "            one_label_dict[label[0]][label[1]][label[2]][label[3]] = i\n",
    "            i = i + 1\n",
    "    return one_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_label(labels, one_label_dict):\n",
    "    one_labels = []\n",
    "    for label in labels:\n",
    "        one_labels.append(one_label_dict[label[0]][label[1]][label[2]][label[3]])\n",
    "    return one_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_one = convert_to_one_label(train_label, get_one_label_dict(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_one = convert_to_one_label(val_label, get_one_label_dict(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1616"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_label_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_x00hIey-fw"
   },
   "source": [
    "## Building TCNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcFQu3F0y-fy"
   },
   "source": [
    "###  Causal Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByuyggHey-gI"
   },
   "source": [
    "###  Spatial Dropout\n",
    "\n",
    "Reference: https://stats.stackexchange.com/questions/282282/how-is-spatial-dropout-in-2d-implemented\n",
    "\n",
    "Actually, simply setting noise_shape in tf.layers.Dropout will do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1078,
     "status": "ok",
     "timestamp": 1522629692360,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "YRTsgwSGy-gK",
    "outputId": "6def0a04-cf65-4226-e6c9-4f7630ae02cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4, 10)\n",
      "[[-0.82197386 -3.0046816  -3.724099   -2.8766513  -0.22663254  0.88886863\n",
      "   1.6210606  -2.3477132   2.278684   -0.6836003 ]\n",
      " [-1.937318    0.7735584   2.840088    0.21559832 -0.7209419  -0.32201436\n",
      "   1.0481603   2.226582    1.1027129  -2.3055673 ]\n",
      " [-0.70179737 -0.8198413  -0.43068424 -0.19779772 -0.9129509  -2.2073545\n",
      "  -1.6410354   1.2270569  -2.4816089   2.0207832 ]\n",
      " [-1.310588   -0.9603893  -1.6769583   0.01309513  2.2220554  -0.6717528\n",
      "   5.1088195   1.8669513   0.55742496  1.5011914 ]]\n",
      "[[ 0.         -0.          0.          0.          0.          0.\n",
      "   0.         -0.          0.          0.        ]\n",
      " [-0.          0.         -0.          0.         -0.          0.\n",
      "   0.          0.          0.         -0.        ]\n",
      " [-0.          0.          0.         -0.          0.         -0.\n",
      "  -0.          0.         -0.         -0.        ]\n",
      " [-2.6522791  -0.18217683  0.6235265   0.21999747 -0.22957887  1.8100656\n",
      "  -1.908828   -3.8984725   0.14673786  1.2256571 ]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() as g:\n",
    "    x = tf.random_normal((32, 4, 10)) # (batch_size, channel, length)\n",
    "    dropout = tf.layers.Dropout(0.5, noise_shape=[x.shape[0], x.shape[1], tf.constant(1)])\n",
    "    output = dropout(x, training=True)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    res = sess.run(output)\n",
    "    print(res.shape)   \n",
    "    print(res[0, :, :])\n",
    "    print(res[1, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdTffJqQy-gU"
   },
   "source": [
    "### Temporal blocks\n",
    "\n",
    "Note: `tf.contrib.layers.layer_norm` only supports `channels_last`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9bHYwhRxy-gW"
   },
   "outputs": [],
   "source": [
    "# Redefining CausalConv1D to simplify its return values\n",
    "class CausalConv1D(tf.layers.Conv1D):\n",
    "    def __init__(self, filters,\n",
    "               kernel_size,\n",
    "               strides=1,\n",
    "               dilation_rate=1,\n",
    "               activation=None,\n",
    "               use_bias=True,\n",
    "               kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "               bias_initializer=tf.zeros_initializer(),\n",
    "               kernel_regularizer=None,\n",
    "               bias_regularizer=None,\n",
    "               activity_regularizer=None,\n",
    "               kernel_constraint=None,\n",
    "               bias_constraint=None,\n",
    "               trainable=True,\n",
    "               name=None,\n",
    "               **kwargs):\n",
    "        super(CausalConv1D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='valid',\n",
    "            data_format='channels_last',\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            trainable=trainable,\n",
    "            name=name, **kwargs\n",
    "        )\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        pad_1 = int(self.kernel_size[0]/2)\n",
    "        pad_2 = self.kernel_size[0]-1-pad_1\n",
    "        width_padding = [ pad_1* self.dilation_rate[0], pad_2 * self.dilation_rate[0]]\n",
    "        print(width_padding)\n",
    "        inputs = tf.pad(inputs, tf.constant([(0, 0,), width_padding, (0, 0)]), \"REFLECT\")\n",
    "        return super(CausalConv1D, self).call(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv2D(tf.layers.Conv2D):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 padding='valid',\n",
    "                 data_format='channels_last',\n",
    "                 dilation_rate=(1, 1),\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                 bias_initializer=tf.zeros_initializer(),\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 trainable=True,\n",
    "                 name=None,\n",
    "                 reuse=None,\n",
    "                 **kwargs):\n",
    "        super(CausalConv2D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=(1,strides),\n",
    "            padding='valid',\n",
    "            data_format='channels_last',\n",
    "            dilation_rate=(1, dilation_rate),\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            trainable=trainable,\n",
    "            name=name, \n",
    "            **kwargs\n",
    "        )\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        pad_1 = int(self.kernel_size[1]/2)\n",
    "        pad_2 = self.kernel_size[1]-1-pad_1\n",
    "        heigh_padding = [ pad_1* self.dilation_rate[1], pad_2 * self.dilation_rate[1]]\n",
    "        pad_1 = int(self.kernel_size[0]/2)\n",
    "        pad_2 = self.kernel_size[0]-1-pad_1\n",
    "        width_padding = [ pad_1* self.dilation_rate[0], pad_2 * self.dilation_rate[0]]\n",
    "        inputs = tf.pad(inputs, tf.constant([(0, 0,), width_padding, heigh_padding, (0,0)]), \"REFLECT\")\n",
    "        return super(CausalConv2D, self).call(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "re2siwPgy-ga"
   },
   "outputs": [],
   "source": [
    "class TemporalBlock(tf.layers.Layer):\n",
    "    def __init__(self, n_outputs, kernel_size, strides, dilation_rate, dropout=0.2, trainable=True, name=None, dtype=None, \n",
    "                 activity_regularizer=None, **kwargs):\n",
    "        super(TemporalBlock, self).__init__(trainable=trainable, dtype=dtype, activity_regularizer=activity_regularizer,\n",
    "                                            name=name, **kwargs)        \n",
    "        self.dropout = dropout\n",
    "        self.n_outputs = n_outputs\n",
    "        self.conv1 = CausalConv2D(n_outputs, kernel_size, strides=strides, dilation_rate=1, \n",
    "                                  activation=tf.nn.relu, name=\"conv1\")\n",
    "        self.conv2 = CausalConv2D(n_outputs, kernel_size, strides=1, dilation_rate=dilation_rate, \n",
    "                                  activation=tf.nn.relu, name=\"conv2\")\n",
    "        \n",
    "        self.conv3 = CausalConv2D(n_outputs, kernel_size, strides=strides, dilation_rate=1, \n",
    "                          activation=tf.nn.relu, name=\"conv3\")\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        channel_dim = 2\n",
    "        self.dropout1 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "        self.dropout2 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.conv1(inputs)\n",
    "        x = tf.contrib.layers.layer_norm(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.contrib.layers.layer_norm(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        inputs = self.conv3(inputs)\n",
    "        return tf.nn.leaky_relu(x + inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1162,
     "status": "ok",
     "timestamp": 1522634695536,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "-CMZKL1jy-ge",
    "outputId": "05e31b54-3bfa-4049-f538-a20844b15f41",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input with shape of (1, 3, 8, 1)\n",
      "---------  ---------  ----------  ---------  ---------  ----------  ----------  ---------\n",
      "-1.0154    -0.586145  -0.0847688   1.08107    0.664716   1.14846    -0.0510511   1.07549\n",
      " 1.00501    0.250471  -0.135105    0.69252    0.429332  -0.0694308  -0.336875   -0.890913\n",
      "-0.372627  -1.25377    0.726707   -0.951095  -0.285603  -0.170857    0.386026    0.746121\n",
      "---------  ---------  ----------  ---------  ---------  ----------  ----------  ---------\n",
      "Output with shape of (1, 3, 8, 8)\n",
      "---------  ----------  ----------  ---------  ----------  ---------  ----------  ---------\n",
      "-0.118704   4.65737    -0.101032    1.43941   -0.138552   -0.147065  -0.0242772   3.97687\n",
      " 2.51609   -0.0844534  -0.0154095  -0.147065  -0.147065    3.66903   -0.147065   -0.115054\n",
      "-0.147065   5.88011    -0.132755    1.22316   -0.0890022  -0.147065  -0.102725    3.90816\n",
      "---------  ----------  ----------  ---------  ----------  ---------  ----------  ---------\n",
      "---------  ---------  ----------  ----------  --------  ----------  ----------  ----------\n",
      "-0.12401   -0.147065  -0.0873394  -0.0709138  0.152737  -0.0296757  -0.0179859  -0.0756076\n",
      "-0.126564  -0.143734  -0.0589913  -0.0903676  0.551494   0.0593839  -0.0481955   0.355113\n",
      "-0.125125  -0.142569  -0.147065   -0.119231   0.340751  -0.0753788  -0.0644197  -0.114459\n",
      "---------  ---------  ----------  ----------  --------  ----------  ----------  ----------\n",
      "-----------  ---------  ----------  ---------  ----------  -------  ----------  ---------\n",
      "-0.147065     1.52874   -0.0843716   2.66201    0.0920238  0.78865  -0.0755387  -0.147065\n",
      "-0.0856011   -0.134434  -0.140084   -0.147065  -0.0835607  1.79206  -0.13187     0.668449\n",
      "-0.00840913   1.17308   -0.0894605   3.17522    0.407436   1.17523  -0.118038   -0.11039\n",
      "-----------  ---------  ----------  ---------  ----------  -------  ----------  ---------\n",
      "---------  --------  --------  ---------  ---------  --------  --------  ---------\n",
      "0.0417925  0         0         0          0.0805472  0.554949  0.184869  0.152943\n",
      "0.329836   0         0.126345  0.0205543  0          0.488937  0.20487   0.308334\n",
      "0          0.183496  0         0          0.0704529  0.451242  0.171306  0.0272279\n",
      "---------  --------  --------  ---------  ---------  --------  --------  ---------\n",
      "---------  ----------  ----------  ----------  ---------  ---------  -----------  ---------\n",
      "-0.128792   0.398666   -0.147065   -0.0145251  -0.147065  -0.147065  -0.137446     3.97963\n",
      "-0.147065  -0.0268692  -0.0799005  -0.111388   -0.147065   1.49401   -0.00712783  -0.104714\n",
      "-0.139403  -0.015027   -0.147065    0.0226469  -0.147065  -0.147065  -0.147065     3.91961\n",
      "---------  ----------  ----------  ----------  ---------  ---------  -----------  ---------\n",
      "---------  --------  ---------  --------  ---------  ---------  --------  --------\n",
      "0.107342   0         0          0.351599  0.0777997  0.0903112  0         0\n",
      "0          0.666107  0.0956534  0         0          0.0976613  0.237497  0.106644\n",
      "0.0380627  0         0          0.501645  0.230844   0.176635   0         0\n",
      "---------  --------  ---------  --------  ---------  ---------  --------  --------\n",
      "---------  ---------  ----------  ---------  ----------  ---------  ----------  ---------\n",
      " 0.192412  -0.147065   1.57148    -0.147065  -0.147065    0.077012   2.02749    -0.147065\n",
      "-0.121927   3.48038   -0.0461416  -0.147065  -0.0727691  -0.147065  -0.0966229   3.71886\n",
      " 1.60255   -0.147065   1.89119    -0.147065  -0.147065    0.342776   1.53187    -0.147065\n",
      "---------  ---------  ----------  ---------  ----------  ---------  ----------  ---------\n",
      "---------  -----------  ----------  -------  ----------  ----------  ---------  ---------\n",
      "-0.147065  -0.00181848  -0.0469864  1.59441  -0.0863371   1.08761    -0.147065  -0.146558\n",
      "-0.147065  -0.131261    -0.147065   1.87228   0.0082339  -0.0516199  -0.147065   1.01781\n",
      "-0.117959  -0.114114    -0.0361148  1.16929  -0.147065    1.41573    -0.147065  -0.129442\n",
      "---------  -----------  ----------  -------  ----------  ----------  ---------  ---------\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() as g:\n",
    "    x = tf.random_normal((1, 3, 8, 1)) # (batch_size, length, channel)\n",
    "    tblock = TemporalBlock(8, (3,3), 1, 4) #n_outputs, kernel_size, strides, dilation_rate\n",
    "    output = tblock(x, training=tf.constant(True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    res = sess.run(output)\n",
    "    print(\"Input with shape of {}\".format(x.shape))\n",
    "    print(tabulate(tf.squeeze(x).eval()))\n",
    "    print(\"Output with shape of {}\".format(res.shape))\n",
    "    print(tabulate(res[0, :, :, 0]))\n",
    "    print(tabulate(res[0, :, :, 1]))\n",
    "    print(tabulate(res[0, :, :, 2]))\n",
    "    print(tabulate(res[0, :, :, 3]))\n",
    "    print(tabulate(res[0, :, :, 4]))\n",
    "    print(tabulate(res[0, :, :, 5]))\n",
    "    print(tabulate(res[0, :, :, 6]))\n",
    "    print(tabulate(res[0, :, :, 7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhzHzZtMy-gk"
   },
   "source": [
    "### Temporal convolutional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GeLztD1Ly-gm"
   },
   "outputs": [],
   "source": [
    "class TemporalConvNet(tf.layers.Layer):\n",
    "    def __init__(self, num_channels, strides, kernel_size=2, dropout=0.2, trainable=True, name=None, dtype=None, \n",
    "                 activity_regularizer=None, **kwargs):\n",
    "        super(TemporalConvNet, self).__init__(trainable=trainable, dtype=dtype, activity_regularizer=activity_regularizer,\n",
    "                                              name=name, **kwargs)\n",
    "        self.layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 1 ** i\n",
    "            out_channels = num_channels[i]\n",
    "            self.layers.append(TemporalBlock(out_channels, kernel_size, strides=strides[i], dilation_rate=dilation_size,\n",
    "                                             dropout=dropout, name=\"tblock_{}\".format(i)))\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        outputs = inputs\n",
    "        for layer in self.layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1728,
     "status": "ok",
     "timestamp": 1522634710620,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "zCMhWfWjy-g0",
    "outputId": "9d39a675-debb-41e0-86e5-970c57845079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 10, 8)\n",
      "---------  ----------  ---------  ----------  --------  --------  ---------  --------\n",
      " 2.56614    1.0259      1.53186   -0.133287   2.35915   0         -0.133287  0\n",
      " 0.766785   2.59044     1.33161   -0.133287   0         0          0.665247  0\n",
      "-0.133287   0.860084   -0.122152  -0.133287   1.56387   1.5653    -0.133287  0.311007\n",
      " 0.871284   0.542529    0.559552  -0.123903   1.14042   1.67408   -0.133287  0\n",
      "-0.133287   2.74805    -0.133287  -0.133287   1.18399   0          1.52117   2.67627\n",
      "-0.133287   3.64058    -0.133287   0.359349   0.848606  0.969381  -0.133287  0\n",
      " 1.63504   -0.133287    0.681861  -0.133287   0         0         -0.133287  0\n",
      "-0.133287  -0.0871876  -0.133287   0.218772   0.870577  0          0.500016  0\n",
      "-0.133287  -0.0732622  -0.133287  -0.133287   0         0         -0.133287  0\n",
      "-0.133287   0.0516056  -0.133287  -0.0654511  0.410016  0         -0.133287  0\n",
      "---------  ----------  ---------  ----------  --------  --------  ---------  --------\n",
      "----------  ---------  -----------  ----------  --------  --------  ----------  -\n",
      " 1.67137     1.73597   -0.133287    -0.133287   3.29195   2.3949     1.98276    0\n",
      "-0.0409504   0.546613   0.623017     0.280641   1.45639   0         -0.0691142  0\n",
      " 0.923418    0.650494  -0.0510472    0.197982   1.5798    2.24057    2.17983    0\n",
      "-0.133287    3.40143    0.540317    -0.133287   0         0          2.29363    0\n",
      " 1.20678     2.6581    -0.0895405   -0.133287   0         0          0.831974   0\n",
      "-0.133287    1.53729    4.16845     -0.0512781  0         0.752347   1.35765    0\n",
      " 0.38348     2.32174    0.00738931  -0.0893162  0.625604  0          0.815413   0\n",
      " 0.29963    -0.133138   2.09237     -0.133287   0.209508  0.225725  -0.133287   0\n",
      "-0.133287   -0.133287  -0.133287    -0.133287   0.301941  0         -0.133287   0\n",
      "-0.133287   -0.133287  -0.0529575   -0.133287   0.281683  0         -0.133287   0\n",
      "----------  ---------  -----------  ----------  --------  --------  ----------  -\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    Xinput = tf.placeholder(tf.float32, shape=[None, 10, 10, 1])\n",
    "    tcn = TemporalConvNet([8, 8, 8, 8], [1, 1, 1, 1], (3,3), 0.25)\n",
    "    output = tcn(Xinput, training=tf.constant(True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    res = sess.run(output, {Xinput: np.random.randn(1, 10, 10, 1)})\n",
    "    print(res.shape)   \n",
    "    print(tabulate(res[0, :, 0]))\n",
    "    print(tabulate(res[0, :, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jYugVyby-g-"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1300,
     "status": "ok",
     "timestamp": 1522634805178,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "41qAk9lAy-hC",
    "outputId": "a1607a69-b33e-4ef6-e792-360a4b0e250f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 15 with batches per epoch: 23143\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 8\n",
    "batches_per_epoch = int(train_data.shape[0]/batch_size)+1\n",
    "num_epochs = 15\n",
    "print(\"Number of epochs: {} with batches per epoch: {}\".format(num_epochs, batches_per_epoch))\n",
    "\n",
    "# Network Parameters\n",
    "sequence_length=train_data.shape[1]\n",
    "num_classes = len(set(train_label_one))\n",
    "num_of_acids = 21\n",
    "embedding_size = 3\n",
    "dropout = 0.5\n",
    "kernel_size = (3,3)\n",
    "levels = 6\n",
    "hidden_dim_f = 2\n",
    "hidden_features = [hidden_dim_f, hidden_dim_f*2, hidden_dim_f*4, hidden_dim_f*8, hidden_dim_f*16 ,hidden_dim_f*32] # hidden layer num of features\n",
    "strides = [1 ,2, 2, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5236,
     "status": "ok",
     "timestamp": 1522636269832,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "bP37UtN5y-hG",
    "outputId": "089539a5-b6c1-4cb0-ca1c-deacde5b3cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 600, 1)\n",
      "tcn_output (8, 3, 19, 64)\n",
      "flatten_tcn_output (8, 3648)\n",
      "All parameters: 17988029.0\n",
      "Trainable parameters: 5996009\n",
      "embedding/acid_embeddings:0(21, 3)\n",
      "tcn/temporal_conv_net/tblock_0/conv1/kernel:0(3, 3, 1, 2)\n",
      "tcn/temporal_conv_net/tblock_0/conv1/bias:0(2,)\n",
      "tcn/temporal_conv_net/tblock_0/conv2/kernel:0(3, 3, 2, 2)\n",
      "tcn/temporal_conv_net/tblock_0/conv2/bias:0(2,)\n",
      "tcn/temporal_conv_net/tblock_0/conv3/kernel:0(3, 3, 1, 2)\n",
      "tcn/temporal_conv_net/tblock_0/conv3/bias:0(2,)\n",
      "tcn/temporal_conv_net/tblock_1/conv1/kernel:0(3, 3, 2, 4)\n",
      "tcn/temporal_conv_net/tblock_1/conv1/bias:0(4,)\n",
      "tcn/temporal_conv_net/tblock_1/conv2/kernel:0(3, 3, 4, 4)\n",
      "tcn/temporal_conv_net/tblock_1/conv2/bias:0(4,)\n",
      "tcn/temporal_conv_net/tblock_1/conv3/kernel:0(3, 3, 2, 4)\n",
      "tcn/temporal_conv_net/tblock_1/conv3/bias:0(4,)\n",
      "tcn/temporal_conv_net/tblock_2/conv1/kernel:0(3, 3, 4, 8)\n",
      "tcn/temporal_conv_net/tblock_2/conv1/bias:0(8,)\n",
      "tcn/temporal_conv_net/tblock_2/conv2/kernel:0(3, 3, 8, 8)\n",
      "tcn/temporal_conv_net/tblock_2/conv2/bias:0(8,)\n",
      "tcn/temporal_conv_net/tblock_2/conv3/kernel:0(3, 3, 4, 8)\n",
      "tcn/temporal_conv_net/tblock_2/conv3/bias:0(8,)\n",
      "tcn/temporal_conv_net/tblock_3/conv1/kernel:0(3, 3, 8, 16)\n",
      "tcn/temporal_conv_net/tblock_3/conv1/bias:0(16,)\n",
      "tcn/temporal_conv_net/tblock_3/conv2/kernel:0(3, 3, 16, 16)\n",
      "tcn/temporal_conv_net/tblock_3/conv2/bias:0(16,)\n",
      "tcn/temporal_conv_net/tblock_3/conv3/kernel:0(3, 3, 8, 16)\n",
      "tcn/temporal_conv_net/tblock_3/conv3/bias:0(16,)\n",
      "tcn/temporal_conv_net/tblock_4/conv1/kernel:0(3, 3, 16, 32)\n",
      "tcn/temporal_conv_net/tblock_4/conv1/bias:0(32,)\n",
      "tcn/temporal_conv_net/tblock_4/conv2/kernel:0(3, 3, 32, 32)\n",
      "tcn/temporal_conv_net/tblock_4/conv2/bias:0(32,)\n",
      "tcn/temporal_conv_net/tblock_4/conv3/kernel:0(3, 3, 16, 32)\n",
      "tcn/temporal_conv_net/tblock_4/conv3/bias:0(32,)\n",
      "tcn/temporal_conv_net/tblock_5/conv1/kernel:0(3, 3, 32, 64)\n",
      "tcn/temporal_conv_net/tblock_5/conv1/bias:0(64,)\n",
      "tcn/temporal_conv_net/tblock_5/conv2/kernel:0(3, 3, 64, 64)\n",
      "tcn/temporal_conv_net/tblock_5/conv2/bias:0(64,)\n",
      "tcn/temporal_conv_net/tblock_5/conv3/kernel:0(3, 3, 32, 64)\n",
      "tcn/temporal_conv_net/tblock_5/conv3/bias:0(64,)\n",
      "tcn/dense/kernel:0(3648, 1616)\n",
      "tcn/dense/bias:0(1616,)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(10)\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        sequences = tf.placeholder(tf.int32, [None, sequence_length], name='sequences')\n",
    "        labels = tf.placeholder(tf.int32, (None,))\n",
    "        is_training = tf.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "        dataset = (tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "                   .shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "                   .apply(tf.contrib.data.batch_and_drop_remainder(batch_size)))\n",
    "    \n",
    "        iterator = dataset.make_initializable_iterator()\n",
    "        \n",
    "    \n",
    "    with tf.variable_scope('embedding'):\n",
    "        acid_embeddings = tf.get_variable(\"acid_embeddings\", [num_of_acids, embedding_size])\n",
    "\n",
    "        batch_sequences, batch_labels = iterator.get_next()\n",
    "\n",
    "        embedded_sequences = tf.nn.embedding_lookup(acid_embeddings, batch_sequences)\n",
    "        embedded_sequences = tf.expand_dims(tf.transpose(embedded_sequences, perm=[0,2,1]), axis=3)\n",
    "        print(embedded_sequences.shape)\n",
    "    # Define weights\n",
    "    with tf.variable_scope('tcn'):\n",
    "        tcn_output = TemporalConvNet(hidden_features, strides, kernel_size, \n",
    "                                                 dropout)(embedded_sequences, training=is_training)\n",
    "        print(\"tcn_output\", tcn_output.shape)\n",
    "        flatten_tcn_output = tf.layers.flatten(tcn_output)\n",
    "        print(\"flatten_tcn_output\", flatten_tcn_output.shape)\n",
    "        logits = tf.layers.dense(flatten_tcn_output,num_classes, activation=None, kernel_initializer=tf.orthogonal_initializer())\n",
    "            \n",
    "\n",
    "    # Define loss and optimizer\n",
    "    with tf.name_scope(\"loss_op\"):\n",
    "        loss_op = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=batch_labels, logits=logits))\n",
    "        tf.summary.scalar(\"loss_op\", loss_op)\n",
    "    \n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, 1, output_type=tf.int32), tf.squeeze(batch_labels))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    \n",
    "    summ = tf.summary.merge_all()\n",
    "    \n",
    "     # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    print(\"All parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.global_variables()]))\n",
    "    print(\"Trainable parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()]))\n",
    "    [ print(\"{}{}\".format(x.name, x.shape)) for x in tf.trainable_variables() if \"LayerNorm\" not in x.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(step, loss, acc):\n",
    "    print(\"Step {}, Loss={:.4f}, Accuracy={:.3f}\".format(str(step), loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):    \n",
    "    # Calculate batch loss and accuracy\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    sess.run(iterator.initializer, feed_dict={sequences: val_data, labels: val_label_one})\n",
    "    while True:\n",
    "        try:\n",
    "            # Run optimization\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={is_training: False})\n",
    "            losses.append(loss)\n",
    "            accuracies.append(acc)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    loss_avg = sum(losses)/len(losses)\n",
    "    acc_avg = sum(accuracies)/len(accuracies)\n",
    "    print_progress(\"VALIDATION for epoch {}\".format(epoch), loss_avg, acc_avg)\n",
    "    return acc_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 416220,
     "status": "ok",
     "timestamp": 1522636686094,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "IjwOnIUmy-hM",
    "outputId": "79b8a85e-9f56-458d-ecc9-3eea13094548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss=nan, Accuracy=0.000\n",
      "Step 5785, Loss=nan, Accuracy=0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-33d1cc2306fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches_per_epoch\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random \n",
    "from datetime import datetime\n",
    "path = \"../../logs/tcn_sequence/\"\n",
    "log_dir = \"{}{}\".format(path, datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "Path(log_dir).mkdir(exist_ok=True, parents=True)\n",
    "tb_writer = tf.summary.FileWriter(log_dir, graph)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = False\n",
    "best_val_acc = 0.8\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Run the initializer\n",
    "    epoch, step = 0, 0\n",
    "    sess.run([init, iterator.initializer], feed_dict={sequences: train_data, labels: train_label_one})\n",
    "    while epoch < num_epochs:\n",
    "        try: \n",
    "            sess.run(train_op, feed_dict={is_training: True})\n",
    "            step = step +1 \n",
    "            if step % int(batches_per_epoch/4) == 0 or step == 1:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={is_training: True})\n",
    "                print_progress(step, loss, acc)\n",
    "                [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={is_training: True})\n",
    "                tb_writer.add_summary(s, step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            path\n",
    "            epoch = epoch + 1\n",
    "            val_acc = validation(epoch)           \n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                save_path = saver.save(sess, \"{}{}\".format(path, \"v1\"))\n",
    "                print(\"Model saved in path: %s\" % save_path)\n",
    "            sess.run(iterator.initializer, feed_dict={sequences: train_data, labels: train_label_one})\n",
    "    print(\"Optimization Finished!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation with new sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 500)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"..//data//test_sequences.csv\", sep='\\t', skipinitialspace=True)\n",
    "data[\"Sequence\"] = data.Sequence.str.ljust(500, '0')\n",
    "letterToIndex = {'0': 0, 'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12,\n",
    "                 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20}\n",
    "data[\"Sequence_vector\"] = [[letterToIndex[char] for char in val ] for index, val in data.Sequence.iteritems()]\n",
    "test_data= np.asarray([ np.asarray(element) for element in data[\"Sequence_vector\"].values])\n",
    "test_data_for_tensorflow = np.append(test_data, np.zeros((batch_size-len(test_data), sequence_length)), axis=0).astype(int)\n",
    "test_data_for_tensorflow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_elements = np.array([1,2,3,4,5,6])\n",
    "label_for_tensorflow = np.append(test_elements, np.zeros((batch_size-len(test_elements))), axis=0).astype(int)\n",
    "label_for_tensorflow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../logs/tcn_sequence/v1\n"
     ]
    }
   ],
   "source": [
    "s = tf.Session(graph=graph)\n",
    "s.run(init)\n",
    "saver.restore(s, \"../logs/tcn_sequence/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\n",
      "Oxidoreductases Transferases Hydrolases Lyases Isomerases Ligases\n",
      "[[[0.00003311 0.00000058 0.         ... 0.00005921 0.00000001 0.00000002]]]\n",
      "238\n",
      "[[[0.         0.         0.         ... 0.         0.00000075 0.        ]]]\n",
      "218\n",
      "[[[0.0000794  0.         0.         ... 0.00029334 0.         0.        ]]]\n",
      "548\n",
      "[[[0.00000006 0.         0.         ... 0.00000005 0.00000172 0.        ]]]\n",
      "1267\n",
      "[[[0.00008943 0.         0.         ... 0.00000001 0.         0.        ]]]\n",
      "471\n",
      "[[[0. 0. 0. ... 0. 0. 0.]]]\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=8)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "s.run(iterator.initializer, feed_dict={sequences: test_data_for_tensorflow, labels: label_for_tensorflow})\n",
    "preds, ls = s.run([prediction, batch_labels], feed_dict={is_training: False})\n",
    "count = 0\n",
    "selected_ls = ls.take(np.argwhere(ls > 0))\n",
    "selected_preds = preds.take(np.argwhere(ls > 0), axis=0)\n",
    "for i in selected_ls.argsort(axis=0):\n",
    "    if count == 0:\n",
    "        print(\"\\n\\r\")\n",
    "        print(\"Oxidoreductases Transferases Hydrolases Lyases Isomerases Ligases\")\n",
    "    print(selected_preds[i])\n",
    "    print(np.argmax(selected_preds[i]))\n",
    "    count = count + 1\n",
    "\n",
    "#     print( p[\"classes\"]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ls.argsort(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [5],\n",
       "       [2]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.sort()\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123],\n",
       "       [124],\n",
       "       [125],\n",
       "       [126],\n",
       "       [127]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(ls > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "tcn_mnist.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
