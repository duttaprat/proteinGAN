{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b10XJFD-y-fS"
   },
   "source": [
    "# Solving Sequential MNIST with Temporal Convolutional Networks(TCNs)\n",
    "\n",
    "- Sequential MNIST: Based on the work of [Aymeric Damien](https://github.com/aymericdamien/TensorFlow-Examples/) and [Sungjoon](https://github.com/sjchoi86/tensorflow-101/blob/master/notebooks/rnn_mnist_simple.ipynb)\n",
    "- Temporal Convolutional Networks: [Bai, S., Kolter, J. Z., & Koltun, V. (2018). An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling.](http://arxiv.org/abs/1803.01271)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqicde8-y-fW"
   },
   "source": [
    "### MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "To classify images using a recurrent neural network, we consider every image row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then handle 28 sequences of 28 timesteps for every sample.\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "### Temporal Convolutional Networks Overview\n",
    "\n",
    "![TCNs](https://cdn-images-1.medium.com/max/1000/1*1cK-UEWHGaZLM-4ITCeqdQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeeOZueJy-fW"
   },
   "source": [
    "## System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 312.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4080.0,
     "status": "ok",
     "timestamp": 1.522629650076E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "PSj1MFEyy-fa",
    "outputId": "0a4e1c2b-457b-4a03-e50d-58289e661f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watermark\n",
      "  Downloading watermark-1.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from watermark)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython->watermark)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->watermark)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->watermark)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->watermark)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark)\n",
      "Installing collected packages: watermark\n",
      "Successfully installed watermark-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 260.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7980.0,
     "status": "ok",
     "timestamp": 1.522629659026E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "PJ589Jbgy-fk",
    "outputId": "913450d8-ac1c-4407-ffdd-c6eb2228a36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.3\n",
      "IPython 5.5.0\n",
      "\n",
      "tensorflow 1.6.0\n",
      "numpy 1.14.2\n",
      "\n",
      "compiler   : GCC 7.2.0\n",
      "system     : Linux\n",
      "release    : 4.4.111+\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n",
      "Git hash   :\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p tensorflow,numpy -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 364.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12856.0,
     "status": "ok",
     "timestamp": 1.522629671936E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "1KgKXmJ1CatC",
    "outputId": "445a66eb-0991-499c-bde7-7358563d6106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Downloading GPUtil-1.2.3.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil)\n",
      "Building wheels for collected packages: gputil\n",
      "  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/ff/24/c1/7e98d678e5be90c88cc151f1f3ef77a96ea3e8266b1aa225a4\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.2.3\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages\n",
      "Collecting humanize\n",
      "  Downloading humanize-0.5.1.tar.gz\n",
      "Building wheels for collected packages: humanize\n",
      "  Running setup.py bdist_wheel for humanize ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d4/80/38/cfbfd95752f71f3812505b948b43383ddc99eedf835fc13b09\n",
      "Successfully built humanize\n",
      "Installing collected packages: humanize\n",
      "Successfully installed humanize-0.5.1\n",
      "Gen RAM Free: 12.6 GB  I Proc size: 241.1 MB\n",
      "GPU RAM Free: 11439MB | Used: 0MB | Util   0% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "# From https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn't guaranteed\n",
    "gpu = GPUs[0]\n",
    "\n",
    "def printm():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1220.0,
     "status": "ok",
     "timestamp": 1.522629683286E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "5zj3MnAMy-fq",
    "outputId": "85b5cede-11ac-4182-f7e5-8deffffce67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "# import random \n",
    "# from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_x00hIey-fw"
   },
   "source": [
    "## Building TCNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcFQu3F0y-fy"
   },
   "source": [
    "###  Causal Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "-u-dyRIPy-fy"
   },
   "outputs": [],
   "source": [
    "class CausalConv1D(tf.layers.Conv1D):\n",
    "    def __init__(self, filters,\n",
    "               kernel_size,\n",
    "               strides=1,\n",
    "               dilation_rate=1,\n",
    "               activation=None,\n",
    "               use_bias=True,\n",
    "               kernel_initializer=None,\n",
    "               bias_initializer=tf.zeros_initializer(),\n",
    "               kernel_regularizer=None,\n",
    "               bias_regularizer=None,\n",
    "               activity_regularizer=None,\n",
    "               kernel_constraint=None,\n",
    "               bias_constraint=None,\n",
    "               trainable=True,\n",
    "               name=None,\n",
    "               **kwargs):\n",
    "        super(CausalConv1D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='valid',\n",
    "            data_format='channels_last',\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            trainable=trainable,\n",
    "            name=name, **kwargs\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        padding = (self.kernel_size[0] - 1) * self.dilation_rate[0]\n",
    "        if self.data_format == 'channels_first':\n",
    "            inputs = tf.pad(inputs, tf.constant([[0, 0], [0, 0], [padding, 0]], dtype=tf.int32))\n",
    "        else:\n",
    "            inputs = tf.pad(inputs, tf.constant([(0, 0,), (padding, 0), (0, 0)]))\n",
    "        return super(CausalConv1D, self).call(inputs), inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 193.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2770.0,
     "status": "ok",
     "timestamp": 1.522629689926E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "4FIx5P1ty-f2",
    "outputId": "37a998b7-0ebc-4461-8c8d-856e01b1d530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/donatasrep/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "(32, 12, 4)\n",
      "[ 0.          0.         -0.45763603  0.504357    0.36972928  0.8420956\n",
      " -0.17213115 -0.88108134  0.8499337  -0.83316106  1.6390396  -1.3233004 ]\n",
      "(32, 10, 8)\n",
      "[0.         0.30983484 0.         1.0478979  1.2866292  0.\n",
      " 0.523978   0.         2.4876685  0.        ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() as g:\n",
    "    x = tf.random_normal((32, 10, 4)) # (batch_size, length, channel)\n",
    "    with tf.variable_scope(\"tcn\"):\n",
    "        conv = CausalConv1D(8, 3, activation=tf.nn.relu)\n",
    "    output = conv(x)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    res, inputs = sess.run(output)\n",
    "    print(inputs.shape)\n",
    "    print(inputs[0, :, 0])\n",
    "    print(res.shape)    \n",
    "    print(res[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 104.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1162.0,
     "status": "ok",
     "timestamp": 1.522629691134E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "_CYDJDCGy-f-",
    "outputId": "be3cd49a-5070-44b4-c8de-3c3e64ade420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9, 1)\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "(1, 7, 8)\n",
      "[0.48714566 0.         0.25451237 0.48714566 0.         0.25451237\n",
      " 0.48714566]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() as g:\n",
    "    x = tf.expand_dims(\n",
    "        tf.expand_dims(tf.constant([1, 0, 0, 1, 0, 0, 1], dtype=tf.float32), axis=0),\n",
    "        axis=-1) # (batch_size, length, channel)\n",
    "    with tf.variable_scope(\"tcn\"):\n",
    "        conv = CausalConv1D(8, 2, dilation_rate=2, activation=None)\n",
    "    output = conv(x)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    res, inputs = sess.run(output)\n",
    "    print(inputs.shape)\n",
    "    print(inputs[0, :, 0])\n",
    "    print(res.shape)    \n",
    "    print(res[0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByuyggHey-gI"
   },
   "source": [
    "###  Spatial Dropout\n",
    "\n",
    "Reference: https://stats.stackexchange.com/questions/282282/how-is-spatial-dropout-in-2d-implemented\n",
    "\n",
    "Actually, simply setting noise_shape in tf.layers.Dropout will do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 312.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1078.0,
     "status": "ok",
     "timestamp": 1.52262969236E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "YRTsgwSGy-gK",
    "outputId": "6def0a04-cf65-4226-e6c9-4f7630ae02cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4, 10)\n",
      "[[ 0.95880884  1.4532794  -0.8236471   1.5369288  -2.9139783  -0.9681007\n",
      "  -5.0731506   2.399533   -2.860189   -0.38920859]\n",
      " [ 0.         -0.          0.         -0.         -0.         -0.\n",
      "   0.         -0.         -0.          0.        ]\n",
      " [ 1.6342374   1.4396956  -0.8069296   3.4330459   3.1080108  -3.1137471\n",
      "   2.3516803  -0.1314822  -0.94608176 -2.0485475 ]\n",
      " [-1.8981228   1.8372859   0.3333674   0.2543377  -0.47653505 -2.3097582\n",
      "  -3.0428874   0.49862045  0.18071352 -0.67625207]]\n",
      "[[-0.          0.          0.          0.         -0.          0.\n",
      "   0.         -0.         -0.         -0.        ]\n",
      " [ 0.6703546  -0.8413147  -0.19589455  2.7352002   0.4411555   0.9030962\n",
      "   5.731618    0.18732122  2.3072958  -0.42503923]\n",
      " [-0.86330324  0.32336375  0.5302199   0.27789575 -0.66891885 -3.7300706\n",
      "  -1.1190782   1.2690421  -1.3252184  -0.6444381 ]\n",
      " [ 0.         -0.          0.         -0.          0.         -0.\n",
      "   0.         -0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() as g:\n",
    "    x = tf.random_normal((32, 4, 10)) # (batch_size, channel, length)\n",
    "    dropout = tf.layers.Dropout(0.5, noise_shape=[x.shape[0], x.shape[1], tf.constant(1)])\n",
    "    output = dropout(x, training=True)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    res = sess.run(output)\n",
    "    print(res.shape)   \n",
    "    print(res[0, :, :])\n",
    "    print(res[1, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdTffJqQy-gU"
   },
   "source": [
    "### Temporal blocks\n",
    "\n",
    "Note: `tf.contrib.layers.layer_norm` only supports `channels_last`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "9bHYwhRxy-gW"
   },
   "outputs": [],
   "source": [
    "# Redefining CausalConv1D to simplify its return values\n",
    "class CausalConv1D(tf.layers.Conv1D):\n",
    "    def __init__(self, filters,\n",
    "               kernel_size,\n",
    "               strides=1,\n",
    "               dilation_rate=1,\n",
    "               activation=None,\n",
    "               use_bias=True,\n",
    "               kernel_initializer=None,\n",
    "               bias_initializer=tf.zeros_initializer(),\n",
    "               kernel_regularizer=None,\n",
    "               bias_regularizer=None,\n",
    "               activity_regularizer=None,\n",
    "               kernel_constraint=None,\n",
    "               bias_constraint=None,\n",
    "               trainable=True,\n",
    "               name=None,\n",
    "               **kwargs):\n",
    "        super(CausalConv1D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='valid',\n",
    "            data_format='channels_last',\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            trainable=trainable,\n",
    "            name=name, **kwargs\n",
    "        )\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        padding = (self.kernel_size[0] - 1) * self.dilation_rate[0]\n",
    "        inputs = tf.pad(inputs, tf.constant([(0, 0,), (1, 0), (0, 0)]) * padding)\n",
    "        return super(CausalConv1D, self).call(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "re2siwPgy-ga"
   },
   "outputs": [],
   "source": [
    "class TemporalBlock(tf.layers.Layer):\n",
    "    def __init__(self, n_outputs, kernel_size, strides, dilation_rate, dropout=0.2, \n",
    "                 trainable=True, name=None, dtype=None, \n",
    "                 activity_regularizer=None, **kwargs):\n",
    "        super(TemporalBlock, self).__init__(\n",
    "            trainable=trainable, dtype=dtype,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            name=name, **kwargs\n",
    "        )        \n",
    "        self.dropout = dropout\n",
    "        self.n_outputs = n_outputs\n",
    "        self.conv1 = CausalConv1D(\n",
    "            n_outputs, kernel_size, strides=strides, \n",
    "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
    "            name=\"conv1\")\n",
    "        self.conv2 = CausalConv1D(\n",
    "            n_outputs, kernel_size, strides=strides, \n",
    "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
    "            name=\"conv2\")\n",
    "        self.down_sample = None\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        channel_dim = 2\n",
    "        self.dropout1 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "        self.dropout2 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "        if input_shape[channel_dim] != self.n_outputs:\n",
    "            # self.down_sample = tf.layers.Conv1D(\n",
    "            #     self.n_outputs, kernel_size=1, \n",
    "            #     activation=None, data_format=\"channels_last\", padding=\"valid\")\n",
    "            self.down_sample = tf.layers.Dense(self.n_outputs, activation=None)\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.conv1(inputs)\n",
    "        x = tf.contrib.layers.layer_norm(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.contrib.layers.layer_norm(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        if self.down_sample is not None:\n",
    "            inputs = self.down_sample(inputs)\n",
    "        return tf.nn.relu(x + inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 104.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1162.0,
     "status": "ok",
     "timestamp": 1.522634695536E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "-CMZKL1jy-ge",
    "outputId": "05e31b54-3bfa-4049-f538-a20844b15f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 8)\n",
      "[0.94496346 3.170704   1.3703669  0.15042949 0.         0.\n",
      " 1.580966   2.3627877  2.8130584  2.955478  ]\n",
      "[0.         0.         1.7417274  1.2102602  0.         1.4418404\n",
      " 2.9762747  0.24863395 0.30396032 0.        ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() as g:\n",
    "    x = tf.random_normal((32, 10, 4)) # (batch_size, length, channel)\n",
    "    tblock = TemporalBlock(8, 2, 1, 1)\n",
    "    output = tblock(x, training=tf.constant(True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    res = sess.run(output)\n",
    "    print(res.shape)   \n",
    "    print(res[0, :, 0])\n",
    "    print(res[1, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhzHzZtMy-gk"
   },
   "source": [
    "### Temporal convolutional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "GeLztD1Ly-gm"
   },
   "outputs": [],
   "source": [
    "class TemporalConvNet(tf.layers.Layer):\n",
    "    def __init__(self, num_channels, kernel_size=2, dropout=0.2,\n",
    "                 trainable=True, name=None, dtype=None, \n",
    "                 activity_regularizer=None, **kwargs):\n",
    "        super(TemporalConvNet, self).__init__(\n",
    "            trainable=trainable, dtype=dtype,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            name=name, **kwargs\n",
    "        )\n",
    "        self.layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            out_channels = num_channels[i]\n",
    "            self.layers.append(\n",
    "                TemporalBlock(out_channels, kernel_size, strides=1, dilation_rate=dilation_size,\n",
    "                              dropout=dropout, name=\"tblock_{}\".format(i))\n",
    "            )\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        outputs = inputs\n",
    "        for layer in self.layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 104.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1672.0,
     "status": "ok",
     "timestamp": 1.522634708682E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "cRTtl0mey-go",
    "outputId": "e335ba5a-34b1-453b-fea7-224fa3f7c606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 8)\n",
      "[0.        0.        1.3852701 3.395162  3.5055282 2.4379122 1.5352616\n",
      " 4.3767943 1.547796  1.8849642]\n",
      "[0.         0.         3.1234603  0.         0.         0.\n",
      " 0.23531175 5.5649805  0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() as g:\n",
    "    x = tf.random_normal((32, 10, 4)) # (batch_size, length, channel)\n",
    "    tcn = TemporalConvNet([8, 8, 8, 8], 2, 0.25)\n",
    "    output = tcn(x, training=tf.constant(True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    res = sess.run(output)\n",
    "    print(res.shape)   \n",
    "    print(res[0, :, 0])\n",
    "    print(res[1, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 104.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1728.0,
     "status": "ok",
     "timestamp": 1.52263471062E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "zCMhWfWjy-g0",
    "outputId": "9d39a675-debb-41e0-86e5-970c57845079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 8)\n",
      "[0.8632078  1.3778193  0.28429168 1.4425604  1.3253632  0.\n",
      " 0.63085276 0.         3.6162543  2.304384  ]\n",
      "[0.        0.        0.        0.        0.        0.926967  1.2254503\n",
      " 0.        2.5647626 4.733012 ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    Xinput = tf.placeholder(tf.float32, shape=[None, 10, 4])\n",
    "    tcn = TemporalConvNet([8, 8, 8, 8], 2, 0.25)\n",
    "    output = tcn(Xinput, training=tf.constant(True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    res = sess.run(output, {Xinput: np.random.randn(32, 10, 4)})\n",
    "    print(res.shape)   \n",
    "    print(res[0, :, 0])\n",
    "    print(res[1, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jYugVyby-g-"
   },
   "source": [
    "## Sequential MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1300.0,
     "status": "ok",
     "timestamp": 1.522634805178E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "41qAk9lAy-hC",
    "outputId": "a1607a69-b33e-4ef6-e792-360a4b0e250f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per epoch: 859\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "display_step = 500\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "print(\"Number of batches per epoch:\", total_batch)\n",
    "training_steps = 3000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 28 * 28 # timesteps\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.1\n",
    "kernel_size = 8\n",
    "levels = 6\n",
    "nhid = 20 # hidden layer num of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5236.0,
     "status": "ok",
     "timestamp": 1.522636269832E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "bP37UtN5y-hG",
    "outputId": "089539a5-b6c1-4cb0-ca1c-deacde5b3cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters: 108992.0\n",
      "Trainable parameters: 36330\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(10)\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "    is_training = tf.placeholder(\"bool\")\n",
    "    \n",
    "    # Define weights\n",
    "    logits = tf.layers.dense(\n",
    "        TemporalConvNet([nhid] * levels, kernel_size, dropout)(\n",
    "            X, training=is_training)[:, -1, :],\n",
    "        num_classes, activation=None, \n",
    "        kernel_initializer=tf.orthogonal_initializer()\n",
    "    )\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "   \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=logits, labels=Y))\n",
    "    \n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        # gvs = optimizer.compute_gradients(loss_op)\n",
    "        # for grad, var in gvs:\n",
    "        #     if grad is None:\n",
    "        #         print(var)\n",
    "        # capped_gvs = [(tf.clip_by_value(grad, -.5, .5), var) for grad, var in gvs]\n",
    "        # train_op = optimizer.apply_gradients(capped_gvs)    \n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "    # Evaluate model (with test logits, for dropout to be disabled)\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    print(\"All parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.global_variables()]))\n",
    "    print(\"Trainable parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 278.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 416220.0,
     "status": "ok",
     "timestamp": 1.522636686094E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "IjwOnIUmy-hM",
    "outputId": "79b8a85e-9f56-458d-ecc9-3eea13094548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 3.3666, Training Accuracy= 0.188, Test Accuracy= 0.172\n",
      "Step 500, Minibatch Loss= 0.2161, Training Accuracy= 0.938, Test Accuracy= 0.938\n",
      "Model saved in path: ../weights/tcn/model1.ckpt\n",
      "Step 1000, Minibatch Loss= 0.1686, Training Accuracy= 0.953, Test Accuracy= 0.992\n",
      "Model saved in path: ../weights/tcn/model1.ckpt\n",
      "Step 1500, Minibatch Loss= 0.1366, Training Accuracy= 0.969, Test Accuracy= 0.992\n",
      "Step 2000, Minibatch Loss= 0.1438, Training Accuracy= 0.953, Test Accuracy= 1.000\n",
      "Model saved in path: ../weights/tcn/model1.ckpt\n",
      "Step 2500, Minibatch Loss= 0.1324, Training Accuracy= 0.969, Test Accuracy= 1.000\n",
      "Step 3000, Minibatch Loss= 0.1763, Training Accuracy= 0.953, Test Accuracy= 1.000\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "# log_dir = \"logs/tcn/%s\" % datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "# Path(log_dir).mkdir(exist_ok=True, parents=True)\n",
    "# tb_writer = tf.summary.FileWriter(log_dir, graph)\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = False\n",
    "best_val_acc = 0.8\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # print(np.max(batch_x), np.mean(batch_x), np.median(batch_x))\n",
    "        # Reshape data to get 28 * 28 seq of 1 elements\n",
    "        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, is_training: True})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={\n",
    "                X: batch_x, Y: batch_y, is_training: False})\n",
    "            # Calculate accuracy for 128 mnist test images\n",
    "            test_len = 128\n",
    "            test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "            test_label = mnist.test.labels[:test_len]\n",
    "            val_acc = sess.run(accuracy, feed_dict={X: test_data, Y: test_label, is_training: False})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc) + \", Test Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(val_acc))\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                save_path = saver.save(sess, \"../weights/tcn/model1.ckpt\")\n",
    "                print(\"Model saved in path: %s\" % save_path)\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91elDQ4Xy-hS"
   },
   "source": [
    "## Permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "KMtyE5m-97FK"
   },
   "outputs": [],
   "source": [
    "training_steps = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ri6zKrm9Ie30"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4664.0,
     "status": "ok",
     "timestamp": 1.522637824064E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "eWX3IRfR0z5O",
    "outputId": "800eba07-4ffc-492d-d5fc-7906308a9f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters: 108992.0\n",
      "Trainable parameters: 36330\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(10)\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "    is_training = tf.placeholder(\"bool\")\n",
    "    \n",
    "    # Permute the time step\n",
    "    np.random.seed(100)\n",
    "    permute = np.random.permutation(784)\n",
    "    X_shuffled = tf.gather(X, permute, axis=1)\n",
    "    \n",
    "    # Define weights\n",
    "    logits = tf.layers.dense(\n",
    "        TemporalConvNet([nhid] * levels, kernel_size, dropout)(\n",
    "            X_shuffled, training=is_training)[:, -1, :],\n",
    "        num_classes, activation=None, \n",
    "        kernel_initializer=tf.orthogonal_initializer()\n",
    "    )\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "   \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=logits, labels=Y))\n",
    "    \n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        # gvs = optimizer.compute_gradients(loss_op)\n",
    "        # for grad, var in gvs:\n",
    "        #     if grad is None:\n",
    "        #         print(var)\n",
    "        # capped_gvs = [(tf.clip_by_value(grad, -.5, .5), var) for grad, var in gvs]\n",
    "        # train_op = optimizer.apply_gradients(capped_gvs)    \n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "    # Evaluate model (with test logits, for dropout to be disabled)\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    print(\"All parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.global_variables()]))\n",
    "    print(\"Trainable parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 312.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 414232.0,
     "status": "ok",
     "timestamp": 1.52263823852E12,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480.0
    },
    "id": "oprHW-Qry-ha",
    "outputId": "7f544e34-7cb8-44fb-ff2e-8ad3ee669d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 3.7196, Training Accuracy= 0.125, Test Accuracy= 0.062\n",
      "Step 500, Minibatch Loss= 0.3547, Training Accuracy= 0.906, Test Accuracy= 0.906\n",
      "Model saved in path: /tmp/model.ckpt\n",
      "Step 1000, Minibatch Loss= 0.2223, Training Accuracy= 0.922, Test Accuracy= 0.945\n",
      "Model saved in path: /tmp/model.ckpt\n",
      "Step 1500, Minibatch Loss= 0.4307, Training Accuracy= 0.906, Test Accuracy= 0.961\n",
      "Model saved in path: /tmp/model.ckpt\n",
      "Step 2000, Minibatch Loss= 0.1025, Training Accuracy= 0.938, Test Accuracy= 0.977\n",
      "Model saved in path: /tmp/model.ckpt\n",
      "Step 2500, Minibatch Loss= 0.2563, Training Accuracy= 0.891, Test Accuracy= 0.961\n",
      "Step 3000, Minibatch Loss= 0.1184, Training Accuracy= 0.969, Test Accuracy= 0.969\n",
      "Step 3500, Minibatch Loss= 0.1279, Training Accuracy= 0.953, Test Accuracy= 0.969\n",
      "Step 4000, Minibatch Loss= 0.0419, Training Accuracy= 0.984, Test Accuracy= 0.984\n",
      "Model saved in path: /tmp/model.ckpt\n",
      "Step 4500, Minibatch Loss= 0.3604, Training Accuracy= 0.938, Test Accuracy= 0.969\n",
      "Step 5000, Minibatch Loss= 0.0682, Training Accuracy= 0.984, Test Accuracy= 0.977\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "log_dir = \"logs/tcn/%s\" % datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "Path(log_dir).mkdir(exist_ok=True, parents=True)\n",
    "tb_writer = tf.summary.FileWriter(log_dir, graph)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "best_val_acc = 0.8\n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # print(np.max(batch_x), np.mean(batch_x), np.median(batch_x))\n",
    "        # Reshape data to get 28 * 28 seq of 1 elements\n",
    "        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, is_training: True})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={\n",
    "                X: batch_x, Y: batch_y, is_training: False})\n",
    "            # Calculate accuracy for 128 mnist test images\n",
    "            test_len = 128\n",
    "            test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "            test_label = mnist.test.labels[:test_len]\n",
    "            val_acc = sess.run(accuracy, feed_dict={X: test_data, Y: test_label, is_training: False})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc) + \", Test Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(val_acc))\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "                print(\"Model saved in path: %s\" % save_path)\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "chQz9B84y-he"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "tcn_mnist.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
