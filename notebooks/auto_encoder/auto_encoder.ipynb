{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeeOZueJy-fW"
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1220,
     "status": "ok",
     "timestamp": 1522629683286,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "5zj3MnAMy-fq",
    "outputId": "85b5cede-11ac-4182-f7e5-8deffffce67b",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7bc393883e6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/classification/train_features_all.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/classification/val_features_all.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[1;32m--> 433\u001b[1;33m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[1;31m# Try a pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = np.load(\"../data/classification/train_features_all.npy\")\n",
    "val_data = np.load(\"../data/classification/val_features_all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.asarray([ np.asarray(element) for element in train_data[:,0]])\n",
    "val_data = np.asarray([ np.asarray(element) for element in val_data[:,0]])\n",
    "train_data = train_data[:,:128]\n",
    "val_data = val_data[:,:128]\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"../data/cgan/full/train_features_smiles.npy\")\n",
    "val_data = np.load(\"../data/cgan/full/val_features_smiles.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jYugVyby-g-"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1300,
     "status": "ok",
     "timestamp": 1522634805178,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "41qAk9lAy-hC",
    "outputId": "a1607a69-b33e-4ef6-e792-360a4b0e250f"
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001#0.5\n",
    "BATCH_SIZE = 128\n",
    "batches_per_epoch = int(train_data.shape[0]/BATCH_SIZE)+1\n",
    "num_epochs = 3\n",
    "print(\"Number of epochs: {} with batches per epoch: {}\".format(num_epochs, batches_per_epoch))\n",
    "\n",
    "# Network Parameters\n",
    "SEQUENCE_LENGTH=train_data.shape[1]\n",
    "ONE_HOT_LENGTH = train_data.max()+1\n",
    "# embedding_size = 128\n",
    "\n",
    "DROPOUT_RATE = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, layers, is_training):    \n",
    "    with tf.variable_scope('encoder'):\n",
    "        encoded = tf.layers.flatten(x, name=\"flat\")\n",
    "        i = 0\n",
    "        for layer in layers:\n",
    "            encoded = tf.layers.dense(inputs=encoded,\n",
    "                                      activation=tf.nn.selu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      units=layer,\n",
    "                                      name=\"dense{}\".format(i))\n",
    "            i = i+1\n",
    "        encoded = tf.layers.batch_normalization(encoded, name = \"batch_normalization_encoder\")\n",
    "    print(encoded.shape)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x, layers, is_training):\n",
    "    with tf.variable_scope('decoder'):\n",
    "        i = 0\n",
    "        decoded = x\n",
    "        for layer in reversed(layers):            \n",
    "            decoded = tf.layers.dense(inputs=decoded,\n",
    "                                      activation=tf.nn.selu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      units=layer,\n",
    "                                      name=\"dense{}\".format(i))\n",
    "            i = i + 1\n",
    "        decoded = tf.layers.batch_normalization(decoded, name = \"batch_normalization_decoder\")\n",
    "        decoded = tf.layers.dense(inputs=decoded,\n",
    "                                  activation=None,\n",
    "                                  units=SEQUENCE_LENGTH*ONE_HOT_LENGTH,\n",
    "                                  name=\"final_dense\")\n",
    "        decoded = tf.reshape(decoded, shape=[-1, SEQUENCE_LENGTH, ONE_HOT_LENGTH], name='decoded')\n",
    "        print(decoded.shape)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5236,
     "status": "ok",
     "timestamp": 1522636269832,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "bP37UtN5y-hG",
    "outputId": "089539a5-b6c1-4cb0-ca1c-deacde5b3cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1024)\n",
      "(128, 128, 21)\n",
      "All parameters: 16542594.0\n",
      "Trainable parameters: 5512832\n",
      "encoder/dense0/kernel:0(2688, 1024)\n",
      "encoder/dense0/bias:0(1024,)\n",
      "encoder/batch_normalization_encoder/gamma:0(1024,)\n",
      "encoder/batch_normalization_encoder/beta:0(1024,)\n",
      "decoder/batch_normalization_decoder/gamma:0(1024,)\n",
      "decoder/batch_normalization_decoder/beta:0(1024,)\n",
      "decoder/final_dense/kernel:0(1024, 2688)\n",
      "decoder/final_dense/bias:0(2688,)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(10)\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        sequences = tf.placeholder(tf.int32, [None, SEQUENCE_LENGTH], name='sequences')\n",
    "        is_training = tf.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "        dataset = (tf.data.Dataset.from_tensor_slices(sequences)\n",
    "                   .shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "                   .apply(tf.contrib.data.batch_and_drop_remainder(BATCH_SIZE)))    \n",
    "        iterator = dataset.make_initializable_iterator()\n",
    "    \n",
    "    batch_sequences = iterator.get_next()    \n",
    "        \n",
    "    with tf.variable_scope('one_hot'):\n",
    "        one_hot_seq = tf.one_hot(batch_sequences, ONE_HOT_LENGTH)\n",
    "    \n",
    "    encoded = encoder(one_hot_seq, [1024], is_training)\n",
    "    encoded = tf.layers.dropout(encoded, DROPOUT_RATE, name=\"dropout\",training=is_training)\n",
    "    decoded = decoder(encoded, [], is_training)\n",
    "\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    with tf.name_scope(\"loss_op\"):\n",
    "        loss_op = tf.losses.sparse_softmax_cross_entropy(batch_sequences, decoded)\n",
    "        acc, acc_op  = tf.metrics.accuracy(labels=batch_sequences, predictions=tf.argmax(decoded,2))\n",
    "        correct_prediction = tf.equal(tf.argmax(decoded,2, output_type=tf.int32), batch_sequences)\n",
    "        acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"loss_op\", loss_op)\n",
    "    \n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "    \n",
    "    summ = tf.summary.merge_all()\n",
    "    \n",
    "     # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "    #init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    print(\"All parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.global_variables()]))\n",
    "    print(\"Trainable parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()]))\n",
    "    [ print(\"{}{}\".format(x.name, x.shape)) for x in tf.trainable_variables() if \"LayerNorm\" not in x.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(step, loss, acc):\n",
    "    print(\"Step {}, Loss={:.4f}, Accuracy={:.3f}\".format(str(step), loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):    \n",
    "    # Calculate batch loss and accuracy\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    sess.run(iterator.initializer, feed_dict={sequences: val_data})\n",
    "    while True:\n",
    "        try:\n",
    "            # Run optimization\n",
    "            loss, a = sess.run([loss_op, acc], feed_dict={is_training: False})\n",
    "            losses.append(loss)\n",
    "            accuracies.append(a)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    loss_avg = sum(losses)/len(losses)\n",
    "    acc_avg = sum(accuracies)/len(accuracies)\n",
    "    print_progress(\"VALIDATION for epoch {}\".format(epoch), loss_avg, acc_avg)\n",
    "    return acc_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 416220,
     "status": "ok",
     "timestamp": 1522636686094,
     "user": {
      "displayName": "CeShine Lee",
      "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
      "userId": "114938319508229761672"
     },
     "user_tz": -480
    },
    "id": "IjwOnIUmy-hM",
    "outputId": "79b8a85e-9f56-458d-ecc9-3eea13094548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss=3.0380, Accuracy=0.064\n",
      "Step 361, Loss=0.2981, Accuracy=0.945\n",
      "Step 722, Loss=0.1358, Accuracy=0.973\n",
      "Step 1083, Loss=0.0985, Accuracy=0.981\n",
      "Step VALIDATION for epoch 1, Loss=0.0934, Accuracy=0.982\n",
      "Model saved in path: ../logs/auto_encoder/v_128\n",
      "Step 1444, Loss=0.0664, Accuracy=0.990\n",
      "Step 1805, Loss=0.0657, Accuracy=0.988\n",
      "Step 2166, Loss=0.0746, Accuracy=0.987\n",
      "Step 2527, Loss=0.0633, Accuracy=0.989\n",
      "Step VALIDATION for epoch 2, Loss=0.0752, Accuracy=0.985\n",
      "Model saved in path: ../logs/auto_encoder/v_128\n",
      "Step 2888, Loss=0.0487, Accuracy=0.992\n",
      "Step 3249, Loss=0.0586, Accuracy=0.990\n",
      "Step 3610, Loss=0.0500, Accuracy=0.992\n",
      "Step 3971, Loss=0.0503, Accuracy=0.992\n",
      "Step VALIDATION for epoch 3, Loss=0.0683, Accuracy=0.987\n",
      "Model saved in path: ../logs/auto_encoder/v_128\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random \n",
    "from datetime import datetime\n",
    "path = \"../logs/auto_encoder/\"\n",
    "log_dir = \"{}{}\".format(path, datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "Path(log_dir).mkdir(exist_ok=True, parents=True)\n",
    "tb_writer = tf.summary.FileWriter(log_dir, graph)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = False\n",
    "best_val_acc = 0.8\n",
    "sess = tf.Session(graph=graph)\n",
    "# Run the initializer\n",
    "epoch, step = 0, 0\n",
    "sess.run([init, iterator.initializer], feed_dict={sequences: train_data})\n",
    "while epoch < num_epochs:\n",
    "    try: \n",
    "        sess.run(train_op, feed_dict={is_training: True})\n",
    "        step = step +1 \n",
    "        if step % int(batches_per_epoch/4) == 0 or step == 1:\n",
    "            loss, a = sess.run([loss_op, acc], feed_dict={is_training: False})\n",
    "            print_progress(step, loss, a)\n",
    "            [s] = sess.run([summ], feed_dict={is_training: False})\n",
    "            #tb_writer.add_summary(np.mean(loss), step)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        epoch = epoch + 1\n",
    "        val_acc = validation(epoch)           \n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            save_path = saver.save(sess, \"{}{}\".format(path, \"v_128\"))\n",
    "            print(\"Model saved in path: %s\" % save_path)\n",
    "        sess.run(iterator.initializer, feed_dict={sequences: train_data})\n",
    "print(\"Optimization Finished!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seq = val_data[:1]\n",
    "val_seq = np.repeat(val_seq, [BATCH_SIZE], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([iterator.initializer], feed_dict={sequences: val_seq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_to_index = tf.argmax(decoded, axis=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded_smiles = sess.run(decoded_to_index, feed_dict={is_training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  1  8  4 14  7  8  3  6 10 10 15  7 18  6 10 15 18  3  7  6 10 17 13\n",
      " 18 16  1 16 10 18 10 10  1  6  1  6  1 10 16 18  6 17  5  1 10 15 10 18\n",
      " 15 10  5  1  3 18 20  8 10 13  6 12 16 18 16 20 18  6  1 12  9  9  3 10\n",
      " 17 15  1 16 15  1 18 18 17  6  1 17  3  6  8  6 10  4  5  1 10 14 10  1\n",
      " 15  9  6  5 12  8 18 10 18 16 15 16 13  4  9 10  6 16 18  1  1  4  8  4\n",
      "  1  1 17 13  6 18 15 17]\n"
     ]
    }
   ],
   "source": [
    "print(decoded_smiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  1,  8,  4, 14,  7,  8,  3,  6, 10, 10, 15,  7, 18,  6, 10, 15,\n",
       "       18,  3,  7,  6, 10, 17, 13, 18, 16,  1, 16, 10, 18, 10, 10,  1,  6,\n",
       "        8,  6,  1, 10, 16, 18,  6, 17,  5,  1, 10, 15, 10, 18, 15, 10,  5,\n",
       "        1,  3, 18, 20,  8, 10, 13,  6, 12, 16, 18, 16,  9, 20,  6,  1, 12,\n",
       "        9,  9,  3, 10, 17, 15,  1, 16, 19,  1, 18, 18, 17,  6,  1, 17,  3,\n",
       "        6,  8,  6, 15,  4,  5,  1, 10, 14, 10,  1, 15,  9,  6,  5, 12,  8,\n",
       "       18, 10, 18, 16, 15, 16, 13,  4,  9, 10,  6, 16, 18,  1,  1,  4,  8,\n",
       "        4,  1,  1, 17, 13,  6, 18, 15, 17])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIEQHIDGLLRHVGLRVDHGLTPVSASLVLLAGIGALSVGTFALRLVRLFADVYILPGNSVSKYGANKKDLTRASWAVVTGATDGIGREFALQLARKGFNIVLVSRSPEKLGSVAAEIEAATPGVRT\n",
      "MAIEQHIDGLLRHVGLRVDHGLTPVSASLVLLAGAGALSVGTFALRLVRLFADVYILPGNSVSYVGANKKDLTRASRAVVTGATDGIGLEFALQLARKGFNIVLVSRSPEKLGSVAAEIEAATPGVRT\n"
     ]
    }
   ],
   "source": [
    "from common.bio.constants import *\n",
    "print(\"\".join([ ID_TO_AMINO_ACID[acid_index] for acid_index in val_data[0]]))\n",
    "print(\"\".join([ ID_TO_AMINO_ACID[acid_index] for acid_index in decoded_smiles[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "tcn_mnist.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
