{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import json\n",
    "import fastai\n",
    "import math\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"../../data/protein/structure/secondary_structure/\"\n",
    "DATA_PATH = ROOT+\"sample_1_kmers\"\n",
    "MODEL_PATH = \"../../weights/protein/structure/secondary_structure/1_kmers\"\n",
    "SEQUENCE_LENGTH=512\n",
    "VOCAB_SIZE=20\n",
    "BERT_CONFIG_FILE = \"../../../bert/config/bert_config_file.json\"\n",
    "BERT_WEIGHTS = \"../../../bert_pytorch/weights/tpu\"\n",
    "NUM_CLASSES = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "num_workers = 8 # On cloud 8\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnzymeDataSet(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path, seq_length, is_test=True, vocab_size=20, random=False):\n",
    "        self.data = np.load(path)\n",
    "        self.seq_length = seq_length\n",
    "        self.is_test = is_test\n",
    "        self.vocab_size = vocab_size\n",
    "        self.random = random\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data[idx]\n",
    "        seq = np.asarray(row[1])\n",
    "        label = row[0]\n",
    "        if len(seq) > SEQUENCE_LENGTH:\n",
    "            seq = seq[0:512]\n",
    "            label = label[0:512]\n",
    "        mask = np.ones(len(row[1]))\n",
    "        if not self.is_test:\n",
    "            mutations = int(len(seq)*0.05)\n",
    "            np.put(seq, np.random.randint(0, len(seq)-1, mutations), np.random.randint(1, self.vocab_size, mutations))\n",
    "        to_pad = self.seq_length-len(seq)\n",
    "        if self.random:\n",
    "            end_padding = randint(0, to_pad)\n",
    "            begin_padding = to_pad - end_padding\n",
    "            seq = np.pad(seq, mode=\"constant\", pad_width=(begin_padding,end_padding))\n",
    "            mask = np.pad(mask, mode=\"constant\", pad_width=(begin_padding,end_padding))\n",
    "            label = np.pad(label, mode=\"constant\", pad_width=(begin_padding,end_padding))\n",
    "        else:\n",
    "            seq = np.pad(seq, mode=\"constant\", pad_width=(0,to_pad))\n",
    "            mask = np.pad(mask, mode=\"constant\", pad_width=(0,to_pad))\n",
    "            label = np.pad(label, mode=\"constant\", pad_width=(0,to_pad))\n",
    "        return (np.int64(seq) , mask), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ds = EnzymeDataSet(DATA_PATH+\"/train/data.npy\", SEQUENCE_LENGTH, is_test=False, vocab_size=VOCAB_SIZE)\n",
    "val_ds = EnzymeDataSet(DATA_PATH+\"/val/data.npy\", SEQUENCE_LENGTH)\n",
    "test_ds = EnzymeDataSet(DATA_PATH+\"/test/data.npy\", SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import *\n",
    "class BertEnzymeClassification(nn.Module):\n",
    "    def __init__(self, config, num_labels):\n",
    "        super(BertEnzymeClassification, self).__init__()\n",
    "        self.bert = BertModel(config)\n",
    "        self.conv = nn.Conv1d(config.hidden_size, num_labels, 1)\n",
    "\n",
    "        def init_weights(module):\n",
    "            if isinstance(module, (nn.Conv1d)):\n",
    "                # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "                # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "            elif isinstance(module, BERTLayerNorm):\n",
    "                module.beta.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "                module.gamma.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        all_encoder_layers, pooled_output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        logits = self.conv(all_encoder_layers)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from modeling import BertConfig\n",
    "bert_config = BertConfig.from_json_file(BERT_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../bert_pytorch/weights/tpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a2c983b47f43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0menzymeClassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertEnzymeClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0menzymeClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBERT_WEIGHTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0menzymeClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\donatas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../bert_pytorch/weights/tpu'"
     ]
    }
   ],
   "source": [
    "enzymeClassifier = BertEnzymeClassification(bert_config, NUM_CLASSES)\n",
    "enzymeClassifier.bert.load_state_dict(torch.load(BERT_WEIGHTS, map_location='cpu'))\n",
    "enzymeClassifier.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzymeClassifier.bert.embeddings.word_embeddings.weight[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n, p in enzymeClassifier.bert.named_parameters():\n",
    "    if p.requires_grad: \n",
    "        p.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimization import BERTAdam\n",
    "param_optimizer = list(enzymeClassifier.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if n not in no_decay], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if n in no_decay], 'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "train_examples = len(np.load(DATA_PATH+\"/train/data.npy\"))\n",
    "num_train_steps = int(train_examples / batch_size / epochs)\n",
    "optimizer = partial(BERTAdam, params = optimizer_grouped_parameters,\n",
    "                     lr=5e-5,\n",
    "                     warmup=0.1,\n",
    "                     t_total=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.0001, 1, 1, 1, 1, 1, 1, 1, 1]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(p.numel() for p in enzymeClassifier.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fastai.basic_data.DataBunch.create(train_ds=train_ds, valid_ds=val_ds, test_ds=test_ds, bs=batch_size, num_workers=num_workers)\n",
    "learner = fastai.basic_train.Learner(data, enzymeClassifier, \n",
    "        loss_func=criterion, \n",
    "        metrics=fastai.accuracy, \n",
    "        #opt_func=optimizer,\n",
    "        path=None, \n",
    "        model_dir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, truth =learner.get_preds(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai.accuracy(preds, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ (n, p) for n, p in enzymeClassifier.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ n for n, p in enzymeClassifier.named_parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
