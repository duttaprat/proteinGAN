{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import json\n",
    "import fastai\n",
    "import math\n",
    "from functools import partial\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"../../data/protein/structure/secondary_structure/\"\n",
    "DATA_PATH = ROOT+\"cullpdb\"\n",
    "MODEL_PATH = \"../../weights/protein/structure/secondary_structure/cullpdb\"\n",
    "SEQUENCE_LENGTH=512\n",
    "VOCAB_SIZE=20\n",
    "BERT_CONFIG_FILE = \"../../../bert/config/bert_config_file.json\"\n",
    "BERT_WEIGHTS = \"../../../bert_pytorch/weights/tpu\"\n",
    "NUM_CLASSES = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "num_workers = 8 # On cloud 8\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EnzymeDataSet(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path, seq_length, is_test=True, vocab_size=20, random=False):\n",
    "        self.data = np.load(os.path.join(path, \"data.npy\"))\n",
    "        self.mutations = np.load(os.path.join(path, \"mutations_cumsum.npy\"))\n",
    "        self.lengths = np.load(os.path.join(path, \"lengths.npy\"))\n",
    "        self.seq_length = seq_length\n",
    "        self.is_test = is_test\n",
    "        self.vocab_size = vocab_size\n",
    "        self.random = random\n",
    "        self.vocab_size = np.arange(1, vocab_size+1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data[idx]\n",
    "        seq = row[0][0:512]\n",
    "        label =  row[1][0:512]\n",
    "        mutations = self.mutations[idx]\n",
    "        length = min(512,self.lengths[idx])\n",
    "        \n",
    "        if not self.is_test:\n",
    "            mutation_size = int(length*0.2)\n",
    "            indicies = np.sort(np.random.randint(1,length-1, mutation_size))\n",
    "            selected = mutations[indicies]\n",
    "            random_mutation = np.random.rand(len(selected), 1)\n",
    "            mutated_amino_acids = (random_mutation < selected).argmax(axis=1) + 1\n",
    "            np.put(seq, indicies, mutated_amino_acids)\n",
    "            \n",
    "        mask = np.ones(length)\n",
    "        mask = np.pad(mask, mode=\"constant\", pad_width=(0,len(seq)-length))\n",
    "        return (np.int64(seq) , mask), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ds = EnzymeDataSet(os.path.join(DATA_PATH, \"train\"), SEQUENCE_LENGTH, is_test=False, vocab_size=VOCAB_SIZE)\n",
    "val_ds = EnzymeDataSet(os.path.join(DATA_PATH, \"val\"), SEQUENCE_LENGTH)\n",
    "test_ds = EnzymeDataSet(os.path.join(DATA_PATH, \"test\"), SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([11, 15, 18,  6, ...,  0,  0,  0,  0]),\n",
       "  array([1., 1., 1., 1., ..., 0., 0., 0., 0.])),\n",
       " array([2, 3, 3, 3, ..., 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import *\n",
    "class BertEnzymeClassification(nn.Module):\n",
    "    def __init__(self, config, num_labels):\n",
    "        super(BertEnzymeClassification, self).__init__()\n",
    "        self.bert = BertModel(config)\n",
    "        self.conv1 = nn.Conv1d(config.hidden_size, config.hidden_size, 5)\n",
    "        self.padding = nn.ReflectionPad1d((2,2))\n",
    "        self.bn = nn.BatchNorm1d(config.hidden_size)\n",
    "        self.conv2 = nn.Conv1d(config.hidden_size, num_labels, 1)\n",
    "        self.bert_layer = BERTLayer(config)\n",
    "\n",
    "        def init_weights(module):\n",
    "            if isinstance(module, (nn.Conv1d)):\n",
    "                # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "                # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "            elif isinstance(module, BERTLayerNorm):\n",
    "                module.beta.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "                module.gamma.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        all_encoder_layers, pooled_output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        last_encoder_layer = all_encoder_layers[-1]\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        last_encoder_layer = self.bert_layer(last_encoder_layer, attention_mask=extended_attention_mask.float())\n",
    "        print(last_encoder_layer[0][:][0])\n",
    "        last_encoder_layer = self.padding(last_encoder_layer)\n",
    "        output = self.conv1(last_encoder_layer)\n",
    "        output = torch.nn.functional.relu(self.bn(output))\n",
    "        output = self.conv2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from modeling import BertConfig\n",
    "bert_config = BertConfig.from_json_file(BERT_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEnzymeClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BERTEmbeddings(\n",
       "      (word_embeddings): Embedding(22, 512)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(16, 512)\n",
       "      (LayerNorm): BERTLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BERTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BERTPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
       "  (padding): ReflectionPad1d((2, 2))\n",
       "  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv1d(512, 9, kernel_size=(1,), stride=(1,))\n",
       "  (bert_layer): BERTLayer(\n",
       "    (attention): BERTAttention(\n",
       "      (self): BERTSelfAttention(\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (output): BERTSelfOutput(\n",
       "        (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (LayerNorm): BERTLayerNorm()\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BERTIntermediate(\n",
       "      (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    )\n",
       "    (output): BERTOutput(\n",
       "      (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (LayerNorm): BERTLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enzymeClassifier = BertEnzymeClassification(bert_config, NUM_CLASSES)\n",
    "enzymeClassifier.bert.load_state_dict(torch.load(BERT_WEIGHTS, map_location='cpu'))\n",
    "enzymeClassifier.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.01, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enzymeClassifier.bert.embeddings.word_embeddings.weight[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n, p in enzymeClassifier.bert.named_parameters():\n",
    "    if p.requires_grad: \n",
    "        p.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimization import BERTAdam\n",
    "param_optimizer = list(enzymeClassifier.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if n not in no_decay], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if n in no_decay], 'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "train_examples = len(np.load(DATA_PATH+\"/train/data.npy\"))\n",
    "num_train_steps = int(train_examples / batch_size / epochs)\n",
    "optimizer = partial(BERTAdam, params = optimizer_grouped_parameters,\n",
    "                     lr=5e-5,\n",
    "                     warmup=0.1,\n",
    "                     t_total=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([512, 512, 5]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([9, 512, 1]),\n",
       " torch.Size([9]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([2048, 512]),\n",
       " torch.Size([2048]),\n",
       " torch.Size([512, 2048]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in enzymeClassifier.parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4469257"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in enzymeClassifier.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.01, 3.290247, 1.77455 , 1.57773 , 3.032445, 1.      , 3.39651 , 2.58894 , 2.397312]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(input, targs):\n",
    "    \"Compute accuracy with `targs` when `input` is bs * n_classes.\"\n",
    "    mask = (targs > 0)\n",
    "    targs = targs.masked_select(mask)\n",
    "    input = input.argmax(dim=1)\n",
    "    input = input.masked_select(mask)\n",
    "    return (input==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fastai.basic_data.DataBunch.create(train_ds=train_ds, valid_ds=val_ds, test_ds=test_ds, bs=batch_size, num_workers=num_workers)\n",
    "learner = fastai.basic_train.Learner(data, enzymeClassifier, \n",
    "        loss_func=criterion, \n",
    "        metrics=accuracy, \n",
    "        #opt_func=optimizer,\n",
    "        path=None, \n",
    "        model_dir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='88', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.06e-02,  1.45e-03, -1.66e-02,  6.41e-03, -6.14e-03,  5.87e-02,\n",
      "        -2.53e-03, -7.33e-03,  6.58e-02, -1.81e-02,  3.44e-03,  2.67e-02,\n",
      "         8.11e-03, -4.53e-03,  6.11e-02,  6.56e-03,  1.18e-02,  4.02e-02,\n",
      "         1.17e-03,  2.44e-02,  1.56e-02,  2.89e-02,  1.31e-02,  2.49e-03,\n",
      "         3.78e-02,  1.93e-02, -2.53e-02,  4.90e-03, -1.03e-02, -7.42e-02,\n",
      "         5.65e-02, -4.66e-02,  7.00e-03, -4.36e-02,  1.82e-02,  8.37e-03,\n",
      "         1.76e-02,  4.78e-02,  2.72e-02, -2.08e-02,  1.63e-02,  3.32e-02,\n",
      "         4.78e-03,  3.65e-02,  1.44e-03,  2.79e-02,  1.88e-02,  1.26e-02,\n",
      "         3.73e-03, -3.19e-04,  1.30e-02, -3.81e-03, -4.18e-02,  4.07e-02,\n",
      "        -4.75e-04,  9.84e-04, -2.04e-03,  8.63e-03, -7.96e-03, -2.81e-02,\n",
      "        -2.75e-03, -3.11e-03,  3.52e-02,  2.55e-03,  2.64e-03, -1.15e-02,\n",
      "         3.91e-03, -2.12e-02, -1.17e-02,  5.08e-03,  3.44e-03,  3.23e-02,\n",
      "        -4.74e-03, -2.51e-02, -3.25e-02, -3.33e-02,  1.11e-02, -2.89e-02,\n",
      "         8.61e-03, -4.18e-02, -1.36e-02,  9.73e-03,  1.17e-02,  1.16e-01,\n",
      "         1.31e-02,  2.87e-02,  1.00e-02,  4.09e-02,  3.55e-03,  1.06e-02,\n",
      "         1.72e-02,  2.07e-02, -4.64e-02, -3.07e-02,  1.64e-02,  2.11e-02,\n",
      "        -5.71e-02, -2.56e-02,  2.32e-02, -7.65e-03, -5.89e-02,  1.08e-01,\n",
      "         4.47e-02,  1.53e-02,  2.10e-02,  4.44e-03,  4.16e-02, -2.45e-03,\n",
      "        -1.15e-02,  5.60e-02, -3.55e-03,  8.09e-02, -9.80e-03, -2.25e-02,\n",
      "        -9.54e-03, -2.20e-02,  2.35e-02, -6.45e-02,  3.76e-02,  2.77e-02,\n",
      "         3.70e-02,  1.74e-02,  3.58e-03, -1.25e-03,  1.70e-02,  4.58e-02,\n",
      "         3.42e-02,  3.59e-02,  2.88e-02, -3.06e-02, -1.09e-02, -4.35e-02,\n",
      "        -1.57e-02, -1.47e-02, -3.16e-02,  5.16e-03,  1.20e-02,  7.85e-02,\n",
      "        -8.29e-03, -1.46e-02,  6.56e-02, -2.16e-02, -1.39e-02, -1.31e-02,\n",
      "         3.11e-02, -3.17e-02, -1.99e-03,  1.53e-02,  7.30e-02,  7.73e-02,\n",
      "         3.84e-02,  1.28e-02,  2.98e-05,  5.44e-04,  1.55e-02, -1.10e-02,\n",
      "        -1.62e-02,  6.87e-03, -1.37e-02, -5.88e-03, -1.76e-03,  1.64e-02,\n",
      "        -3.81e-03, -1.51e-02,  3.24e-02,  3.42e-02, -1.24e-02, -1.30e-02,\n",
      "        -2.99e-02,  2.25e-03,  4.54e-02, -1.62e-02, -1.61e-03,  5.35e-02,\n",
      "        -1.66e-02,  3.53e-03, -1.87e-02,  8.64e-03, -4.14e-02, -1.29e-02,\n",
      "        -4.87e-02, -1.60e-02, -3.38e-02, -4.52e-02,  3.73e-02, -1.25e-02,\n",
      "        -2.26e-02,  2.49e-03, -2.30e-02, -2.44e-02, -1.14e-03, -1.12e-03,\n",
      "        -3.91e-02, -1.43e-02, -2.74e-02, -5.36e-02,  5.89e-02, -2.21e-02,\n",
      "         2.47e-02,  3.87e-02, -1.50e-02, -2.57e-02, -2.58e-03, -4.67e-03,\n",
      "        -9.03e-03,  2.52e-02,  5.03e-02, -1.75e-02,  2.24e-02, -3.34e-02,\n",
      "        -2.14e-02, -2.34e-02, -3.63e-02,  1.00e-02,  1.93e-02, -6.22e-02,\n",
      "        -3.86e-03,  1.27e-02, -7.00e-03, -9.20e-03, -1.22e-02, -1.07e-02,\n",
      "         3.83e-02,  1.11e-03, -1.34e-03,  3.08e-02,  2.13e-02, -2.58e-02,\n",
      "         3.38e-02,  9.30e-03,  4.35e-03,  1.61e-02,  4.32e-03,  2.58e-03,\n",
      "         3.10e-02,  2.99e-03, -3.36e-02, -3.79e-03,  2.34e-02, -4.24e-02,\n",
      "         1.30e-02,  2.58e-03,  7.99e-03,  1.72e-02, -1.49e-02, -3.23e-02,\n",
      "        -1.79e-02, -1.54e-02,  4.13e-02,  4.27e-02,  2.31e-02,  4.11e-02,\n",
      "        -2.35e-02,  1.76e-03, -3.65e-02,  1.07e-02,  1.61e-02,  2.10e-03,\n",
      "        -2.96e-02, -7.88e-03, -2.99e-02,  7.85e-04, -2.71e-02, -9.96e-03,\n",
      "        -6.31e-02, -1.17e-02,  7.98e-02,  2.74e-02,  8.50e-03,  5.23e-02,\n",
      "         4.14e-02,  1.82e-02,  3.87e-02,  2.65e-02,  4.77e-02, -2.02e-02,\n",
      "        -3.51e-02,  5.03e-03, -2.73e-02, -4.02e-02, -6.56e-03, -2.52e-02,\n",
      "         3.34e-02,  1.08e-02, -1.23e-02, -4.08e-02,  2.77e-02, -2.53e-02,\n",
      "        -3.15e-02,  1.72e-02,  2.84e-02, -3.25e-03, -1.96e-02,  2.03e-02,\n",
      "         2.11e-02,  2.19e-02, -1.93e-02, -5.06e-04, -2.44e-02,  7.08e-03,\n",
      "        -2.10e-02,  2.41e-04,  2.37e-02, -1.68e-02,  1.75e-02,  3.21e-03,\n",
      "         2.47e-02, -1.25e-02, -1.17e-02, -2.10e-02,  6.27e-02,  2.32e-02,\n",
      "         1.54e-02,  5.00e-03, -1.90e-02,  5.92e-03, -3.67e-02,  2.51e-02,\n",
      "         7.34e-03,  2.77e-03, -1.15e-02, -2.91e-03,  4.12e-02, -1.60e-02,\n",
      "         1.42e-02,  4.10e-02, -2.73e-02, -3.82e-02,  1.09e-02, -2.43e-03,\n",
      "        -3.51e-02, -4.29e-03,  5.98e-03,  1.25e-02, -3.86e-02,  3.18e-03,\n",
      "         2.50e-02,  2.04e-02,  3.83e-02, -8.48e-03,  1.27e-02, -4.52e-03,\n",
      "        -3.30e-04, -8.86e-03,  1.03e-04, -8.46e-03,  1.57e-02, -1.04e-02,\n",
      "         2.82e-02, -3.23e-02,  8.41e-02, -4.45e-02, -4.53e-03, -5.81e-03,\n",
      "        -1.29e-02,  2.41e-02, -1.97e-02,  2.61e-02, -3.11e-03,  5.88e-02,\n",
      "        -4.89e-03, -1.82e-02, -2.99e-02,  1.10e-02,  2.20e-04, -2.81e-03,\n",
      "         3.30e-02, -2.88e-02, -1.93e-02, -1.87e-03, -2.91e-02, -6.39e-03,\n",
      "         3.17e-02, -1.79e-02, -4.85e-02,  3.33e-02, -4.05e-02, -2.96e-02,\n",
      "         3.95e-02, -4.35e-03, -2.27e-02,  7.36e-03,  1.40e-02, -2.70e-02,\n",
      "         1.93e-02,  2.11e-02,  4.37e-02, -1.44e-02,  2.18e-02, -3.16e-03,\n",
      "         8.50e-03,  3.10e-02,  3.47e-02, -9.45e-03,  2.94e-02, -1.29e-02,\n",
      "        -1.09e-02,  4.34e-02, -7.98e-04,  3.17e-02,  9.55e-03,  2.34e-02,\n",
      "         3.59e-02, -3.18e-02,  1.06e-02, -1.43e-02, -1.82e-02, -7.47e-04,\n",
      "        -2.51e-02,  2.95e-02, -7.24e-03, -1.34e-02,  4.44e-02,  2.14e-02,\n",
      "         1.84e-03,  1.45e-02,  3.42e-03,  4.80e-02, -2.64e-02,  7.83e-03,\n",
      "        -1.47e-02, -2.86e-03, -2.96e-02, -1.63e-02,  3.55e-02, -4.33e-02,\n",
      "        -1.17e-02,  2.95e-02,  4.32e-02,  3.14e-02,  1.76e-02,  1.16e-01,\n",
      "         2.12e-02, -2.72e-02,  1.04e-02,  3.86e-02, -4.12e-03, -6.88e-03,\n",
      "         8.29e-03, -5.55e-02, -2.55e-02, -3.84e-03, -1.18e-02,  3.01e-02,\n",
      "        -3.67e-02,  3.40e-02, -2.49e-02,  1.04e-02, -7.74e-03, -3.14e-02,\n",
      "        -2.96e-02, -9.85e-02, -1.30e-03, -4.15e-02, -3.72e-03,  2.24e-02,\n",
      "         8.69e-03,  3.86e-04,  5.97e-03,  1.09e-02, -2.52e-02,  2.20e-02,\n",
      "        -2.56e-02,  1.66e-02, -1.05e-02, -1.69e-02,  4.85e-02, -1.86e-02,\n",
      "         6.73e-02, -2.47e-04, -3.94e-02, -4.78e-03,  8.28e-03,  3.72e-02,\n",
      "        -5.24e-04,  2.62e-02,  6.61e-02,  1.95e-02,  3.99e-02,  1.06e-02,\n",
      "        -2.29e-02, -2.28e-03,  4.61e-02, -1.43e-02,  7.24e-02, -1.43e-02,\n",
      "        -1.21e-02, -2.84e-02,  1.82e-02,  4.95e-02,  4.14e-02,  1.65e-02,\n",
      "        -1.28e-02,  2.32e-02,  1.35e-02,  4.00e-02, -6.74e-03, -5.00e-03,\n",
      "         3.99e-02,  8.34e-03, -2.04e-03,  1.80e-02,  2.99e-02,  8.20e-03,\n",
      "        -3.57e-02,  8.10e-03,  4.42e-03, -9.91e-02, -1.43e-02, -1.04e-03,\n",
      "         9.83e-03,  8.77e-03], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 3.98e-02, -6.09e-04,  3.46e-02,  2.60e-02, -2.48e-02,  4.87e-02,\n",
      "        -2.05e-02, -8.24e-03,  6.32e-02, -1.43e-02,  5.21e-03,  2.69e-02,\n",
      "         6.65e-03, -1.75e-04,  1.68e-02,  8.33e-03,  1.11e-02,  4.13e-02,\n",
      "         1.76e-02,  2.39e-02, -2.70e-03,  2.78e-02,  1.56e-02,  5.65e-03,\n",
      "         3.55e-02,  3.16e-02, -3.13e-02, -1.81e-03,  1.32e-02, -7.18e-02,\n",
      "         5.80e-02, -4.25e-02,  1.45e-04, -3.93e-02, -5.23e-03,  7.70e-03,\n",
      "         1.59e-02,  4.50e-02,  3.96e-02, -1.19e-02,  1.65e-02,  9.98e-03,\n",
      "         7.34e-03,  3.55e-02,  1.64e-02,  2.44e-02,  1.86e-02,  1.21e-02,\n",
      "         1.34e-02, -5.18e-03,  2.18e-03,  8.24e-03, -2.70e-02,  2.49e-02,\n",
      "        -2.05e-03, -2.40e-03, -1.05e-02,  8.47e-03, -5.65e-03, -2.91e-02,\n",
      "        -3.20e-03, -1.08e-02,  3.40e-02,  6.57e-03,  6.44e-04, -1.44e-02,\n",
      "         2.94e-03, -1.27e-02, -1.20e-02,  8.66e-03, -3.37e-02,  2.64e-02,\n",
      "        -2.13e-03, -3.59e-02, -2.64e-02, -3.02e-02, -4.98e-03, -2.14e-02,\n",
      "        -6.10e-03, -3.94e-02, -7.11e-03, -3.88e-02,  1.36e-02,  8.72e-02,\n",
      "         1.45e-02,  1.87e-02,  1.19e-02,  3.78e-02,  4.09e-03,  1.06e-02,\n",
      "        -1.37e-02,  2.11e-02, -5.60e-02, -2.80e-02,  1.15e-02,  1.32e-02,\n",
      "        -3.66e-02, -2.40e-02,  3.12e-02, -1.03e-02,  3.52e-03,  5.76e-02,\n",
      "         4.53e-02,  3.05e-02,  2.53e-02,  4.14e-03,  6.38e-02, -3.23e-05,\n",
      "        -2.22e-03,  5.97e-02, -1.49e-02,  7.62e-02, -1.06e-02, -1.12e-02,\n",
      "        -9.99e-03, -2.10e-02,  2.16e-02, -3.76e-02,  3.53e-02,  2.84e-02,\n",
      "         1.22e-02,  1.52e-02,  2.63e-03,  4.43e-03,  2.53e-02,  4.59e-02,\n",
      "         4.24e-02,  3.58e-02,  2.19e-02, -4.01e-02, -1.05e-02, -4.14e-02,\n",
      "        -1.59e-02, -8.14e-03, -2.97e-02, -1.16e-04,  7.71e-03,  6.94e-02,\n",
      "        -1.04e-02, -1.66e-02,  4.95e-02, -1.49e-02,  2.07e-02, -1.21e-02,\n",
      "         3.43e-02, -4.49e-02,  2.79e-03,  1.50e-02,  1.00e-01,  6.91e-02,\n",
      "         5.51e-02,  6.43e-03,  1.45e-03,  2.18e-02,  3.15e-02, -1.06e-02,\n",
      "        -4.30e-03,  6.80e-03, -1.90e-02,  2.14e-03,  1.14e-02,  1.43e-02,\n",
      "        -1.17e-02,  1.34e-02,  1.75e-02,  3.22e-02, -1.22e-02, -1.51e-02,\n",
      "        -3.05e-02,  1.19e-02,  1.58e-02, -1.51e-02,  3.37e-03,  5.92e-02,\n",
      "        -1.67e-02,  3.54e-04, -1.88e-02,  7.16e-03, -3.79e-02, -1.16e-02,\n",
      "        -9.16e-02, -2.38e-02, -5.21e-02, -4.20e-02,  3.70e-02, -2.00e-02,\n",
      "        -2.26e-02,  5.35e-03, -1.53e-02, -2.84e-02, -7.53e-04, -2.95e-02,\n",
      "        -3.93e-02,  2.37e-02, -2.80e-02, -5.41e-02,  4.44e-02, -2.05e-02,\n",
      "         2.95e-03,  2.13e-02, -1.54e-02,  4.65e-03, -8.25e-03, -4.64e-03,\n",
      "        -1.72e-02,  1.91e-02,  3.20e-03, -2.49e-02,  1.51e-02, -3.52e-02,\n",
      "        -3.03e-03, -1.96e-02, -3.52e-02,  1.34e-02,  4.42e-02, -6.01e-02,\n",
      "        -1.51e-03,  2.66e-02, -1.05e-02, -2.09e-03, -1.11e-02, -4.24e-03,\n",
      "         1.84e-02,  1.15e-02,  8.35e-03,  3.34e-02,  1.83e-02, -2.48e-02,\n",
      "         3.42e-02,  8.69e-03,  2.24e-03,  2.15e-03,  5.97e-03,  1.71e-02,\n",
      "         3.54e-02, -8.10e-04, -3.50e-02, -6.32e-03, -4.74e-03, -4.06e-02,\n",
      "         1.21e-02,  3.28e-03,  8.33e-03,  2.44e-02, -1.57e-02, -1.78e-02,\n",
      "        -1.53e-02, -1.50e-02,  2.32e-02,  3.68e-02,  1.85e-02,  3.95e-02,\n",
      "        -2.26e-02,  1.17e-03, -4.85e-03,  9.08e-03,  1.60e-02,  4.66e-03,\n",
      "        -3.04e-02, -8.03e-03, -8.13e-03, -5.18e-04,  2.37e-02, -1.13e-02,\n",
      "        -5.35e-02, -4.08e-03,  7.68e-02,  2.76e-02,  9.84e-03,  3.16e-02,\n",
      "         4.74e-02,  1.86e-02,  1.64e-02,  2.85e-02,  4.94e-02, -6.47e-02,\n",
      "        -3.56e-02,  3.91e-02, -2.15e-02, -3.92e-02, -7.38e-03, -3.27e-02,\n",
      "         2.90e-02,  1.04e-02, -1.52e-02,  2.95e-03,  2.79e-02, -5.48e-02,\n",
      "        -2.80e-02, -1.30e-02,  2.97e-02, -4.31e-03, -2.15e-02,  2.70e-02,\n",
      "         2.18e-02,  2.21e-02, -1.14e-02, -8.35e-02, -1.82e-02,  7.69e-03,\n",
      "         4.56e-03, -5.54e-03,  2.47e-02, -1.76e-02,  1.49e-02,  3.04e-03,\n",
      "         1.96e-02, -1.50e-02, -1.68e-02, -3.14e-02,  5.54e-02,  5.53e-02,\n",
      "         1.90e-02,  1.09e-02, -1.95e-02,  4.73e-03, -5.20e-02,  1.23e-02,\n",
      "         7.34e-03,  5.50e-03, -1.12e-02, -1.42e-02,  4.75e-02, -1.68e-02,\n",
      "         3.86e-02,  4.54e-02, -2.94e-02, -4.46e-02,  1.47e-02, -4.60e-03,\n",
      "        -3.61e-02,  5.67e-03,  1.69e-03,  2.79e-02, -4.04e-02, -6.78e-03,\n",
      "         2.49e-02,  1.84e-02,  2.54e-02, -7.80e-03,  1.25e-02, -5.73e-03,\n",
      "        -3.20e-03, -1.61e-02,  6.47e-03, -8.63e-03,  1.61e-02,  1.09e-02,\n",
      "         2.81e-02, -3.25e-02,  8.71e-02, -4.44e-02, -5.27e-03, -2.28e-02,\n",
      "        -9.08e-03,  2.51e-02, -3.41e-02,  3.04e-02, -8.91e-04,  5.78e-02,\n",
      "        -1.95e-03, -1.76e-02, -3.16e-02,  1.23e-02,  1.23e-02, -7.97e-03,\n",
      "         3.74e-02, -2.90e-02, -1.99e-02, -7.64e-04, -2.46e-02, -1.71e-05,\n",
      "         2.75e-02, -5.20e-02, -8.76e-02,  3.08e-02, -4.01e-02, -2.90e-02,\n",
      "         6.53e-02, -5.13e-03, -3.92e-02,  6.30e-03,  1.59e-02, -4.29e-02,\n",
      "        -3.91e-02,  7.06e-03,  4.62e-02, -1.48e-02,  1.96e-02,  5.94e-03,\n",
      "         2.97e-02,  3.26e-02,  3.98e-02, -9.91e-03,  2.35e-02, -1.65e-02,\n",
      "        -1.21e-02,  4.47e-02, -3.39e-03,  9.37e-03,  6.06e-03,  2.83e-02,\n",
      "         3.69e-02, -1.91e-02,  1.06e-02, -1.02e-02, -1.20e-02,  1.16e-03,\n",
      "        -1.33e-02,  2.47e-02, -8.02e-03, -1.26e-02,  4.01e-02,  1.67e-02,\n",
      "         4.35e-03,  1.48e-02,  3.37e-03,  4.90e-02, -3.14e-02,  1.77e-02,\n",
      "        -3.76e-03, -4.42e-03, -2.91e-02, -1.62e-02,  3.61e-02, -1.83e-02,\n",
      "         2.60e-02,  2.12e-02,  2.88e-02,  3.12e-02,  1.67e-02,  1.26e-01,\n",
      "         3.83e-05, -2.81e-02,  2.42e-02,  3.40e-02, -3.11e-03, -1.56e-02,\n",
      "         2.71e-03, -5.63e-02, -2.58e-02, -8.55e-03,  2.66e-02,  2.42e-02,\n",
      "        -4.24e-02,  3.31e-02, -2.27e-02,  1.08e-03, -1.24e-02, -5.33e-02,\n",
      "        -8.23e-03, -4.52e-02, -5.60e-04, -4.15e-02, -5.78e-03,  1.78e-02,\n",
      "         1.18e-02, -2.49e-04,  3.87e-03,  2.24e-02, -3.37e-02,  1.87e-02,\n",
      "        -1.27e-02,  1.88e-02,  2.72e-03, -1.42e-02,  5.84e-02,  1.41e-02,\n",
      "        -3.58e-02, -3.62e-03, -7.29e-02, -3.40e-03,  7.92e-03,  4.27e-02,\n",
      "         8.40e-04,  2.61e-02,  1.12e-01,  2.26e-02,  6.36e-02, -1.11e-03,\n",
      "        -2.45e-02, -9.21e-03,  2.00e-02, -1.90e-02,  2.69e-02, -1.49e-02,\n",
      "        -1.28e-02, -2.86e-02,  1.21e-02,  5.19e-02,  4.28e-02,  1.36e-02,\n",
      "        -2.12e-02,  1.74e-02,  1.86e-02,  4.28e-02, -2.16e-02, -5.32e-03,\n",
      "         3.62e-02,  2.72e-02, -2.09e-03,  7.75e-04,  2.99e-02,  2.38e-02,\n",
      "        -3.33e-02, -2.15e-03,  3.49e-03, -1.06e-01, -2.05e-02, -3.55e-03,\n",
      "        -1.28e-03,  1.29e-02], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5.25e-02,  4.87e-04, -6.97e-03,  2.36e-02, -1.85e-02,  5.17e-02,\n",
      "         3.22e-02,  1.51e-03,  6.31e-02, -1.48e-02,  7.49e-03,  2.69e-02,\n",
      "         6.34e-03,  1.02e-02,  6.78e-02,  1.11e-02,  5.65e-04,  4.07e-02,\n",
      "         4.16e-02,  2.05e-02, -1.09e-02,  3.13e-02,  1.43e-02,  1.19e-02,\n",
      "         3.59e-02,  3.73e-02, -3.16e-02, -1.08e-03,  8.17e-04, -7.01e-02,\n",
      "         5.47e-02, -3.01e-02,  7.61e-03, -4.13e-02,  7.63e-03,  7.41e-03,\n",
      "         1.36e-02,  3.31e-02,  4.18e-02, -1.71e-02,  1.66e-02, -6.90e-03,\n",
      "        -5.72e-03,  3.54e-02,  1.10e-02,  2.45e-02,  1.82e-02,  1.23e-02,\n",
      "         5.09e-03, -5.28e-03,  4.43e-03,  4.95e-03, -2.28e-02,  1.89e-02,\n",
      "        -5.45e-03, -4.74e-03, -1.21e-02,  8.35e-03,  1.63e-03, -2.37e-02,\n",
      "         2.02e-04, -4.76e-03,  4.16e-02,  7.38e-03,  1.00e-02, -1.70e-02,\n",
      "         3.48e-03, -1.93e-02, -1.18e-02,  1.13e-02,  1.11e-02,  2.44e-02,\n",
      "        -2.53e-03, -5.83e-03, -2.50e-02, -3.10e-02,  7.47e-03, -2.65e-02,\n",
      "        -2.86e-03, -3.79e-02, -2.97e-03, -3.06e-02,  1.18e-02,  5.59e-02,\n",
      "         3.14e-02,  2.40e-02,  1.06e-02,  3.80e-02,  3.77e-03,  9.83e-03,\n",
      "         4.63e-02,  2.17e-02, -3.86e-02, -2.58e-02,  1.58e-02,  1.23e-02,\n",
      "        -3.10e-02, -2.46e-02,  5.58e-04, -1.29e-02, -1.02e-02,  9.68e-02,\n",
      "         3.77e-02,  1.80e-02,  3.02e-02,  3.49e-03,  6.27e-02, -8.89e-03,\n",
      "         3.26e-03,  6.51e-02, -9.29e-03,  7.64e-02, -9.41e-03, -2.51e-02,\n",
      "        -3.91e-03, -1.89e-02,  2.23e-02, -5.92e-02,  2.99e-02,  2.87e-02,\n",
      "         4.04e-02,  1.69e-02,  5.70e-03, -7.44e-05,  2.33e-02,  8.41e-02,\n",
      "         4.61e-02,  2.59e-02,  3.05e-02, -3.09e-02, -1.02e-02, -4.24e-02,\n",
      "        -1.42e-02, -1.35e-02, -2.81e-02,  4.90e-03,  6.94e-03,  5.29e-02,\n",
      "        -7.35e-03, -1.66e-02,  6.28e-02, -9.27e-03,  1.49e-02, -9.05e-03,\n",
      "         3.24e-02, -2.24e-02,  3.32e-03,  1.47e-02,  8.63e-02,  7.38e-02,\n",
      "        -4.43e-03,  3.87e-03,  4.85e-04, -4.74e-03,  2.87e-02, -9.14e-03,\n",
      "        -7.46e-03,  8.69e-03,  2.27e-03,  7.00e-03,  9.43e-03,  1.56e-02,\n",
      "         2.97e-03,  1.92e-02,  2.32e-02,  2.78e-02, -1.76e-02, -1.16e-02,\n",
      "        -2.62e-02,  1.47e-02,  1.12e-02, -1.45e-02,  7.70e-04,  6.96e-02,\n",
      "        -4.74e-03,  2.64e-03, -1.86e-02,  8.12e-03, -3.97e-02, -1.05e-02,\n",
      "        -4.80e-02, -1.70e-02, -4.20e-02, -4.41e-02,  3.70e-02, -1.49e-02,\n",
      "        -2.28e-02, -4.40e-03, -1.87e-02, -2.83e-02, -1.53e-03, -3.74e-02,\n",
      "        -3.66e-02, -3.18e-02, -2.71e-02, -5.59e-02,  3.24e-02, -2.14e-02,\n",
      "         9.21e-03,  4.42e-02, -1.17e-02, -3.94e-02, -5.91e-03, -4.58e-03,\n",
      "        -1.54e-02,  2.45e-02,  1.08e-02, -1.95e-02,  1.62e-02, -2.15e-02,\n",
      "        -9.79e-03, -2.85e-02, -3.65e-02,  8.12e-03,  3.26e-02, -7.45e-02,\n",
      "         4.14e-03,  2.22e-02, -1.44e-02, -3.75e-03, -2.43e-02, -1.50e-02,\n",
      "         1.08e-02,  8.42e-03, -7.96e-03,  3.10e-02,  1.79e-02, -2.52e-02,\n",
      "         1.40e-02,  5.66e-03, -1.59e-04,  1.23e-03,  2.17e-03, -6.76e-03,\n",
      "         3.45e-02,  5.51e-04, -2.14e-02, -4.39e-03, -9.13e-05, -4.10e-02,\n",
      "         1.27e-02,  3.53e-03,  8.01e-03,  2.49e-02, -1.31e-02, -1.88e-02,\n",
      "        -1.17e-02, -1.69e-02, -9.08e-04,  4.83e-02,  2.22e-02,  3.38e-02,\n",
      "        -1.82e-02,  2.11e-02, -3.18e-02,  9.44e-03,  1.61e-02, -8.93e-04,\n",
      "        -2.93e-02, -7.51e-03, -4.10e-02, -9.91e-04,  3.41e-02,  1.27e-02,\n",
      "        -4.52e-02, -2.65e-02,  8.15e-02,  2.53e-02,  7.64e-03,  1.58e-02,\n",
      "         4.96e-02,  1.79e-02,  2.87e-02,  3.10e-02,  5.16e-02, -3.50e-02,\n",
      "        -3.57e-02,  1.40e-02, -2.91e-02, -4.16e-02, -7.41e-03, -2.49e-02,\n",
      "         2.86e-02,  7.70e-03, -1.48e-02, -2.55e-02,  2.79e-02, -7.21e-03,\n",
      "        -4.15e-02,  1.92e-02,  3.01e-02, -3.18e-03, -1.75e-02,  3.03e-02,\n",
      "         2.56e-02,  2.24e-02, -1.98e-02,  1.49e-02, -2.49e-02,  7.59e-03,\n",
      "        -2.06e-02, -2.22e-02,  2.76e-02, -1.78e-02,  1.55e-02,  2.23e-03,\n",
      "         1.97e-02, -1.84e-02, -5.71e-03, -3.23e-02,  5.80e-02,  4.95e-02,\n",
      "         1.89e-02, -2.93e-04, -2.57e-02,  5.68e-03, -4.26e-02,  2.36e-02,\n",
      "         5.35e-03,  4.76e-03, -1.13e-02, -2.86e-03,  4.58e-02, -1.69e-02,\n",
      "         5.21e-02,  4.91e-02, -3.03e-02, -1.96e-02,  1.18e-02, -7.62e-03,\n",
      "        -3.87e-02,  9.91e-03,  2.22e-02,  1.82e-02, -4.13e-02,  1.01e-02,\n",
      "         2.60e-02,  2.20e-02,  2.34e-02, -3.92e-03,  1.24e-02, -5.79e-03,\n",
      "         6.68e-03, -3.23e-02,  1.90e-02, -1.11e-02,  1.61e-02,  5.22e-03,\n",
      "         2.80e-02, -3.19e-02,  7.58e-02, -4.45e-02, -5.14e-03, -4.36e-02,\n",
      "        -1.38e-02,  1.27e-02, -2.62e-02,  2.44e-02, -3.63e-03,  5.86e-02,\n",
      "        -7.50e-03, -1.89e-02, -3.23e-02,  2.36e-02,  1.20e-02, -2.34e-03,\n",
      "         3.74e-02, -2.87e-02, -1.95e-02, -1.25e-03, -2.82e-02,  2.02e-03,\n",
      "         2.85e-02, -1.23e-01, -6.59e-02,  3.42e-02, -4.02e-02, -3.15e-02,\n",
      "         4.65e-03, -4.34e-03, -2.87e-02,  7.43e-03,  1.42e-02, -4.68e-02,\n",
      "        -1.12e-02,  1.25e-02,  4.87e-02, -1.52e-02,  2.38e-02, -8.15e-03,\n",
      "         3.02e-02,  1.58e-02,  4.57e-02, -9.68e-03,  3.33e-02, -8.78e-03,\n",
      "        -1.64e-02,  2.90e-02, -1.45e-02,  4.36e-02,  7.31e-03,  2.05e-02,\n",
      "         3.55e-02, -3.08e-02,  1.19e-02, -9.30e-03, -2.52e-02, -1.71e-02,\n",
      "        -2.94e-02,  1.96e-02, -7.70e-03,  1.61e-02,  3.08e-02,  1.78e-02,\n",
      "         2.13e-03,  1.73e-02,  6.12e-03,  6.00e-02, -3.26e-02,  2.66e-02,\n",
      "        -1.70e-02, -4.50e-03, -2.96e-02, -1.75e-02,  3.56e-02, -2.04e-02,\n",
      "         6.34e-03,  6.83e-03,  3.46e-02,  2.97e-02,  1.49e-02,  7.40e-03,\n",
      "        -1.47e-02, -3.13e-02,  1.86e-03,  3.90e-02, -3.63e-03, -1.61e-02,\n",
      "         8.10e-03, -5.61e-02, -2.60e-02, -1.79e-02, -1.78e-02,  2.74e-02,\n",
      "        -2.76e-02,  3.46e-02, -3.12e-02, -3.21e-03, -8.80e-03, -6.30e-02,\n",
      "        -5.74e-02, -8.30e-02, -1.54e-03, -5.07e-02, -5.86e-03,  1.70e-02,\n",
      "         1.03e-02,  2.16e-03,  5.69e-03,  1.15e-02, -2.79e-02,  1.73e-02,\n",
      "        -1.89e-02,  1.52e-02, -1.17e-02, -1.76e-02,  5.82e-02, -6.19e-03,\n",
      "        -3.13e-02,  2.01e-03, -4.26e-02, -2.23e-02,  2.83e-03,  4.67e-02,\n",
      "        -9.75e-03,  2.41e-02,  8.30e-02,  2.29e-02,  4.87e-02,  8.70e-03,\n",
      "        -2.63e-02, -3.91e-03,  1.95e-02, -2.13e-02,  5.49e-02, -1.21e-02,\n",
      "        -1.39e-02, -2.88e-02,  1.30e-02,  5.19e-02,  4.33e-02,  2.56e-02,\n",
      "        -2.28e-02,  2.00e-02,  1.27e-02,  4.18e-02, -1.21e-02, -7.55e-03,\n",
      "         5.55e-02,  1.04e-02, -2.29e-03, -9.48e-04,  2.96e-02,  2.01e-02,\n",
      "        -3.78e-02,  6.00e-04,  2.05e-03, -1.14e-01, -1.75e-02, -7.48e-03,\n",
      "        -2.53e-03,  1.22e-02], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 5.63e-02,  3.37e-03,  2.43e-03,  1.83e-02,  4.04e-03,  5.46e-02,\n",
      "        -2.94e-03,  1.34e-02,  6.20e-02, -1.24e-02,  7.15e-03,  2.70e-02,\n",
      "         1.26e-02,  5.30e-03,  5.11e-02,  1.05e-02,  2.03e-03,  4.14e-02,\n",
      "         4.29e-02,  2.71e-02,  1.88e-02,  2.72e-02,  1.27e-02,  1.40e-02,\n",
      "         2.21e-02,  2.96e-02, -5.44e-03,  3.60e-03,  1.05e-02, -6.64e-02,\n",
      "         4.28e-02, -2.91e-02,  7.94e-03, -3.52e-02, -1.04e-02,  6.59e-03,\n",
      "         1.56e-02,  2.41e-02,  3.41e-02, -3.83e-03,  1.69e-02,  3.56e-02,\n",
      "         1.26e-02,  3.45e-02,  7.89e-03,  2.45e-02,  1.83e-02,  1.28e-02,\n",
      "         3.80e-03, -1.06e-02,  1.31e-02,  6.61e-03, -1.50e-02,  3.42e-02,\n",
      "         1.02e-03,  1.89e-03, -8.78e-03,  8.58e-03,  1.00e-02, -1.95e-02,\n",
      "         1.37e-03, -1.33e-02,  3.00e-02,  1.17e-03,  5.91e-03, -1.96e-02,\n",
      "         3.72e-03, -5.39e-02, -1.14e-02,  7.79e-03, -1.73e-02,  2.21e-02,\n",
      "        -3.73e-03, -1.56e-02, -2.23e-02, -3.07e-02,  4.04e-04, -2.66e-02,\n",
      "         5.35e-04, -3.90e-02, -6.86e-03, -2.74e-02,  1.22e-02,  3.52e-02,\n",
      "         1.23e-02,  1.59e-02,  1.32e-02,  3.30e-02,  3.49e-03,  1.91e-02,\n",
      "         6.01e-02,  2.47e-02, -4.13e-02, -1.61e-02,  2.05e-02,  1.75e-02,\n",
      "        -1.12e-02, -2.25e-02,  1.63e-02, -9.50e-03,  1.64e-02,  5.11e-02,\n",
      "         4.12e-02,  1.58e-02,  3.49e-02,  2.69e-03,  3.24e-02,  2.19e-03,\n",
      "         1.02e-02,  5.26e-02, -3.29e-03,  7.27e-02, -1.53e-02, -1.38e-02,\n",
      "        -7.02e-03, -2.04e-02,  2.38e-02, -4.73e-02,  3.15e-02,  2.78e-02,\n",
      "         2.00e-02,  1.76e-02, -1.78e-04,  5.00e-03,  2.50e-02,  6.66e-02,\n",
      "         5.49e-02,  3.74e-02,  3.22e-02, -2.34e-02, -1.01e-02, -4.07e-02,\n",
      "        -1.43e-02, -1.45e-02, -2.92e-02,  1.10e-02,  6.24e-03, -1.68e-02,\n",
      "        -5.97e-03, -1.44e-02,  5.08e-02, -1.15e-02,  1.64e-02, -1.21e-02,\n",
      "         3.46e-02, -3.90e-02,  1.32e-03,  1.52e-02,  9.14e-02,  8.13e-02,\n",
      "         2.04e-02,  1.09e-02,  3.27e-03, -1.65e-04,  2.31e-02, -7.52e-03,\n",
      "        -3.25e-03,  3.64e-03, -1.02e-02,  6.91e-03,  2.00e-02,  1.56e-02,\n",
      "         1.13e-02,  1.25e-02,  1.95e-02,  3.12e-02, -1.52e-02, -1.05e-02,\n",
      "        -2.87e-02, -4.66e-04,  3.45e-02, -1.13e-02, -1.37e-03,  5.46e-02,\n",
      "        -1.77e-02,  4.75e-03, -1.86e-02,  5.70e-03, -3.61e-02, -1.04e-02,\n",
      "         1.18e-02, -1.87e-02, -2.29e-02, -4.06e-02,  3.38e-02, -1.68e-02,\n",
      "        -2.31e-02, -5.44e-03, -2.47e-02, -2.78e-02, -1.97e-03, -4.39e-02,\n",
      "        -3.95e-02, -6.77e-02, -2.69e-02, -5.27e-02,  4.73e-02, -2.12e-02,\n",
      "         1.21e-02,  4.92e-02, -1.09e-02, -2.07e-02,  2.53e-03, -4.43e-03,\n",
      "        -5.09e-03,  1.21e-02,  1.11e-02, -2.56e-02,  2.06e-02, -2.73e-02,\n",
      "        -6.27e-05, -3.58e-02, -3.50e-02,  1.03e-02,  2.01e-02, -6.02e-02,\n",
      "         1.94e-02,  5.66e-03, -1.42e-02, -1.62e-02, -9.83e-03, -2.28e-02,\n",
      "         6.04e-03,  2.46e-02, -1.31e-02,  3.92e-02,  1.85e-02, -2.53e-02,\n",
      "         2.02e-02, -2.48e-04,  8.95e-04,  1.20e-02,  1.01e-02, -3.26e-03,\n",
      "         3.22e-02, -1.55e-03, -2.78e-02, -8.28e-03,  7.13e-03, -3.88e-02,\n",
      "         1.27e-02,  3.61e-03,  8.15e-03,  9.04e-03, -1.17e-02, -2.76e-02,\n",
      "        -1.52e-02, -1.83e-02,  1.93e-02,  3.79e-02,  2.21e-02,  4.57e-02,\n",
      "        -2.27e-02,  1.41e-02, -8.23e-03,  6.59e-03,  1.55e-02,  4.73e-03,\n",
      "        -2.68e-02, -1.10e-02, -2.89e-02,  9.44e-04,  2.88e-02,  3.81e-02,\n",
      "        -5.17e-02,  7.99e-03,  1.07e-01,  2.55e-02,  8.22e-03,  8.67e-03,\n",
      "         4.50e-02,  1.74e-02,  3.77e-02,  2.71e-02,  4.99e-02, -1.84e-02,\n",
      "        -3.62e-02,  1.57e-02, -2.86e-02, -4.20e-02, -8.93e-03, -1.53e-02,\n",
      "         1.30e-02,  8.11e-03, -1.74e-02, -1.58e-02,  2.80e-02, -1.23e-02,\n",
      "        -2.07e-02,  4.49e-03,  2.95e-02, -4.93e-03, -2.69e-02,  3.08e-02,\n",
      "         2.14e-02,  2.26e-02, -2.26e-02, -5.03e-02, -2.46e-02,  7.32e-03,\n",
      "        -2.65e-02,  2.90e-03,  2.82e-02, -1.77e-02,  1.60e-02,  2.16e-04,\n",
      "         1.71e-02, -1.50e-02, -2.33e-02, -3.44e-02,  4.13e-02,  3.84e-02,\n",
      "         1.94e-02,  1.45e-03, -2.94e-02,  2.95e-03, -4.36e-02,  1.91e-02,\n",
      "         4.30e-03,  2.81e-03, -1.37e-02, -1.35e-02,  3.19e-02, -1.77e-02,\n",
      "        -4.51e-03,  5.66e-02, -3.49e-02, -8.82e-02,  7.86e-03, -2.08e-02,\n",
      "        -4.03e-02,  1.26e-03,  1.40e-02,  2.11e-02, -4.15e-02, -8.43e-03,\n",
      "         2.49e-02,  2.15e-02,  3.41e-02, -7.15e-03,  1.21e-02, -6.49e-03,\n",
      "        -5.54e-03, -1.50e-02,  2.99e-02, -1.27e-02,  1.60e-02,  1.15e-02,\n",
      "         2.78e-02, -3.37e-02,  7.65e-02, -4.43e-02, -4.04e-03, -3.41e-02,\n",
      "        -1.19e-02,  3.74e-02, -3.80e-02,  2.18e-02, -4.41e-03,  5.79e-02,\n",
      "        -4.42e-03, -2.65e-02, -3.34e-02,  7.41e-03,  1.75e-02, -1.99e-02,\n",
      "         3.70e-02, -2.90e-02, -1.93e-02, -1.25e-03, -2.91e-02,  2.26e-05,\n",
      "         2.30e-02,  6.06e-03, -5.71e-02,  3.42e-02, -4.65e-02, -3.19e-02,\n",
      "        -3.77e-03, -5.76e-03, -3.89e-02,  1.05e-02,  1.21e-02, -5.21e-02,\n",
      "        -1.10e-02,  8.64e-03,  4.13e-02, -1.49e-02,  1.78e-02, -6.75e-03,\n",
      "         8.63e-03,  1.14e-02,  2.25e-02, -1.01e-02,  3.09e-02, -6.59e-03,\n",
      "        -1.27e-02,  1.93e-02, -2.32e-02,  2.51e-02,  1.14e-02,  1.94e-02,\n",
      "         3.26e-02, -2.55e-02,  1.13e-02, -1.44e-02,  2.38e-02,  4.90e-03,\n",
      "        -3.17e-02,  1.86e-02, -9.85e-03, -3.91e-02,  3.77e-02,  9.60e-03,\n",
      "         3.14e-03,  1.54e-02,  2.45e-03,  4.82e-02, -3.47e-02,  2.76e-02,\n",
      "        -1.16e-02, -4.90e-03, -3.05e-02, -1.77e-02,  3.52e-02, -2.65e-02,\n",
      "        -1.85e-03,  2.61e-02,  2.33e-02,  3.14e-02,  1.78e-02,  7.18e-02,\n",
      "        -1.27e-03, -3.00e-02,  6.96e-04,  3.54e-02, -3.26e-03, -2.06e-02,\n",
      "         1.13e-02, -5.70e-02, -2.63e-02, -1.74e-02,  8.27e-02,  3.41e-02,\n",
      "        -5.03e-02,  3.03e-02, -4.10e-02,  5.44e-03, -7.96e-03, -3.23e-02,\n",
      "        -1.99e-02, -9.63e-02, -9.40e-04, -6.12e-02, -9.09e-03,  1.44e-02,\n",
      "         1.11e-02, -4.57e-04,  4.48e-03,  1.17e-02, -3.46e-02,  1.73e-02,\n",
      "        -1.84e-02,  1.41e-02, -8.40e-03, -4.77e-02,  5.34e-02, -3.54e-02,\n",
      "        -1.60e-02,  4.63e-04, -6.18e-02, -1.15e-02,  7.11e-03,  4.19e-02,\n",
      "         3.51e-03,  2.35e-02,  7.19e-02,  1.78e-02,  4.70e-02,  2.07e-03,\n",
      "        -2.48e-02, -1.17e-02,  6.96e-03, -3.14e-02,  4.85e-02, -1.55e-02,\n",
      "        -1.45e-02, -2.90e-02,  1.18e-02,  6.08e-02,  4.10e-02,  2.96e-02,\n",
      "        -2.74e-02,  1.73e-02,  1.37e-02,  4.04e-02, -1.79e-02, -9.85e-03,\n",
      "         4.26e-02,  1.08e-02, -2.36e-03, -8.99e-03,  2.96e-02,  1.74e-02,\n",
      "        -3.62e-02, -1.05e-02,  2.00e-03, -1.11e-01, -3.82e-02,  3.52e-03,\n",
      "        -6.98e-03,  7.43e-03], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.94e-02,  4.47e-03,  1.87e-02,  1.75e-02,  1.21e-02,  6.13e-02,\n",
      "         4.89e-02, -7.91e-03,  6.34e-02, -1.26e-02,  1.04e-02,  2.69e-02,\n",
      "         1.84e-02,  1.70e-02,  3.10e-02,  1.23e-02,  1.61e-02,  3.93e-02,\n",
      "         2.85e-02,  2.73e-02,  1.42e-03,  3.43e-02,  1.68e-02, -1.61e-02,\n",
      "         3.83e-02,  3.49e-02, -1.67e-02,  1.26e-02,  1.87e-02, -6.21e-02,\n",
      "         4.68e-02, -2.13e-02,  1.22e-02, -3.92e-02,  3.56e-03,  8.02e-03,\n",
      "         1.68e-02,  4.40e-02,  4.75e-02, -5.29e-03,  1.72e-02,  2.96e-03,\n",
      "         1.15e-02,  3.45e-02,  1.56e-02,  1.77e-02,  1.77e-02,  1.29e-02,\n",
      "         3.88e-03, -1.03e-02,  6.31e-03,  5.46e-03, -1.25e-02,  1.29e-02,\n",
      "         1.25e-02,  6.05e-03, -1.31e-02,  8.82e-03,  1.11e-02, -1.83e-02,\n",
      "         2.54e-03, -9.69e-03,  3.62e-02, -1.20e-04,  1.02e-02, -6.98e-03,\n",
      "         5.71e-03, -2.63e-02, -1.13e-02,  1.09e-02, -3.28e-02,  2.27e-02,\n",
      "        -3.86e-03, -3.41e-03, -1.74e-02, -2.85e-02,  3.66e-03, -2.38e-02,\n",
      "        -1.33e-03, -3.77e-02, -5.70e-03,  1.78e-02,  1.29e-02,  4.83e-02,\n",
      "         1.03e-02,  3.20e-02,  1.08e-02,  3.63e-02,  5.33e-03,  1.83e-02,\n",
      "         1.42e-03,  2.44e-02, -2.28e-02, -1.56e-02,  2.35e-02,  2.72e-02,\n",
      "        -1.04e-02, -2.25e-02,  1.98e-02, -7.03e-03,  1.90e-02,  1.00e-01,\n",
      "         3.64e-02,  1.78e-02,  4.32e-02,  6.47e-03,  9.00e-03,  1.36e-02,\n",
      "        -1.94e-04,  5.91e-02, -6.33e-03,  5.85e-02, -8.85e-03, -1.23e-02,\n",
      "        -1.85e-03, -1.68e-02,  2.12e-02, -3.33e-02,  3.46e-02,  2.77e-02,\n",
      "         1.45e-02,  1.90e-02,  1.21e-02,  2.57e-02,  2.62e-02,  4.29e-02,\n",
      "         5.43e-02,  3.51e-02,  3.23e-02, -2.84e-02, -1.01e-02, -4.15e-02,\n",
      "        -1.54e-02, -1.29e-02, -2.71e-02, -1.23e-02,  8.15e-03,  9.98e-02,\n",
      "        -6.18e-03, -7.91e-03,  5.30e-02, -6.54e-03,  2.23e-02, -4.68e-03,\n",
      "         3.29e-02, -1.95e-02,  3.86e-03,  1.55e-02,  9.79e-02,  8.18e-02,\n",
      "         3.15e-02,  6.83e-03,  2.16e-03,  3.08e-03,  3.85e-02, -6.69e-03,\n",
      "        -8.50e-03,  4.46e-03,  7.93e-03,  8.06e-03,  8.87e-03,  1.01e-02,\n",
      "        -1.30e-02,  1.32e-02,  2.19e-02,  3.11e-02, -1.61e-02, -1.60e-02,\n",
      "        -2.92e-02,  3.45e-03,  2.04e-02, -8.04e-03, -9.98e-04,  5.27e-02,\n",
      "        -1.24e-02,  2.14e-03, -1.85e-02,  5.84e-03, -3.25e-02, -6.77e-03,\n",
      "        -2.69e-02, -8.94e-03, -3.24e-02, -4.21e-02,  3.68e-02, -1.61e-02,\n",
      "        -2.29e-02, -6.64e-03, -1.72e-02, -3.12e-02,  1.66e-04, -1.61e-02,\n",
      "        -3.76e-02,  1.54e-02, -3.52e-02, -5.20e-02,  4.50e-02, -1.99e-02,\n",
      "         1.04e-02,  4.77e-02, -1.16e-02,  4.51e-03, -2.73e-04, -4.57e-03,\n",
      "        -2.36e-03,  4.34e-03, -9.05e-03, -2.48e-02,  2.35e-02, -2.09e-02,\n",
      "        -1.89e-02, -3.02e-02, -3.52e-02,  1.93e-02,  1.75e-02, -7.55e-02,\n",
      "         7.81e-03, -2.53e-02, -1.31e-02, -8.87e-03, -1.37e-02, -1.30e-02,\n",
      "         2.96e-02,  1.22e-02, -1.01e-02,  3.09e-02,  1.61e-02, -2.60e-02,\n",
      "         3.43e-02,  2.88e-03,  3.26e-03, -3.57e-04,  8.45e-03, -1.04e-02,\n",
      "         2.13e-02,  1.93e-03, -2.66e-02, -5.73e-03,  2.67e-03, -3.93e-02,\n",
      "         1.27e-02,  3.56e-03,  8.06e-03,  1.57e-02, -1.43e-02, -2.31e-02,\n",
      "        -1.74e-02, -1.83e-02, -1.18e-03,  4.38e-02,  2.02e-02,  3.75e-02,\n",
      "        -1.62e-02,  2.74e-02, -5.72e-03,  5.30e-03,  1.54e-02,  1.02e-03,\n",
      "        -2.71e-02, -7.31e-03, -2.88e-02,  1.08e-03,  4.17e-02, -3.23e-02,\n",
      "        -5.59e-02, -1.44e-02,  1.18e-01,  2.57e-02,  1.04e-02,  5.37e-03,\n",
      "         4.64e-02,  1.66e-02,  4.11e-02,  3.07e-02,  4.74e-02, -7.27e-02,\n",
      "        -3.57e-02,  1.49e-02, -2.61e-02, -4.21e-02, -7.98e-03,  1.62e-03,\n",
      "         2.31e-02,  6.82e-03, -2.07e-02, -1.72e-02,  2.80e-02, -6.15e-02,\n",
      "        -2.84e-02, -1.07e-02,  2.96e-02, -4.02e-03, -1.61e-02,  2.88e-02,\n",
      "         2.25e-02,  2.26e-02, -2.05e-02, -6.07e-02, -2.93e-02,  7.54e-03,\n",
      "        -2.77e-02,  7.76e-03,  2.88e-02, -1.75e-02,  1.48e-02,  1.55e-03,\n",
      "         1.47e-02, -2.17e-02, -2.69e-02, -3.55e-02,  6.12e-02,  5.09e-02,\n",
      "         2.34e-02, -3.32e-03, -2.97e-02,  2.38e-03, -4.03e-02,  1.34e-02,\n",
      "         4.72e-03,  4.85e-03, -1.62e-02, -1.35e-02,  4.17e-02, -1.80e-02,\n",
      "         3.47e-02,  3.44e-02, -4.02e-02, -6.03e-02,  6.58e-03, -1.88e-02,\n",
      "        -4.18e-02,  1.03e-02, -2.01e-03,  4.88e-03, -4.11e-02,  3.45e-03,\n",
      "         2.14e-02,  2.12e-02,  2.99e-02, -1.48e-02,  1.20e-02, -6.62e-03,\n",
      "        -2.38e-02, -1.32e-02,  1.23e-02, -6.14e-03,  1.56e-02,  1.52e-02,\n",
      "         2.76e-02, -3.39e-02,  7.88e-02, -4.48e-02, -5.19e-03, -3.73e-02,\n",
      "        -2.36e-02,  3.68e-04, -5.14e-02,  2.16e-02,  1.06e-03,  5.96e-02,\n",
      "        -5.69e-03, -3.03e-02, -3.36e-02,  1.50e-02,  2.25e-02, -1.82e-02,\n",
      "         4.64e-02, -2.89e-02, -2.00e-02, -1.70e-03, -3.05e-02,  5.95e-04,\n",
      "         2.37e-02, -1.92e-02, -7.58e-02,  3.20e-02, -4.65e-02, -3.18e-02,\n",
      "        -4.05e-02, -4.99e-03, -3.62e-02,  1.74e-02,  1.41e-02, -3.72e-02,\n",
      "        -7.26e-03,  8.94e-03,  3.93e-02, -1.56e-02,  1.47e-02, -1.54e-02,\n",
      "         1.02e-02,  1.86e-02,  3.86e-02, -1.01e-02,  2.82e-02, -1.36e-02,\n",
      "        -1.42e-02,  4.19e-02, -3.39e-02,  3.44e-02,  7.37e-03,  2.05e-02,\n",
      "         3.12e-02, -3.00e-02,  1.08e-02, -2.77e-02,  4.74e-02, -1.50e-02,\n",
      "        -3.00e-02,  2.65e-02, -1.03e-02, -3.97e-02,  4.04e-02,  1.11e-02,\n",
      "         3.24e-03,  1.44e-02,  1.86e-03,  4.88e-02, -3.78e-02,  1.28e-02,\n",
      "        -1.81e-02, -5.72e-03, -3.06e-02, -2.42e-02,  3.51e-02, -3.56e-02,\n",
      "        -8.45e-03,  5.46e-03,  1.63e-02,  3.09e-02,  1.45e-02,  1.28e-01,\n",
      "        -1.55e-02, -3.23e-02, -1.27e-02,  3.98e-02, -3.71e-03, -7.64e-03,\n",
      "         4.15e-03, -5.79e-02, -2.66e-02, -2.82e-02,  3.23e-02,  2.64e-02,\n",
      "        -4.77e-02,  2.92e-02, -4.32e-02,  3.33e-03, -9.13e-03, -6.75e-02,\n",
      "        -3.79e-02, -7.35e-02, -1.94e-03, -7.04e-02, -9.81e-03,  1.66e-02,\n",
      "         9.39e-03, -1.27e-03,  4.00e-03,  1.83e-02, -3.99e-02,  1.38e-02,\n",
      "        -1.54e-02,  1.05e-02, -1.44e-02, -3.34e-02,  4.37e-02, -1.34e-02,\n",
      "        -3.55e-02, -5.39e-03, -6.22e-02, -2.07e-02,  5.89e-04,  2.86e-02,\n",
      "         3.11e-04,  2.30e-02,  6.61e-02,  1.59e-02,  4.02e-02,  2.41e-03,\n",
      "        -2.78e-02,  7.15e-03,  4.75e-03, -1.96e-02,  1.67e-02, -1.84e-02,\n",
      "        -1.37e-02, -2.95e-02,  1.04e-02,  5.01e-02,  4.18e-02,  9.41e-03,\n",
      "        -2.82e-02,  1.64e-02,  5.85e-03,  3.76e-02, -2.15e-02, -5.30e-03,\n",
      "         5.18e-02,  2.48e-02, -2.70e-03, -1.11e-02,  2.98e-02,  8.68e-03,\n",
      "        -3.92e-02,  4.46e-03,  2.08e-03, -5.14e-02, -4.88e-02,  8.12e-03,\n",
      "        -4.86e-03,  9.16e-03], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 7.55e-02,  7.08e-03,  3.96e-02,  2.24e-02,  1.28e-02,  6.03e-02,\n",
      "         2.38e-02,  1.28e-02,  6.39e-02, -1.00e-02,  1.31e-02,  2.71e-02,\n",
      "         1.45e-02,  9.85e-03,  5.79e-02,  1.30e-02,  1.10e-02,  4.08e-02,\n",
      "         3.49e-02,  3.28e-02,  5.45e-03,  3.39e-02,  1.59e-02,  2.81e-02,\n",
      "         3.66e-02,  5.11e-02, -9.41e-03,  1.41e-02,  2.02e-02, -3.89e-02,\n",
      "         4.71e-02, -8.54e-03,  1.37e-02, -3.29e-02,  4.67e-03,  1.06e-02,\n",
      "         1.55e-02,  5.69e-02,  2.97e-02, -2.55e-03,  1.72e-02,  4.21e-03,\n",
      "         1.61e-02,  3.49e-02,  1.67e-02,  2.61e-02,  1.79e-02,  1.31e-02,\n",
      "         4.07e-03, -4.42e-03,  1.66e-02,  8.19e-03, -6.04e-03,  2.33e-02,\n",
      "        -1.64e-03,  5.11e-03, -5.21e-03,  9.24e-03,  1.36e-02, -1.42e-02,\n",
      "         2.06e-03, -9.19e-03,  2.76e-02,  8.70e-03,  1.46e-02,  8.21e-04,\n",
      "         5.69e-03, -2.98e-02, -1.11e-02,  9.99e-03, -4.02e-02,  2.69e-02,\n",
      "        -5.52e-04,  1.60e-03, -1.19e-02, -2.80e-02,  6.64e-03, -2.25e-02,\n",
      "         9.05e-03, -3.64e-02, -2.41e-03, -4.25e-03,  1.45e-02,  5.39e-02,\n",
      "         1.43e-02,  3.22e-02,  1.18e-02,  4.03e-02,  4.17e-03,  2.11e-02,\n",
      "         7.63e-02,  2.52e-02, -1.53e-02, -8.35e-03,  1.75e-02,  3.16e-02,\n",
      "        -1.83e-02, -2.18e-02,  2.76e-02, -3.69e-03, -7.50e-04,  7.37e-02,\n",
      "         3.57e-02,  1.76e-02,  3.72e-02,  6.60e-03,  2.87e-02,  1.47e-02,\n",
      "        -9.27e-03,  4.83e-02, -7.56e-03,  6.21e-02, -1.24e-02, -2.70e-02,\n",
      "         3.44e-03, -1.80e-02,  3.13e-02, -3.63e-02,  3.84e-02,  2.78e-02,\n",
      "         1.80e-02,  2.38e-02,  1.98e-03,  2.07e-02,  2.93e-02,  5.20e-02,\n",
      "         3.27e-02,  3.39e-02,  3.08e-02, -3.27e-02, -9.75e-03, -4.09e-02,\n",
      "        -1.40e-02, -1.33e-02, -2.60e-02,  1.13e-02,  7.64e-03,  1.20e-01,\n",
      "         1.29e-04, -8.26e-03,  4.97e-02, -5.58e-03,  4.57e-03, -4.50e-03,\n",
      "         3.49e-02,  1.10e-02,  2.59e-03,  1.50e-02,  7.66e-02,  7.55e-02,\n",
      "         4.54e-03,  1.03e-02, -7.55e-05,  2.30e-03,  2.66e-02, -8.61e-03,\n",
      "        -5.48e-03,  7.12e-03, -7.06e-03,  1.36e-02,  7.34e-03,  1.88e-02,\n",
      "        -1.12e-02,  1.23e-02,  2.15e-02,  2.56e-02, -1.74e-02, -8.74e-03,\n",
      "        -2.55e-02,  1.12e-02,  2.24e-02, -9.14e-03,  1.35e-03,  4.98e-02,\n",
      "        -1.69e-02,  5.17e-03, -1.86e-02,  4.60e-03, -3.18e-02, -1.03e-02,\n",
      "         1.90e-02, -5.17e-03, -3.58e-02, -3.87e-02,  3.76e-02, -1.54e-02,\n",
      "        -2.15e-02, -7.33e-03, -1.77e-02, -2.44e-02,  5.40e-04, -6.27e-03,\n",
      "        -3.64e-02, -1.69e-02, -3.21e-02, -5.29e-02,  3.69e-02, -1.97e-02,\n",
      "         1.64e-02,  5.00e-02, -1.20e-02,  5.35e-03, -3.08e-03, -4.38e-03,\n",
      "        -8.33e-03, -1.78e-03,  3.07e-03, -2.76e-02,  1.81e-02, -2.27e-02,\n",
      "        -4.33e-03, -2.70e-02, -3.53e-02,  1.63e-02,  2.75e-02, -7.47e-02,\n",
      "        -3.66e-03,  4.53e-04, -1.31e-02, -6.43e-03, -9.85e-03, -1.35e-02,\n",
      "         1.09e-02,  1.97e-02, -8.36e-03,  2.89e-02,  1.52e-02, -2.64e-02,\n",
      "         2.61e-02, -2.32e-03,  5.88e-04, -3.68e-03,  9.40e-03, -1.08e-03,\n",
      "         3.81e-02,  1.92e-03, -2.30e-02, -5.59e-03,  8.32e-03, -3.94e-02,\n",
      "         1.39e-02,  3.61e-03,  8.00e-03, -4.65e-03, -2.42e-02, -2.76e-02,\n",
      "        -2.30e-02, -1.78e-02,  6.55e-03,  4.12e-02,  2.25e-02,  4.57e-02,\n",
      "        -2.04e-02, -3.80e-03, -4.22e-02,  7.86e-03,  1.54e-02,  1.43e-03,\n",
      "        -3.20e-02, -1.07e-02, -3.01e-02,  1.23e-03,  1.80e-02, -7.21e-03,\n",
      "        -6.22e-02, -1.78e-02,  1.08e-01,  2.50e-02,  4.74e-03, -7.37e-03,\n",
      "         4.49e-02,  1.69e-02,  3.60e-02,  2.51e-02,  4.56e-02, -5.93e-02,\n",
      "        -3.61e-02,  1.45e-02, -2.63e-02, -4.39e-02, -8.07e-03, -1.57e-02,\n",
      "         2.25e-02,  7.43e-03, -2.25e-02, -1.95e-02,  2.80e-02, -7.32e-02,\n",
      "        -3.76e-02,  5.34e-03,  2.68e-02, -7.07e-03, -2.56e-02,  2.58e-02,\n",
      "         1.45e-02,  2.25e-02, -1.71e-02, -5.02e-02, -3.44e-02,  7.29e-03,\n",
      "        -2.38e-02,  7.20e-04,  2.31e-02, -1.77e-02,  1.44e-02,  2.07e-03,\n",
      "         8.16e-03, -2.18e-02, -3.12e-02, -3.87e-02,  5.85e-02,  3.57e-02,\n",
      "         1.77e-02, -6.20e-04, -3.08e-02,  2.06e-03, -5.10e-02,  1.03e-02,\n",
      "         2.76e-03,  4.32e-03, -1.98e-02, -1.37e-02,  3.84e-02, -1.79e-02,\n",
      "         6.16e-03,  4.47e-02, -4.44e-02, -7.62e-02, -2.27e-04, -1.57e-02,\n",
      "        -4.10e-02,  2.79e-03,  3.09e-02,  3.56e-03, -4.28e-02,  5.37e-03,\n",
      "         2.23e-02,  2.03e-02,  1.34e-02, -1.63e-02,  1.20e-02, -6.95e-03,\n",
      "        -2.34e-02, -1.69e-02, -5.96e-03, -1.51e-02,  1.53e-02,  1.54e-02,\n",
      "         2.75e-02, -3.33e-02,  7.24e-02, -4.51e-02, -6.34e-03, -4.84e-02,\n",
      "        -2.34e-02, -1.84e-04, -4.81e-02,  1.60e-02,  1.01e-03,  5.83e-02,\n",
      "        -1.50e-02, -2.44e-02, -3.53e-02,  3.47e-03,  1.01e-02, -3.01e-02,\n",
      "         3.55e-02, -2.90e-02, -2.03e-02, -2.10e-03, -2.88e-02,  2.43e-05,\n",
      "         1.95e-02, -8.41e-02, -8.56e-02,  2.97e-02, -4.08e-02, -3.10e-02,\n",
      "         3.99e-05, -5.81e-03, -2.74e-02,  1.01e-02,  1.03e-02, -4.85e-02,\n",
      "        -2.05e-02, -5.50e-04,  3.02e-02, -1.62e-02,  1.01e-02, -1.52e-02,\n",
      "         4.08e-03,  2.31e-02,  3.07e-02, -1.03e-02,  2.84e-02, -8.80e-03,\n",
      "        -2.14e-02,  4.77e-02, -1.05e-02, -6.00e-03,  6.03e-03,  1.77e-02,\n",
      "         2.69e-02, -3.38e-02,  1.09e-02, -3.71e-02, -6.15e-04, -2.33e-02,\n",
      "        -3.09e-02,  1.05e-02, -8.83e-03, -3.41e-02,  3.56e-02,  8.35e-03,\n",
      "         4.74e-03,  1.28e-02,  1.28e-03,  3.75e-02, -4.12e-02,  1.30e-02,\n",
      "        -1.84e-02, -6.71e-03, -2.93e-02, -2.21e-02,  3.38e-02, -3.89e-02,\n",
      "        -1.27e-02, -1.99e-02,  2.46e-02,  3.05e-02,  1.77e-02,  7.44e-02,\n",
      "        -1.55e-02, -3.57e-02,  1.84e-02,  4.85e-02, -4.66e-03, -2.99e-02,\n",
      "         3.30e-04, -5.86e-02, -2.73e-02, -3.46e-02,  2.94e-02,  2.18e-02,\n",
      "        -4.35e-02,  2.45e-02, -3.88e-02, -3.72e-03, -9.98e-03, -5.91e-02,\n",
      "        -5.15e-02, -6.76e-02, -2.00e-03, -3.98e-02, -1.06e-02,  1.10e-02,\n",
      "         1.04e-02, -2.52e-03,  4.42e-03,  1.40e-02, -4.35e-02,  1.10e-02,\n",
      "        -4.22e-02,  7.46e-03,  2.30e-03, -1.87e-02,  5.22e-02, -3.87e-02,\n",
      "        -6.04e-02, -7.17e-03, -9.10e-02, -2.28e-02,  8.36e-04,  2.85e-02,\n",
      "        -1.02e-02,  2.05e-02,  6.79e-02,  1.01e-02,  3.40e-02, -5.20e-03,\n",
      "        -2.64e-02, -8.17e-03,  8.82e-03, -4.13e-02,  3.96e-02, -2.60e-02,\n",
      "        -1.47e-02, -2.95e-02,  1.26e-02,  5.12e-02,  4.19e-02,  2.14e-02,\n",
      "        -1.20e-02,  1.69e-02,  2.29e-03,  3.71e-02, -2.74e-02, -5.34e-03,\n",
      "         4.24e-02,  3.07e-03, -3.13e-03, -9.42e-03,  2.92e-02, -2.52e-02,\n",
      "        -3.92e-02,  1.90e-03,  1.59e-03, -1.25e-01, -3.74e-02, -1.46e-02,\n",
      "        -4.73e-03, -1.26e-03], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7.92e-02,  8.74e-03,  2.22e-02,  3.00e-02,  2.77e-02,  6.27e-02,\n",
      "         6.57e-02,  1.83e-02,  6.53e-02, -1.10e-02,  1.34e-02,  2.72e-02,\n",
      "         1.18e-02,  1.76e-02,  5.93e-02,  1.46e-02,  1.07e-02,  4.04e-02,\n",
      "         2.65e-02,  3.44e-02,  1.56e-02,  3.61e-02,  2.14e-02,  2.37e-02,\n",
      "         4.13e-02,  3.70e-02,  1.22e-02,  4.17e-03,  1.04e-02, -6.55e-02,\n",
      "         3.67e-02, -7.96e-03,  1.98e-02, -3.62e-02, -1.74e-04,  9.27e-03,\n",
      "         1.78e-02,  7.37e-02,  3.30e-02,  6.36e-03,  1.75e-02,  5.55e-02,\n",
      "         2.12e-02,  3.56e-02,  1.30e-02,  3.17e-02,  1.79e-02,  1.32e-02,\n",
      "         9.73e-03, -4.68e-03,  2.31e-02, -2.40e-03, -1.20e-02,  3.76e-02,\n",
      "         4.81e-03,  9.85e-03, -4.35e-03,  9.10e-03,  8.99e-03, -1.89e-02,\n",
      "         4.89e-03, -1.25e-02,  2.74e-02,  6.43e-03,  1.73e-02,  5.43e-03,\n",
      "         6.62e-03, -1.50e-02, -1.09e-02,  1.27e-02, -3.87e-03,  2.59e-02,\n",
      "        -1.14e-03,  6.48e-03, -6.93e-03, -2.70e-02, -4.85e-03, -2.49e-02,\n",
      "         8.04e-03, -4.33e-02,  4.20e-04, -2.63e-02,  1.35e-02,  4.42e-02,\n",
      "         2.77e-02,  4.19e-02,  1.28e-02,  3.95e-02,  5.11e-03,  1.95e-02,\n",
      "         3.42e-02,  2.68e-02,  1.20e-03, -1.94e-02,  2.21e-02,  2.80e-02,\n",
      "        -3.52e-02, -2.15e-02,  2.44e-02,  3.46e-03, -3.62e-03,  7.04e-02,\n",
      "         3.67e-02,  2.29e-02,  2.79e-02,  5.16e-03,  2.27e-02,  2.04e-02,\n",
      "        -4.60e-03,  5.39e-02, -3.19e-03,  6.20e-02, -1.11e-02, -5.25e-03,\n",
      "         1.65e-03, -1.72e-02,  2.55e-02, -1.11e-02,  3.02e-02,  2.77e-02,\n",
      "         2.80e-02,  2.17e-02,  1.23e-02,  2.21e-02,  2.74e-02,  3.94e-02,\n",
      "         2.22e-02,  1.77e-02,  3.24e-02, -2.29e-02, -9.67e-03, -4.09e-02,\n",
      "        -1.36e-02, -7.74e-03, -2.55e-02,  2.03e-02,  2.58e-03,  9.13e-02,\n",
      "         2.80e-03,  8.25e-04,  5.33e-02, -5.31e-03,  1.81e-02, -2.03e-03,\n",
      "         3.31e-02, -8.14e-03,  1.05e-04,  1.49e-02,  8.93e-02,  7.42e-02,\n",
      "         2.84e-02,  7.43e-03,  3.41e-03,  4.95e-03,  1.69e-02, -6.32e-03,\n",
      "        -4.06e-03,  8.56e-03, -5.92e-03,  7.99e-03,  2.92e-03,  1.52e-02,\n",
      "        -6.18e-03,  2.81e-02,  2.59e-02,  3.14e-02, -1.46e-02, -1.13e-02,\n",
      "        -2.89e-02,  2.88e-03,  1.70e-02, -5.76e-03,  3.62e-03,  5.06e-02,\n",
      "        -1.02e-02,  7.86e-03, -1.86e-02,  5.38e-03, -2.68e-02, -9.27e-03,\n",
      "        -2.33e-02,  3.95e-03, -1.73e-02, -3.96e-02,  3.57e-02, -1.50e-02,\n",
      "        -2.08e-02, -1.16e-02, -2.32e-02, -2.00e-02, -1.20e-03, -4.34e-02,\n",
      "        -3.58e-02,  6.29e-03, -2.03e-02, -5.51e-02,  4.79e-02, -1.52e-02,\n",
      "         1.77e-02,  5.95e-02, -1.36e-02, -9.60e-03, -9.04e-03, -4.77e-03,\n",
      "        -2.29e-02,  1.03e-02,  9.86e-03, -2.13e-02,  1.69e-02, -2.51e-02,\n",
      "         8.87e-03, -1.92e-02, -3.37e-02,  1.35e-02,  2.64e-02, -4.09e-02,\n",
      "        -4.40e-03, -2.12e-02, -1.01e-02, -7.21e-03, -1.17e-02,  2.18e-03,\n",
      "         3.94e-02,  6.53e-03, -1.00e-02,  3.34e-02,  1.29e-02, -2.61e-02,\n",
      "         1.69e-02, -2.94e-03,  2.53e-03, -1.67e-03,  1.16e-02, -3.65e-03,\n",
      "         2.66e-02,  5.41e-04, -1.99e-02, -3.78e-03,  5.07e-03, -3.84e-02,\n",
      "         1.42e-02,  3.70e-03,  7.90e-03,  6.36e-03, -1.29e-02, -2.72e-02,\n",
      "        -1.56e-02, -9.04e-03, -7.56e-03,  3.71e-02,  1.75e-02,  4.92e-02,\n",
      "        -4.11e-03,  1.48e-03, -1.37e-02,  1.05e-02,  1.52e-02,  5.80e-03,\n",
      "        -2.33e-02, -4.14e-03, -4.29e-02,  1.89e-03, -1.92e-02, -1.97e-02,\n",
      "        -7.21e-02, -1.46e-02,  1.02e-01,  2.50e-02,  2.61e-03, -1.47e-02,\n",
      "         3.56e-02,  1.64e-02,  3.86e-02,  2.43e-02,  5.50e-02, -7.32e-02,\n",
      "        -3.60e-02,  2.54e-02, -2.74e-02, -4.39e-02, -9.45e-03, -2.97e-02,\n",
      "         1.01e-02,  7.62e-03, -1.56e-02, -3.67e-02,  2.79e-02, -6.92e-02,\n",
      "        -2.29e-02, -2.63e-03,  2.68e-02, -5.77e-03, -3.15e-02,  2.22e-02,\n",
      "         7.87e-03,  2.21e-02, -2.22e-02, -6.53e-02, -3.51e-02,  6.81e-03,\n",
      "        -2.43e-02,  2.75e-04,  2.46e-02, -1.79e-02,  1.30e-02,  2.06e-03,\n",
      "         8.48e-03, -2.36e-02, -3.48e-02, -4.03e-02,  5.23e-02,  4.40e-02,\n",
      "         1.51e-02, -6.45e-03, -3.13e-02,  9.83e-04, -5.31e-02,  1.04e-02,\n",
      "         3.91e-03,  3.01e-03, -2.29e-02, -7.65e-04,  3.45e-02, -1.81e-02,\n",
      "         1.01e-02,  1.57e-02, -4.83e-02, -7.00e-02,  2.10e-03, -1.22e-02,\n",
      "        -4.17e-02, -1.36e-03, -3.42e-02,  1.13e-03, -4.48e-02, -3.26e-03,\n",
      "         1.87e-02,  1.88e-02,  2.58e-02, -1.29e-02,  1.19e-02, -7.20e-03,\n",
      "         5.85e-03, -2.85e-02, -1.15e-02, -5.88e-03,  1.50e-02, -2.58e-02,\n",
      "         2.80e-02, -3.28e-02,  7.44e-02, -4.54e-02, -5.52e-03, -5.46e-02,\n",
      "        -1.67e-02, -2.37e-02, -5.33e-02,  2.58e-02, -2.64e-03,  5.56e-02,\n",
      "        -3.39e-03, -2.52e-02, -3.56e-02,  1.00e-02, -2.47e-03,  9.56e-03,\n",
      "         3.35e-02, -2.90e-02, -2.05e-02, -2.44e-03, -3.05e-02,  2.88e-03,\n",
      "         1.61e-02, -1.03e-01, -7.40e-02,  3.65e-02, -3.94e-02, -3.28e-02,\n",
      "         2.77e-02, -5.57e-03, -4.84e-02,  1.08e-02,  8.72e-03, -5.06e-02,\n",
      "         6.30e-03, -6.21e-03,  3.06e-02, -1.67e-02,  1.09e-02, -1.65e-02,\n",
      "         4.71e-03,  1.70e-02,  2.09e-02, -1.04e-02,  2.33e-02, -2.02e-02,\n",
      "        -1.60e-02,  2.92e-02, -3.67e-02, -1.34e-02,  4.63e-03,  9.99e-03,\n",
      "         2.42e-02, -4.29e-02,  1.09e-02, -2.82e-02,  2.95e-02, -3.33e-03,\n",
      "        -3.52e-02,  8.98e-03, -1.12e-02,  6.39e-03,  3.40e-02,  1.78e-02,\n",
      "         2.14e-03,  1.21e-02,  6.07e-04,  2.87e-02, -1.59e-02,  1.07e-02,\n",
      "        -2.42e-02, -7.12e-03, -3.14e-02, -2.27e-02,  3.34e-02, -2.68e-02,\n",
      "        -8.33e-03, -4.58e-02,  8.68e-03,  2.95e-02,  1.55e-02,  9.52e-02,\n",
      "        -3.51e-03, -3.61e-02, -4.50e-04,  3.08e-02, -4.56e-03, -2.83e-02,\n",
      "         6.34e-03, -5.86e-02, -2.82e-02, -2.99e-02,  5.07e-02,  1.69e-02,\n",
      "        -5.08e-02,  1.87e-02, -4.37e-02, -6.95e-03, -7.94e-03, -4.91e-02,\n",
      "        -4.06e-02, -6.35e-02, -2.05e-03, -8.01e-02, -8.27e-03,  7.95e-03,\n",
      "         1.07e-02, -4.68e-03,  3.79e-03,  1.70e-02, -4.28e-02,  1.20e-02,\n",
      "        -2.82e-02,  5.60e-03, -2.76e-02, -3.92e-02,  3.77e-02, -1.09e-02,\n",
      "        -3.61e-02, -5.60e-03, -6.34e-02, -3.60e-02,  4.85e-03,  2.68e-02,\n",
      "        -6.29e-03,  2.20e-02,  4.08e-02,  1.14e-02,  2.90e-02,  1.18e-02,\n",
      "        -2.66e-02, -7.78e-03, -7.22e-05, -4.62e-02,  4.59e-02, -2.89e-04,\n",
      "        -1.41e-02, -2.96e-02,  9.59e-03,  3.95e-02,  4.13e-02,  1.08e-02,\n",
      "        -3.04e-02,  1.48e-02, -6.43e-03,  5.02e-02, -2.65e-02, -1.16e-02,\n",
      "         3.72e-02,  5.07e-03, -3.27e-03, -1.22e-02,  2.90e-02, -2.27e-02,\n",
      "        -4.09e-02,  7.38e-03,  6.82e-04, -1.25e-01, -5.65e-02, -8.75e-03,\n",
      "         6.77e-03,  4.33e-03], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 8.82e-02,  1.20e-02,  2.33e-02,  2.79e-02,  8.66e-03,  3.81e-02,\n",
      "         4.58e-02,  2.85e-02,  6.42e-02, -1.11e-02,  1.67e-02,  2.74e-02,\n",
      "         1.51e-02,  2.45e-02,  7.72e-02,  7.73e-03,  3.46e-03,  4.04e-02,\n",
      "         3.96e-02,  2.96e-02,  9.58e-04,  3.57e-02,  2.79e-02,  2.58e-02,\n",
      "         4.09e-02,  2.76e-02, -1.29e-02,  2.17e-02,  1.11e-02, -4.47e-02,\n",
      "         4.07e-02,  4.86e-04, -1.35e-03, -3.04e-02,  5.85e-03,  1.03e-02,\n",
      "         1.60e-02,  4.47e-02,  4.56e-02,  4.74e-03,  1.77e-02,  2.37e-02,\n",
      "         2.10e-02,  3.58e-02,  2.12e-02,  2.71e-02,  1.79e-02,  1.35e-02,\n",
      "         6.63e-03,  8.31e-04,  2.10e-02,  8.98e-03,  6.70e-03,  3.38e-02,\n",
      "         4.71e-03,  1.08e-02, -3.03e-03,  9.88e-03,  1.13e-02, -1.22e-02,\n",
      "         3.79e-03,  4.15e-04,  3.93e-02,  4.86e-03,  2.61e-02, -5.42e-03,\n",
      "         8.95e-03, -1.62e-02, -1.08e-02,  1.20e-02,  1.05e-02,  3.11e-02,\n",
      "         5.97e-04,  1.01e-02, -3.11e-03, -3.10e-02,  9.13e-03, -2.51e-02,\n",
      "         1.29e-02, -3.46e-02,  4.67e-03,  1.15e-02,  1.48e-02,  1.57e-02,\n",
      "         2.76e-02,  4.02e-02,  1.18e-02,  4.02e-02,  5.32e-03,  1.51e-02,\n",
      "         7.19e-02,  2.64e-02, -1.23e-03, -1.92e-04,  1.72e-02,  2.29e-02,\n",
      "         4.14e-04, -2.11e-02,  2.52e-02,  3.27e-03,  5.17e-04,  8.21e-02,\n",
      "         3.81e-02,  2.15e-02,  4.01e-02,  5.90e-03,  3.39e-02,  2.25e-02,\n",
      "         1.83e-02,  5.75e-02, -2.34e-03,  6.26e-02, -7.56e-03, -7.15e-03,\n",
      "         7.03e-03, -1.30e-02,  4.22e-02, -3.79e-02,  3.49e-02,  2.76e-02,\n",
      "         3.18e-02,  2.37e-02,  6.38e-03,  2.06e-02,  2.82e-02,  5.01e-02,\n",
      "         1.23e-02,  2.34e-02,  3.32e-02, -1.62e-02, -9.51e-03, -4.08e-02,\n",
      "        -1.20e-02, -9.50e-03, -2.36e-02,  1.42e-02,  5.38e-03,  4.20e-02,\n",
      "        -1.96e-03, -2.29e-02,  5.42e-02, -5.57e-03,  7.47e-03, -1.76e-03,\n",
      "         3.38e-02, -7.49e-03,  2.29e-03,  1.42e-02,  7.55e-02,  6.62e-02,\n",
      "         1.91e-02,  1.26e-02,  1.85e-03,  3.84e-03,  2.04e-02, -5.97e-03,\n",
      "         7.46e-03,  1.28e-02,  1.79e-03,  1.33e-02,  1.47e-02,  1.42e-02,\n",
      "         4.79e-03,  4.48e-02,  2.76e-02,  2.69e-02, -1.57e-02, -7.05e-03,\n",
      "        -2.85e-02,  5.08e-03,  2.46e-02, -6.50e-03,  5.12e-03,  6.63e-02,\n",
      "        -9.34e-03,  7.74e-03, -1.85e-02,  6.27e-03, -2.85e-02, -1.16e-02,\n",
      "        -1.37e-02, -4.05e-03, -2.35e-02, -3.74e-02,  3.76e-02, -1.59e-02,\n",
      "        -2.10e-02, -1.11e-03, -1.24e-02, -2.12e-02, -1.63e-04, -2.31e-02,\n",
      "        -3.64e-02, -1.38e-02, -2.07e-02, -5.38e-02,  3.17e-02, -1.17e-02,\n",
      "         1.33e-02,  2.41e-02, -1.42e-02,  1.43e-02, -7.08e-03, -5.00e-03,\n",
      "        -9.45e-03,  6.22e-03,  7.40e-04, -1.99e-02,  2.07e-02, -1.80e-02,\n",
      "         2.30e-02, -2.15e-02, -3.24e-02,  1.24e-02,  3.69e-02, -6.37e-02,\n",
      "        -1.05e-02, -3.48e-02, -7.97e-03, -1.15e-02, -1.52e-02, -4.11e-03,\n",
      "        -5.11e-03,  1.49e-02,  2.16e-04,  2.72e-02,  1.13e-02, -2.69e-02,\n",
      "         1.91e-02, -2.71e-03,  1.14e-03, -4.09e-03,  1.15e-02, -1.89e-03,\n",
      "         3.87e-02, -1.92e-03, -1.82e-02, -9.66e-03, -3.23e-03, -3.65e-02,\n",
      "         1.33e-02,  3.87e-03,  7.87e-03, -8.52e-03, -1.52e-02, -2.48e-02,\n",
      "        -1.23e-02, -1.55e-02, -6.91e-03,  3.81e-02,  2.50e-02,  3.00e-02,\n",
      "        -2.66e-02,  1.17e-03, -2.09e-02,  5.89e-03,  1.52e-02,  1.27e-02,\n",
      "        -2.64e-02, -5.47e-03, -4.88e-02,  2.02e-03,  1.68e-02, -2.30e-02,\n",
      "        -5.84e-02, -7.25e-03,  8.13e-02,  2.38e-02,  3.68e-03,  2.83e-02,\n",
      "         4.78e-02,  1.52e-02,  3.74e-02,  2.71e-02,  5.11e-02, -4.77e-02,\n",
      "        -3.63e-02,  2.87e-02, -2.52e-02, -4.18e-02, -9.30e-03, -1.78e-02,\n",
      "         2.17e-02,  7.62e-03, -2.23e-02, -4.19e-02,  2.78e-02, -7.63e-02,\n",
      "        -4.21e-02,  1.39e-03,  2.46e-02, -6.60e-03, -2.74e-02,  2.15e-02,\n",
      "         2.67e-02,  2.20e-02, -1.71e-02, -4.84e-02, -4.11e-02,  7.31e-03,\n",
      "        -2.37e-02, -2.00e-02,  2.32e-02, -1.81e-02,  1.02e-02,  2.43e-04,\n",
      "        -7.85e-04, -2.37e-02, -3.49e-02, -4.18e-02,  5.06e-02,  5.24e-02,\n",
      "         2.08e-02, -8.46e-03, -2.80e-02, -2.56e-04, -4.96e-02,  7.54e-03,\n",
      "         5.41e-03,  5.56e-03, -2.31e-02, -1.35e-02,  3.12e-02, -1.89e-02,\n",
      "        -2.03e-03,  3.25e-02, -2.90e-02, -7.90e-02,  3.13e-03, -1.95e-02,\n",
      "        -4.56e-02, -2.32e-03, -2.28e-02,  5.60e-03, -4.60e-02, -2.12e-02,\n",
      "         2.44e-02,  1.82e-02,  7.94e-03, -8.16e-03,  1.12e-02, -7.46e-03,\n",
      "         2.17e-03, -3.11e-02, -6.82e-03, -2.00e-02,  1.44e-02, -1.15e-02,\n",
      "         2.73e-02, -3.22e-02,  5.45e-02, -4.56e-02, -6.76e-03, -4.38e-02,\n",
      "        -1.22e-02, -5.62e-04, -5.26e-02,  2.56e-02, -5.17e-03,  5.40e-02,\n",
      "        -9.80e-03, -2.47e-02, -3.61e-02,  7.10e-03,  1.80e-02, -3.86e-02,\n",
      "         3.63e-02, -2.92e-02, -2.03e-02, -3.08e-03, -2.96e-02,  4.35e-03,\n",
      "         1.32e-02, -1.63e-01, -7.22e-02,  3.98e-02, -3.40e-02, -3.28e-02,\n",
      "         4.50e-02, -5.64e-03, -4.64e-02,  2.93e-03,  8.80e-03, -5.75e-02,\n",
      "        -7.73e-03, -6.94e-03,  3.00e-02, -1.69e-02,  1.09e-02, -1.96e-02,\n",
      "         6.33e-03,  1.74e-02,  1.79e-02, -1.06e-02,  2.45e-02, -2.09e-02,\n",
      "        -1.14e-02,  1.32e-02, -3.78e-02,  1.01e-02,  3.41e-03,  7.74e-03,\n",
      "         2.17e-02, -4.27e-02,  1.05e-02, -2.19e-02, -5.35e-03, -1.95e-02,\n",
      "        -3.71e-02,  2.49e-02, -9.94e-03, -3.65e-02,  2.90e-02,  9.92e-03,\n",
      "         1.94e-03,  1.13e-02, -1.11e-03,  3.00e-02, -4.53e-02,  7.30e-03,\n",
      "        -2.59e-02, -8.12e-03, -2.90e-02, -2.48e-02,  3.24e-02, -4.60e-02,\n",
      "        -5.02e-03, -2.26e-02,  9.13e-03,  2.90e-02,  1.28e-02,  4.91e-02,\n",
      "        -2.27e-02, -3.66e-02, -1.01e-02,  4.66e-02, -4.85e-03, -9.61e-03,\n",
      "         8.54e-03, -5.92e-02, -2.83e-02, -4.77e-02,  5.69e-03,  1.07e-02,\n",
      "        -4.90e-02,  1.25e-02, -4.00e-02, -1.43e-02, -1.02e-02, -7.25e-02,\n",
      "        -6.22e-02, -4.10e-02, -1.41e-03, -8.04e-02, -8.60e-03,  3.93e-03,\n",
      "         1.13e-02, -2.85e-03,  1.92e-03,  8.39e-03, -4.45e-02,  7.00e-03,\n",
      "        -2.65e-02,  3.02e-03, -3.23e-02, -4.36e-02,  2.99e-02, -3.61e-02,\n",
      "        -4.06e-02, -4.92e-03, -7.73e-02, -3.98e-02,  7.19e-03,  2.32e-02,\n",
      "        -1.96e-02,  2.10e-02,  3.83e-02,  8.74e-03,  3.28e-02, -4.77e-03,\n",
      "        -2.93e-02,  4.81e-03,  1.22e-02, -5.79e-02,  2.00e-02, -2.40e-02,\n",
      "        -1.42e-02, -2.97e-02,  6.14e-03,  4.07e-02,  4.27e-02,  1.64e-02,\n",
      "        -3.55e-02,  1.18e-02, -1.38e-02,  3.50e-02, -2.65e-02, -1.25e-02,\n",
      "         3.83e-02,  3.51e-03, -3.39e-03, -2.48e-02,  2.88e-02, -5.18e-03,\n",
      "        -3.98e-02,  2.43e-03,  1.29e-03, -1.28e-01, -4.69e-02, -1.39e-02,\n",
      "        -1.10e-02,  4.27e-04], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.58e-02,  1.21e-02,  4.03e-02,  3.04e-02,  2.08e-02,  7.05e-02,\n",
      "         3.17e-02, -1.30e-02,  6.05e-02, -1.26e-02,  2.07e-02,  2.75e-02,\n",
      "         1.73e-02,  2.69e-02,  5.62e-02,  6.66e-03,  4.59e-03,  4.06e-02,\n",
      "         5.16e-02,  3.92e-02,  1.94e-02,  3.84e-02,  2.28e-02, -1.16e-02,\n",
      "         4.48e-02,  4.07e-02,  4.57e-03,  2.57e-02,  3.35e-02, -3.24e-02,\n",
      "         5.12e-02,  8.03e-03,  1.86e-02, -2.72e-02,  2.97e-02,  1.09e-02,\n",
      "         1.85e-02,  6.74e-02,  5.16e-02,  1.33e-02,  1.78e-02,  2.11e-02,\n",
      "         2.47e-02,  3.62e-02,  1.69e-02,  3.10e-02,  1.85e-02,  1.34e-02,\n",
      "         7.50e-03,  3.60e-03,  2.12e-02,  1.45e-02,  1.17e-02,  3.77e-02,\n",
      "         3.45e-03,  1.30e-02, -6.90e-03,  9.65e-03,  2.25e-02, -2.70e-03,\n",
      "         4.32e-03, -2.40e-04,  3.54e-02,  2.10e-03,  3.07e-02,  6.30e-03,\n",
      "         5.55e-03, -5.66e-03, -1.06e-02,  1.08e-02,  8.62e-03,  3.84e-02,\n",
      "         1.88e-04,  2.48e-02,  3.32e-05, -2.47e-02,  9.92e-03, -2.29e-02,\n",
      "         1.83e-02, -3.16e-02,  5.52e-03,  4.97e-03,  1.59e-02,  2.22e-02,\n",
      "         1.86e-02,  4.32e-02,  1.11e-02,  4.09e-02,  5.39e-03,  2.57e-02,\n",
      "         4.14e-02,  2.92e-02,  9.42e-03,  5.00e-03,  2.36e-02,  4.09e-02,\n",
      "         4.11e-02, -1.99e-02,  4.69e-02,  1.01e-02, -1.86e-02,  2.17e-02,\n",
      "         3.87e-02,  2.90e-02,  3.82e-02,  7.28e-03,  4.58e-02, -6.04e-03,\n",
      "        -6.88e-03,  4.17e-02,  4.46e-04,  5.66e-02, -1.06e-02, -9.95e-03,\n",
      "         4.19e-03, -2.09e-02,  4.24e-02, -2.27e-02,  3.01e-02,  2.75e-02,\n",
      "         2.67e-02,  2.62e-02,  4.83e-03,  1.88e-02,  2.85e-02,  3.93e-02,\n",
      "         8.31e-03,  2.58e-02,  3.42e-02, -1.90e-02, -9.38e-03, -4.00e-02,\n",
      "        -1.15e-02, -4.87e-03, -2.30e-02, -3.16e-03,  1.25e-02,  3.12e-02,\n",
      "         9.47e-04, -5.72e-05,  4.94e-02, -1.95e-03, -9.18e-03, -1.00e-03,\n",
      "         3.27e-02,  1.36e-02,  3.51e-03,  1.41e-02,  6.31e-02,  6.42e-02,\n",
      "        -6.32e-04,  9.06e-03, -1.98e-04,  8.54e-03,  1.70e-02, -3.96e-03,\n",
      "         9.20e-03,  8.81e-03, -1.71e-04,  2.34e-02,  4.54e-03,  1.30e-02,\n",
      "         5.37e-03,  2.22e-02,  2.29e-02,  2.85e-02, -1.28e-02,  1.19e-03,\n",
      "        -3.13e-02,  9.57e-03,  6.56e-04, -3.91e-03,  5.62e-03,  5.28e-02,\n",
      "        -4.37e-03,  6.58e-03, -1.85e-02,  6.80e-03, -2.12e-02, -1.19e-02,\n",
      "         3.24e-02, -6.38e-03, -2.07e-02, -3.68e-02,  3.63e-02, -1.52e-02,\n",
      "        -2.04e-02, -2.86e-03, -2.00e-02, -2.48e-02,  7.86e-04, -3.09e-02,\n",
      "        -3.44e-02, -9.63e-03, -2.22e-02, -5.15e-02,  4.51e-02, -1.28e-02,\n",
      "         2.38e-02,  5.68e-02, -1.33e-02,  1.23e-02, -1.22e-02, -5.39e-03,\n",
      "        -4.47e-03, -3.73e-03,  4.42e-03, -2.83e-02,  2.03e-02, -1.20e-02,\n",
      "         1.38e-02, -2.61e-02, -3.33e-02,  1.34e-02,  1.80e-02, -6.31e-02,\n",
      "         8.02e-03, -1.00e-02, -5.38e-03, -1.55e-02, -1.04e-02, -2.12e-03,\n",
      "         1.35e-02,  9.29e-03,  2.42e-03,  2.39e-02,  8.94e-03, -2.62e-02,\n",
      "         2.96e-02, -6.76e-03,  2.61e-03, -5.76e-03,  1.04e-02,  2.61e-04,\n",
      "         2.16e-02, -3.05e-03, -1.63e-02, -8.95e-03,  4.62e-03, -3.59e-02,\n",
      "         1.37e-02,  4.11e-03,  7.80e-03, -6.35e-03, -1.49e-02, -2.46e-02,\n",
      "        -1.62e-02, -1.46e-02, -9.32e-03,  3.27e-02,  1.29e-02,  2.86e-02,\n",
      "        -3.36e-02,  5.45e-03, -2.22e-02,  1.22e-02,  1.49e-02,  1.86e-03,\n",
      "        -2.50e-02, -3.62e-03, -4.69e-02,  3.50e-03, -5.77e-03, -7.22e-03,\n",
      "        -6.42e-02, -3.20e-04,  1.12e-01,  2.36e-02,  3.86e-04, -2.31e-02,\n",
      "         3.60e-02,  1.47e-02,  2.38e-02,  2.81e-02,  4.71e-02, -7.15e-02,\n",
      "        -3.63e-02,  2.85e-02, -2.66e-02, -4.25e-02, -9.13e-03, -3.16e-02,\n",
      "         1.97e-02,  5.91e-03, -2.51e-02, -2.96e-02,  2.75e-02, -8.37e-02,\n",
      "        -3.15e-02, -1.59e-02,  2.26e-02, -7.15e-03, -2.56e-02,  1.51e-02,\n",
      "        -3.21e-03,  2.19e-02, -2.08e-02, -3.83e-02, -4.17e-02,  6.69e-03,\n",
      "        -2.86e-02, -9.84e-03,  2.10e-02, -1.83e-02,  9.18e-03,  8.37e-04,\n",
      "        -3.93e-03, -2.82e-02, -8.76e-03, -4.17e-02,  4.39e-02,  2.74e-02,\n",
      "         7.45e-03, -1.06e-02, -3.27e-02, -1.71e-03, -4.86e-02,  1.47e-02,\n",
      "         2.53e-03,  9.01e-03, -2.52e-02, -1.39e-02,  2.87e-02, -1.93e-02,\n",
      "        -6.94e-03,  4.73e-02, -6.08e-02, -1.89e-02, -1.69e-03, -8.26e-03,\n",
      "        -4.35e-02, -6.19e-03, -7.21e-03, -9.16e-03, -4.59e-02, -1.41e-02,\n",
      "         1.66e-02,  1.76e-02,  4.76e-03, -1.11e-02,  1.11e-02, -7.75e-03,\n",
      "        -1.05e-02, -3.83e-02,  1.17e-02, -7.34e-03,  1.43e-02, -1.95e-02,\n",
      "         2.66e-02, -3.18e-02,  4.54e-02, -4.58e-02, -7.18e-03, -3.78e-02,\n",
      "        -2.29e-02, -2.70e-02, -2.97e-02,  2.06e-02,  3.85e-04,  5.59e-02,\n",
      "        -1.52e-02, -3.08e-02, -3.67e-02,  8.10e-03,  1.70e-02, -3.64e-02,\n",
      "         3.61e-02, -2.88e-02, -2.09e-02, -3.17e-03, -3.08e-02,  2.83e-03,\n",
      "         7.37e-03, -6.31e-02, -1.00e-01,  4.23e-02, -3.12e-02, -3.36e-02,\n",
      "         2.89e-02, -5.81e-03, -4.45e-02,  5.63e-03,  5.86e-03, -3.62e-02,\n",
      "        -1.92e-02, -1.95e-02,  2.21e-02, -1.72e-02,  6.20e-03, -2.39e-02,\n",
      "        -9.52e-03,  1.14e-02,  8.43e-03, -1.07e-02,  2.09e-02, -2.35e-02,\n",
      "        -1.86e-02,  1.86e-02, -3.07e-02, -1.98e-02,  4.05e-03,  9.49e-03,\n",
      "         1.84e-02, -4.43e-02,  1.08e-02, -3.28e-02, -3.76e-02, -3.01e-02,\n",
      "        -3.83e-02,  1.85e-03, -1.22e-02,  3.85e-03,  3.29e-02,  1.46e-02,\n",
      "         2.39e-03,  1.15e-02, -1.72e-03,  1.86e-02, -4.75e-02,  5.93e-03,\n",
      "        -2.66e-02, -8.55e-03, -3.23e-02, -2.63e-02,  3.18e-02, -4.45e-02,\n",
      "        -1.23e-02, -1.62e-03,  9.12e-03,  2.91e-02,  9.64e-03,  4.52e-02,\n",
      "        -3.56e-02, -3.90e-02, -1.03e-02,  3.32e-02, -5.96e-03, -3.56e-02,\n",
      "         3.27e-04, -5.92e-02, -2.89e-02, -5.10e-02, -1.53e-02,  1.57e-02,\n",
      "        -5.39e-02,  1.92e-02, -4.21e-02, -7.25e-03, -8.02e-03, -5.57e-02,\n",
      "        -2.73e-02, -5.50e-02, -7.86e-04, -8.92e-02, -1.19e-02,  2.99e-03,\n",
      "         1.02e-02, -2.92e-03,  2.58e-03,  6.31e-03, -5.10e-02,  6.18e-03,\n",
      "        -2.76e-02, -1.23e-04, -3.03e-02, -5.67e-02,  3.69e-02, -2.51e-02,\n",
      "         1.59e-02, -5.07e-03, -8.49e-02, -4.66e-02, -1.09e-03,  1.89e-02,\n",
      "        -1.67e-02,  1.54e-02,  1.48e-02,  5.79e-03,  2.91e-02, -9.24e-03,\n",
      "        -2.75e-02, -1.36e-02, -7.04e-03, -7.44e-02, -1.25e-03, -2.04e-03,\n",
      "        -1.72e-02, -2.96e-02,  6.84e-03,  5.20e-02,  4.11e-02,  2.27e-02,\n",
      "        -3.98e-02,  1.06e-02, -1.64e-02,  3.30e-02, -3.20e-02, -1.51e-02,\n",
      "         4.79e-02, -1.10e-02, -4.05e-03, -2.21e-02,  2.89e-02, -1.23e-02,\n",
      "        -2.63e-02,  4.15e-03,  2.13e-04, -1.31e-01, -5.42e-02,  5.05e-03,\n",
      "        -1.11e-02, -3.30e-03], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 0.11,  0.01,  0.05,  0.03,  0.04,  0.07,  0.03,  0.00,  0.07, -0.01,\n",
      "         0.02,  0.03,  0.03,  0.03,  0.05,  0.02,  0.02,  0.04,  0.03,  0.04,\n",
      "         0.02,  0.04,  0.03,  0.03,  0.04,  0.05,  0.02,  0.01,  0.03, -0.04,\n",
      "         0.05,  0.01,  0.03, -0.04,  0.01,  0.01,  0.02,  0.07,  0.05,  0.00,\n",
      "         0.02,  0.02,  0.03,  0.04,  0.03,  0.03,  0.02,  0.01,  0.01,  0.00,\n",
      "         0.03, -0.01,  0.02,  0.05,  0.01,  0.02, -0.00,  0.01, -0.02, -0.01,\n",
      "         0.01, -0.00,  0.04,  0.01,  0.03,  0.01,  0.01,  0.00, -0.01,  0.01,\n",
      "         0.00,  0.04,  0.00,  0.02,  0.01, -0.02,  0.01, -0.02,  0.02, -0.04,\n",
      "         0.01,  0.04,  0.02,  0.05,  0.02,  0.04,  0.01,  0.04,  0.01,  0.03,\n",
      "         0.06,  0.03,  0.01,  0.01,  0.02,  0.04, -0.00, -0.02,  0.06,  0.02,\n",
      "         0.02,  0.07,  0.04,  0.02,  0.02,  0.01,  0.03, -0.01,  0.01,  0.05,\n",
      "         0.00,  0.06, -0.01,  0.00,  0.01, -0.01,  0.04, -0.02,  0.03,  0.03,\n",
      "         0.02,  0.03,  0.02,  0.00,  0.02,  0.04,  0.00,  0.02,  0.03, -0.02,\n",
      "        -0.01, -0.04, -0.01, -0.01, -0.02,  0.02,  0.01,  0.06, -0.01,  0.00,\n",
      "         0.04, -0.00,  0.02,  0.00,  0.03,  0.02,  0.00,  0.01,  0.05,  0.07,\n",
      "         0.01,  0.01,  0.00,  0.01,  0.03, -0.00,  0.02,  0.01, -0.00,  0.03,\n",
      "         0.01,  0.02, -0.00,  0.05,  0.03,  0.03, -0.01, -0.01, -0.03,  0.01,\n",
      "         0.01, -0.00,  0.01,  0.05, -0.01,  0.01, -0.02,  0.01, -0.02, -0.01,\n",
      "         0.02,  0.00, -0.01, -0.04,  0.04, -0.01, -0.02, -0.01, -0.02, -0.03,\n",
      "         0.00, -0.03, -0.04, -0.01, -0.03, -0.05,  0.05, -0.01,  0.01,  0.05,\n",
      "        -0.02,  0.04, -0.01, -0.01, -0.00, -0.01,  0.00, -0.03,  0.02, -0.01,\n",
      "        -0.00, -0.02, -0.03,  0.01,  0.03, -0.04, -0.01, -0.03, -0.01, -0.01,\n",
      "        -0.01,  0.00,  0.02,  0.01, -0.00,  0.02,  0.01, -0.03,  0.02, -0.01,\n",
      "         0.00, -0.01,  0.01,  0.00,  0.02, -0.00, -0.01, -0.01,  0.01, -0.04,\n",
      "         0.02,  0.00,  0.01, -0.00, -0.02, -0.02, -0.01, -0.01, -0.01,  0.03,\n",
      "         0.01,  0.03, -0.03, -0.01, -0.00,  0.01,  0.01,  0.01, -0.02, -0.00,\n",
      "        -0.03,  0.00,  0.00, -0.03, -0.06, -0.00,  0.08,  0.02,  0.00, -0.03,\n",
      "         0.03,  0.01,  0.02,  0.03,  0.04, -0.06, -0.04,  0.01, -0.02, -0.04,\n",
      "        -0.01, -0.02,  0.02,  0.01, -0.02, -0.02,  0.03, -0.09, -0.03, -0.02,\n",
      "         0.02, -0.01, -0.02,  0.01, -0.01,  0.02, -0.02, -0.03, -0.01,  0.01,\n",
      "        -0.03, -0.02,  0.02, -0.02,  0.01,  0.00, -0.00, -0.03, -0.05, -0.04,\n",
      "         0.04,  0.04,  0.01, -0.01, -0.03, -0.00, -0.05,  0.01,  0.00,  0.01,\n",
      "        -0.03, -0.02,  0.02, -0.02, -0.02,  0.03, -0.05, -0.07, -0.00, -0.01,\n",
      "        -0.04, -0.01, -0.03,  0.01, -0.04, -0.02,  0.02,  0.02, -0.01, -0.02,\n",
      "         0.01, -0.01,  0.01, -0.03, -0.01, -0.02,  0.01, -0.02,  0.03, -0.03,\n",
      "         0.05, -0.05, -0.01, -0.04, -0.02, -0.00, -0.06,  0.02,  0.00,  0.06,\n",
      "        -0.01, -0.04, -0.04, -0.00,  0.01, -0.04,  0.04, -0.03, -0.02, -0.00,\n",
      "        -0.03,  0.00,  0.01, -0.03, -0.09,  0.03, -0.03, -0.03,  0.03, -0.01,\n",
      "        -0.04, -0.00,  0.01, -0.06, -0.06, -0.02,  0.02, -0.02,  0.01, -0.02,\n",
      "        -0.01,  0.01,  0.01, -0.01,  0.02, -0.02, -0.02,  0.01, -0.02, -0.03,\n",
      "         0.00,  0.01,  0.02, -0.05,  0.01, -0.01, -0.00, -0.02, -0.04,  0.00,\n",
      "        -0.01, -0.05,  0.03,  0.01,  0.00,  0.01, -0.00,  0.02, -0.05,  0.01,\n",
      "        -0.02, -0.01, -0.03, -0.03,  0.03, -0.04, -0.01, -0.03,  0.00,  0.03,\n",
      "         0.01,  0.07, -0.04, -0.04, -0.01,  0.03, -0.01, -0.04,  0.00, -0.06,\n",
      "        -0.03, -0.05,  0.04,  0.00, -0.05,  0.01, -0.05, -0.01, -0.01, -0.08,\n",
      "        -0.07, -0.03, -0.00, -0.09, -0.01, -0.00,  0.01, -0.01,  0.00,  0.00,\n",
      "        -0.05,  0.00, -0.03, -0.00,  0.00, -0.02,  0.05, -0.03,  0.02, -0.01,\n",
      "        -0.08, -0.04,  0.01,  0.02, -0.01,  0.01,  0.01,  0.00,  0.03, -0.01,\n",
      "        -0.02,  0.00, -0.04, -0.07,  0.01, -0.03, -0.02, -0.03,  0.00,  0.03,\n",
      "         0.04, -0.01, -0.04,  0.01, -0.02,  0.03, -0.01, -0.01,  0.03, -0.01,\n",
      "        -0.00,  0.00,  0.03, -0.03, -0.04,  0.01, -0.00, -0.13, -0.05, -0.02,\n",
      "        -0.01, -0.00], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.11,  0.01,  0.04,  0.01,  0.03,  0.06,  0.04,  0.03,  0.07, -0.01,\n",
      "         0.02,  0.03,  0.02,  0.03,  0.08,  0.02,  0.01,  0.04,  0.05,  0.04,\n",
      "         0.02,  0.03,  0.03,  0.02,  0.04,  0.04,  0.01,  0.02,  0.04, -0.03,\n",
      "         0.06,  0.02,  0.03, -0.03,  0.01,  0.01,  0.02,  0.05,  0.06,  0.02,\n",
      "         0.02,  0.03,  0.03,  0.04,  0.03,  0.04,  0.02,  0.01,  0.01,  0.00,\n",
      "         0.03,  0.02,  0.02,  0.06,  0.01,  0.02, -0.01,  0.01,  0.02, -0.01,\n",
      "         0.01,  0.00,  0.04,  0.01,  0.03,  0.01,  0.01, -0.00, -0.01,  0.01,\n",
      "         0.02,  0.03,  0.00,  0.03,  0.01, -0.02,  0.01, -0.02,  0.02, -0.03,\n",
      "        -0.00,  0.02,  0.02,  0.03,  0.02,  0.05,  0.01,  0.04,  0.01,  0.03,\n",
      "         0.06,  0.03,  0.04,  0.01,  0.02,  0.04,  0.04, -0.02,  0.04,  0.02,\n",
      "         0.02,  0.08,  0.04,  0.01,  0.02,  0.01,  0.02,  0.02,  0.02,  0.04,\n",
      "         0.00,  0.09, -0.01,  0.00,  0.01, -0.01,  0.04, -0.00,  0.03,  0.03,\n",
      "         0.02,  0.03,  0.01,  0.01,  0.02,  0.04,  0.00,  0.02,  0.04, -0.01,\n",
      "        -0.01, -0.04, -0.01, -0.00, -0.02, -0.00,  0.01,  0.08,  0.00,  0.01,\n",
      "         0.04, -0.00,  0.01,  0.00,  0.03,  0.01,  0.00,  0.01,  0.06,  0.06,\n",
      "        -0.01,  0.01,  0.00,  0.02, -0.01, -0.00,  0.02,  0.01,  0.00,  0.02,\n",
      "        -0.01,  0.01,  0.00,  0.05,  0.03,  0.03, -0.01, -0.00, -0.03,  0.02,\n",
      "         0.00, -0.00,  0.01,  0.05, -0.01,  0.01, -0.02,  0.01, -0.02, -0.01,\n",
      "         0.02,  0.00, -0.01, -0.04,  0.03, -0.01, -0.02, -0.01, -0.01, -0.02,\n",
      "         0.00, -0.01, -0.03, -0.02, -0.02, -0.05,  0.04, -0.00,  0.01,  0.05,\n",
      "        -0.02,  0.01, -0.01, -0.01, -0.00, -0.01, -0.01, -0.03,  0.02, -0.01,\n",
      "         0.00, -0.02, -0.03,  0.02,  0.03, -0.05,  0.01,  0.01, -0.01, -0.01,\n",
      "        -0.01,  0.00,  0.00,  0.02,  0.00,  0.02,  0.01, -0.03,  0.01, -0.01,\n",
      "         0.00, -0.01,  0.01,  0.00,  0.02, -0.00, -0.01, -0.01,  0.00, -0.03,\n",
      "         0.02,  0.00,  0.01,  0.00, -0.01, -0.02, -0.02, -0.01, -0.01,  0.03,\n",
      "         0.01,  0.03, -0.03, -0.00, -0.04,  0.01,  0.02,  0.00, -0.02, -0.00,\n",
      "        -0.04,  0.01, -0.01, -0.03, -0.05, -0.03,  0.09,  0.02, -0.00, -0.05,\n",
      "         0.03,  0.01,  0.03,  0.03,  0.04, -0.05, -0.04,  0.03, -0.02, -0.04,\n",
      "        -0.01, -0.04,  0.02,  0.01, -0.02, -0.01,  0.03, -0.02, -0.02, -0.01,\n",
      "         0.02, -0.01, -0.03,  0.01,  0.02,  0.02, -0.03, -0.06, -0.05,  0.01,\n",
      "        -0.03, -0.02,  0.02, -0.02,  0.01, -0.00, -0.01, -0.02, -0.04, -0.04,\n",
      "         0.04,  0.04,  0.02, -0.01, -0.03, -0.00, -0.05,  0.02,  0.00,  0.01,\n",
      "        -0.03, -0.02,  0.02, -0.02, -0.00,  0.02, -0.02, -0.09,  0.01, -0.01,\n",
      "        -0.04, -0.01, -0.04, -0.01, -0.04, -0.01,  0.02,  0.02, -0.00, -0.02,\n",
      "         0.01, -0.01, -0.02, -0.03, -0.01, -0.02,  0.01, -0.02,  0.03, -0.03,\n",
      "         0.03, -0.05, -0.01, -0.05, -0.02, -0.01, -0.06,  0.01, -0.01,  0.05,\n",
      "        -0.01, -0.04, -0.04,  0.00,  0.01, -0.05,  0.04, -0.03, -0.02, -0.00,\n",
      "        -0.03,  0.00,  0.00, -0.08, -0.08,  0.04, -0.02, -0.03,  0.02, -0.01,\n",
      "        -0.04, -0.00,  0.01, -0.04, -0.04, -0.02,  0.02, -0.02,  0.01, -0.03,\n",
      "        -0.01, -0.00, -0.00, -0.01,  0.02, -0.02, -0.02,  0.01, -0.04, -0.04,\n",
      "         0.00,  0.01,  0.02, -0.05,  0.01, -0.04, -0.04, -0.03, -0.04, -0.01,\n",
      "        -0.01, -0.05,  0.03,  0.01,  0.00,  0.01, -0.00,  0.02, -0.02,  0.01,\n",
      "        -0.03, -0.01, -0.03, -0.03,  0.03, -0.05,  0.00, -0.06, -0.00,  0.03,\n",
      "         0.01,  0.06, -0.05, -0.04,  0.01,  0.03, -0.01, -0.01, -0.00, -0.06,\n",
      "        -0.03, -0.03, -0.02,  0.01, -0.04,  0.00, -0.05, -0.01, -0.01, -0.07,\n",
      "        -0.06, -0.03, -0.00, -0.10, -0.02, -0.01,  0.01, -0.01,  0.00, -0.01,\n",
      "        -0.05,  0.02, -0.02, -0.01, -0.04, -0.05,  0.03, -0.03, -0.07, -0.01,\n",
      "        -0.09, -0.05,  0.00,  0.01,  0.00,  0.02,  0.00, -0.00,  0.03, -0.00,\n",
      "        -0.03, -0.01, -0.01, -0.08, -0.01, -0.00, -0.02, -0.03,  0.00,  0.03,\n",
      "         0.04, -0.01, -0.04,  0.01, -0.03,  0.03, -0.04, -0.01,  0.04, -0.01,\n",
      "        -0.00, -0.05,  0.03, -0.04, -0.04,  0.01, -0.00, -0.13, -0.06, -0.02,\n",
      "         0.01, -0.01], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 1.06e-01,  1.39e-02,  1.72e-02,  2.86e-02,  1.00e-02,  5.98e-02,\n",
      "         4.02e-02,  2.47e-02,  6.06e-02, -7.56e-03,  1.92e-02,  2.79e-02,\n",
      "         2.34e-02,  2.69e-02,  5.89e-02,  1.73e-02,  9.10e-03,  4.10e-02,\n",
      "         3.32e-02,  3.35e-02,  1.91e-02,  3.20e-02,  1.78e-02, -1.75e-02,\n",
      "         3.91e-02,  3.75e-02,  1.15e-03,  2.04e-02,  2.57e-02, -2.82e-02,\n",
      "         6.13e-02,  2.16e-02,  3.19e-02, -2.09e-02,  1.83e-02,  1.30e-02,\n",
      "         2.07e-02,  5.57e-02,  4.94e-02,  1.19e-02,  1.79e-02,  1.19e-02,\n",
      "         4.52e-03,  3.64e-02,  2.64e-02,  3.59e-02,  1.90e-02,  1.36e-02,\n",
      "         1.01e-02,  5.52e-03,  2.44e-02,  1.73e-02, -8.54e-03,  4.20e-02,\n",
      "         3.56e-03,  2.30e-02,  4.33e-03,  1.12e-02,  3.22e-02,  8.65e-03,\n",
      "         7.76e-03,  2.86e-05,  4.47e-02,  9.56e-03,  3.34e-02,  1.86e-02,\n",
      "         1.37e-02,  6.83e-03, -1.00e-02,  1.65e-02, -1.60e-02,  4.32e-02,\n",
      "         5.20e-03,  3.25e-02,  1.13e-02, -2.05e-02,  1.78e-02, -1.79e-02,\n",
      "         3.08e-02, -3.07e-02,  1.24e-02,  3.22e-02,  1.71e-02,  5.29e-02,\n",
      "         1.37e-02,  4.57e-02,  1.32e-02,  3.18e-02,  6.04e-03,  3.01e-02,\n",
      "         3.15e-02,  2.92e-02, -3.05e-02,  1.48e-02,  2.60e-02,  4.02e-02,\n",
      "         4.51e-02, -1.87e-02,  5.60e-02,  2.10e-02,  1.93e-02,  6.89e-02,\n",
      "         3.60e-02,  1.32e-02, -1.27e-03,  7.72e-03,  2.06e-02, -6.38e-03,\n",
      "        -8.07e-03,  4.08e-02, -3.78e-04,  5.64e-02, -7.59e-03,  1.84e-03,\n",
      "         1.15e-02, -9.76e-03,  4.42e-02, -1.13e-02,  3.06e-02,  2.82e-02,\n",
      "         8.50e-03,  2.69e-02,  7.56e-03,  7.69e-03,  2.32e-02,  7.11e-02,\n",
      "         1.07e-03,  2.78e-02,  3.89e-02, -1.53e-02, -9.01e-03, -4.04e-02,\n",
      "        -8.87e-03, -2.44e-03, -1.99e-02,  1.70e-02,  1.55e-02,  5.95e-02,\n",
      "         3.99e-03,  4.52e-03,  4.02e-02, -5.04e-03, -1.54e-03,  1.36e-03,\n",
      "         2.97e-02,  2.29e-02,  4.27e-03,  1.31e-02,  5.90e-02,  5.73e-02,\n",
      "         1.67e-03,  1.37e-02,  2.72e-03,  2.03e-02,  1.89e-02, -6.02e-03,\n",
      "         1.42e-02,  1.25e-02,  4.52e-03,  2.54e-02,  9.19e-04,  1.16e-02,\n",
      "        -2.72e-03,  4.41e-02,  2.96e-02,  2.71e-02, -7.32e-03,  4.22e-05,\n",
      "        -2.43e-02,  1.83e-02,  2.13e-02,  1.01e-03,  1.43e-02,  5.52e-02,\n",
      "        -7.69e-03,  8.44e-03, -1.84e-02,  8.45e-03, -1.80e-02, -1.20e-02,\n",
      "         4.19e-02,  8.05e-03, -8.09e-03, -3.52e-02,  3.48e-02, -1.29e-02,\n",
      "        -1.87e-02, -7.34e-03, -1.96e-02, -1.82e-02,  1.23e-03,  1.94e-02,\n",
      "        -3.95e-02,  1.86e-04, -1.51e-02, -4.50e-02,  3.98e-02, -3.48e-03,\n",
      "         1.83e-02,  4.93e-02, -1.33e-02,  1.91e-02, -9.59e-03, -4.96e-03,\n",
      "        -2.98e-03,  5.53e-03,  1.53e-04, -2.51e-02,  2.04e-02, -4.82e-03,\n",
      "        -5.11e-03, -1.69e-02, -3.04e-02,  1.86e-02,  2.23e-02, -3.22e-02,\n",
      "         8.48e-03, -2.65e-02, -1.84e-03, -1.38e-02, -4.48e-03,  2.94e-04,\n",
      "         2.30e-02,  3.00e-02, -6.72e-03,  1.55e-02,  6.17e-03, -2.65e-02,\n",
      "         2.71e-02, -1.08e-02,  4.47e-03,  4.90e-03,  1.30e-02, -6.30e-04,\n",
      "         4.01e-02, -2.92e-03, -5.01e-03, -9.93e-03,  5.59e-03, -3.38e-02,\n",
      "         1.61e-02,  3.21e-03,  7.38e-03, -9.42e-03, -1.43e-02, -2.12e-02,\n",
      "        -1.41e-02, -8.88e-03, -3.09e-04,  2.52e-02,  9.14e-03,  2.43e-02,\n",
      "        -2.63e-02, -1.45e-03, -1.32e-02,  1.05e-02,  1.54e-02,  6.22e-03,\n",
      "        -2.28e-02, -2.43e-03, -3.68e-02,  8.00e-03, -1.90e-02, -2.26e-02,\n",
      "        -5.46e-02, -3.20e-03,  9.05e-02,  2.28e-02,  1.21e-03, -4.46e-02,\n",
      "         2.28e-02,  1.37e-02,  3.35e-02,  2.98e-02,  4.71e-02, -6.33e-02,\n",
      "        -3.69e-02,  1.64e-02, -2.00e-02, -3.79e-02, -7.52e-03, -2.75e-02,\n",
      "         1.89e-02,  9.63e-03, -1.35e-02, -2.60e-02,  2.73e-02, -7.96e-02,\n",
      "        -2.35e-02, -4.51e-03,  1.91e-02, -8.74e-03, -2.50e-02,  8.01e-03,\n",
      "        -1.66e-02,  2.14e-02, -1.53e-02, -5.36e-02, -6.61e-03,  6.49e-03,\n",
      "        -2.68e-02, -1.31e-02,  1.44e-02, -1.88e-02,  7.46e-03,  5.71e-05,\n",
      "        -1.21e-02, -2.43e-02, -4.78e-02, -4.38e-02,  3.60e-02,  3.32e-02,\n",
      "         6.76e-03, -1.67e-02, -2.68e-02, -9.01e-04, -4.62e-02,  4.20e-03,\n",
      "         4.18e-03,  4.15e-03, -9.65e-03, -2.32e-02,  1.60e-02, -2.00e-02,\n",
      "        -1.44e-02,  9.01e-03, -2.91e-02, -8.79e-02,  2.62e-03, -1.91e-04,\n",
      "        -3.81e-02, -9.89e-03, -2.27e-02, -1.83e-02, -4.47e-02, -5.31e-03,\n",
      "         1.83e-02,  1.58e-02, -4.50e-03, -2.27e-02,  1.05e-02, -8.39e-03,\n",
      "        -2.43e-02, -3.33e-02, -1.85e-02, -2.32e-02,  1.35e-02, -3.49e-02,\n",
      "         2.59e-02, -3.30e-02,  2.55e-02, -4.62e-02, -4.45e-03, -3.82e-02,\n",
      "        -2.74e-02, -1.08e-03, -5.08e-02,  1.85e-02, -4.81e-03,  5.43e-02,\n",
      "        -9.12e-03, -4.08e-02, -3.88e-02,  4.28e-03,  2.70e-03, -4.48e-02,\n",
      "         3.38e-02, -2.77e-02, -2.14e-02, -3.86e-03, -3.04e-02,  5.84e-03,\n",
      "         9.15e-04, -9.23e-02, -8.12e-02,  3.44e-02, -3.11e-02, -3.39e-02,\n",
      "        -6.92e-03, -6.16e-03, -3.36e-02, -3.91e-03,  6.73e-03, -3.95e-02,\n",
      "        -3.83e-02, -2.71e-02,  1.33e-02, -1.73e-02,  5.13e-03, -3.08e-02,\n",
      "        -1.85e-02, -9.19e-03,  1.54e-02, -1.11e-02,  1.57e-02, -2.03e-02,\n",
      "        -1.77e-02,  1.58e-03, -3.35e-02, -2.48e-02,  3.03e-03,  4.76e-03,\n",
      "         1.21e-02, -5.26e-02,  1.03e-02, -4.33e-02, -4.76e-02, -3.30e-02,\n",
      "        -3.92e-02, -6.99e-03, -1.07e-02, -5.28e-02,  2.54e-02,  5.53e-03,\n",
      "         2.13e-03,  8.85e-03, -2.34e-03,  1.27e-02, -4.93e-02,  7.14e-03,\n",
      "        -2.68e-02, -1.02e-02, -3.12e-02, -3.08e-02,  3.05e-02, -5.54e-02,\n",
      "        -2.17e-02, -3.02e-02, -7.13e-04,  2.86e-02,  1.39e-02,  2.04e-02,\n",
      "        -5.86e-02, -4.34e-02, -1.23e-02,  2.90e-02, -6.77e-03, -4.31e-02,\n",
      "        -1.08e-03, -5.82e-02, -2.70e-02, -5.90e-02, -3.12e-02,  1.51e-02,\n",
      "        -4.97e-02, -1.46e-04, -4.85e-02, -9.58e-03, -1.08e-02, -6.24e-02,\n",
      "        -1.77e-02, -4.17e-02, -9.59e-05, -3.86e-02, -1.65e-02, -8.55e-03,\n",
      "         1.05e-02, -6.02e-03,  1.72e-03, -7.34e-03, -5.05e-02,  2.39e-03,\n",
      "        -2.90e-02,  3.87e-03, -3.83e-02, -6.32e-02,  2.84e-02, -5.05e-02,\n",
      "        -1.14e-01, -8.96e-03, -8.24e-02, -4.69e-02,  2.18e-03,  5.71e-03,\n",
      "        -1.63e-02,  1.25e-02, -1.06e-02, -4.61e-03,  2.15e-02,  1.63e-02,\n",
      "        -2.80e-02, -1.61e-02, -3.13e-02, -8.56e-02,  2.01e-03, -2.62e-02,\n",
      "        -1.81e-02, -3.05e-02,  1.39e-04,  3.04e-02,  4.09e-02, -5.82e-03,\n",
      "        -4.63e-02,  7.90e-03, -3.19e-02,  4.89e-02, -1.57e-02, -1.45e-02,\n",
      "         3.61e-02,  1.11e-02, -3.91e-03, -3.13e-02,  2.78e-02, -5.25e-02,\n",
      "        -4.23e-02,  5.99e-03, -8.59e-04, -5.24e-02, -5.10e-02, -2.34e-02,\n",
      "        -1.25e-02, -1.17e-02], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.08e-01,  1.36e-02,  3.13e-02,  2.08e-02,  2.15e-02,  4.54e-02,\n",
      "         5.37e-02,  1.97e-02,  6.45e-02, -7.04e-03,  1.72e-02,  2.79e-02,\n",
      "         1.21e-02,  2.47e-02,  4.68e-02,  1.54e-02,  8.74e-03,  4.09e-02,\n",
      "         2.98e-02,  3.28e-02,  2.34e-02,  3.57e-02,  1.81e-02,  1.97e-02,\n",
      "         3.49e-02,  4.53e-02, -9.06e-03, -1.17e-04,  3.16e-02, -2.65e-02,\n",
      "         5.89e-02,  2.69e-02,  3.20e-02, -1.86e-02,  2.15e-02,  1.34e-02,\n",
      "         1.83e-02,  5.60e-02,  5.07e-02,  1.40e-02,  1.82e-02,  2.50e-02,\n",
      "         3.00e-02,  3.53e-02,  7.62e-03,  3.79e-02,  1.96e-02,  1.38e-02,\n",
      "         1.52e-02,  7.69e-03,  2.94e-02,  2.06e-02, -8.74e-03,  5.94e-02,\n",
      "         6.81e-03,  2.36e-02, -4.41e-04,  1.27e-02, -2.00e-02,  6.47e-03,\n",
      "         9.86e-03,  3.93e-03,  4.33e-02,  1.25e-02,  2.99e-02,  1.37e-02,\n",
      "         1.45e-02,  1.00e-02, -9.77e-03,  1.62e-02,  2.49e-02,  4.54e-02,\n",
      "         5.43e-03,  3.76e-02,  1.46e-02, -1.73e-02,  2.24e-02, -1.75e-02,\n",
      "         3.36e-02, -3.44e-02, -2.58e-03,  5.47e-02,  1.08e-02,  4.22e-02,\n",
      "         1.74e-02,  4.79e-02,  1.14e-02,  4.59e-03,  6.10e-03,  3.39e-02,\n",
      "         5.70e-02,  2.89e-02, -2.85e-02,  1.84e-02,  2.80e-02,  2.27e-02,\n",
      "         3.82e-02, -1.84e-02,  5.14e-02,  2.41e-02,  1.20e-02,  9.12e-02,\n",
      "         3.34e-02,  1.29e-02,  5.00e-03,  8.29e-03,  1.18e-02,  1.59e-02,\n",
      "         1.42e-02,  5.06e-02,  2.61e-03,  5.41e-02, -7.32e-03, -3.64e-03,\n",
      "         1.13e-02, -8.52e-03,  5.10e-02, -1.76e-02,  3.03e-02,  2.78e-02,\n",
      "         1.64e-02,  2.49e-02,  4.71e-03,  7.17e-03,  2.23e-02,  2.96e-02,\n",
      "         4.58e-03,  2.57e-02,  4.04e-02, -1.10e-02, -8.78e-03, -3.91e-02,\n",
      "        -8.01e-03, -3.78e-03, -1.94e-02,  1.35e-02,  1.64e-02,  6.20e-02,\n",
      "         6.47e-03,  7.92e-03,  3.77e-02, -1.17e-02,  1.51e-03,  3.43e-03,\n",
      "         3.19e-02,  2.65e-02,  2.62e-03,  1.31e-02,  3.52e-02,  5.54e-02,\n",
      "        -1.04e-03,  1.35e-02,  4.76e-03,  2.69e-02,  3.34e-02, -4.96e-03,\n",
      "         2.00e-02,  1.01e-02, -7.29e-04,  2.94e-02,  1.27e-03,  1.13e-02,\n",
      "         2.56e-03,  4.78e-02,  3.23e-02,  3.08e-02, -6.38e-03, -1.44e-04,\n",
      "        -2.32e-02,  1.68e-02,  1.88e-02,  3.00e-03,  1.65e-02,  5.64e-02,\n",
      "        -6.61e-03,  9.83e-03, -1.81e-02,  9.85e-03, -1.20e-02, -1.09e-02,\n",
      "         2.73e-02,  1.01e-02, -3.28e-03, -3.34e-02,  3.62e-02, -1.19e-02,\n",
      "        -1.88e-02, -6.34e-03, -2.09e-02, -1.91e-02,  1.73e-03, -2.39e-02,\n",
      "        -3.21e-02,  1.32e-02, -1.44e-02, -4.46e-02,  4.22e-02, -3.66e-03,\n",
      "         1.64e-02,  4.82e-02, -1.44e-02,  3.08e-02, -6.94e-03, -4.32e-03,\n",
      "        -1.97e-03, -9.95e-03,  7.79e-03, -1.88e-02,  2.16e-02, -4.59e-03,\n",
      "         1.18e-02, -1.49e-02, -3.01e-02,  2.29e-02,  2.89e-02, -3.06e-02,\n",
      "         3.88e-03, -3.24e-03, -7.37e-06, -1.16e-02, -2.74e-03,  7.92e-03,\n",
      "         1.65e-02,  2.71e-02,  4.46e-04,  2.15e-02,  6.12e-03, -2.61e-02,\n",
      "         4.93e-02, -1.43e-02,  4.07e-03,  4.20e-03,  1.36e-02, -6.02e-03,\n",
      "         3.13e-02,  7.30e-04, -2.37e-03, -1.02e-02,  6.96e-03, -3.24e-02,\n",
      "         1.65e-02,  3.86e-03,  7.07e-03,  1.74e-03, -1.33e-02, -2.03e-02,\n",
      "        -1.22e-02, -9.86e-03,  5.74e-03,  2.46e-02,  2.07e-02,  2.48e-02,\n",
      "        -2.69e-02,  1.37e-04, -2.01e-02,  9.82e-03,  1.52e-02,  7.87e-03,\n",
      "        -2.16e-02, -1.96e-03, -1.50e-02,  9.64e-03, -8.23e-03, -1.28e-02,\n",
      "        -5.37e-02, -1.12e-02,  9.02e-02,  2.28e-02, -1.27e-03,  1.51e-02,\n",
      "         1.70e-02,  1.27e-02,  2.35e-02,  2.70e-02,  3.83e-02, -6.31e-02,\n",
      "        -3.69e-02,  4.57e-03, -1.86e-02, -3.74e-02, -8.01e-03, -3.51e-02,\n",
      "         1.83e-02,  7.87e-03, -1.14e-02, -1.41e-02,  2.68e-02, -7.70e-02,\n",
      "        -2.22e-02, -3.81e-03,  1.77e-02, -9.45e-03, -1.55e-02,  3.96e-03,\n",
      "        -2.20e-02,  2.12e-02, -1.78e-02, -4.08e-02, -4.34e-02,  6.26e-03,\n",
      "        -2.32e-02, -2.07e-02,  1.40e-02, -1.91e-02,  5.86e-03, -1.06e-03,\n",
      "        -1.58e-02, -2.17e-02, -4.05e-02, -4.19e-02,  3.19e-02,  4.04e-02,\n",
      "         6.94e-03, -1.63e-02, -3.66e-02, -4.89e-04, -4.18e-02,  1.08e-02,\n",
      "         4.93e-04,  5.12e-03, -3.24e-02, -2.14e-02,  1.20e-02, -2.00e-02,\n",
      "        -1.75e-02,  2.31e-02, -5.35e-02, -6.30e-02,  6.17e-03, -2.74e-04,\n",
      "        -2.51e-02, -4.04e-03, -2.44e-02,  6.05e-03, -4.23e-02, -1.47e-02,\n",
      "         1.77e-02,  1.56e-02, -3.34e-03, -2.08e-02,  1.02e-02, -8.59e-03,\n",
      "        -6.83e-03, -2.37e-02, -1.06e-02, -2.09e-02,  1.37e-02, -3.69e-02,\n",
      "         2.56e-02, -3.33e-02,  1.85e-02, -4.63e-02, -7.80e-03, -3.43e-02,\n",
      "        -2.62e-02, -2.03e-03, -4.87e-02,  1.28e-02, -5.54e-03,  5.37e-02,\n",
      "        -2.25e-03, -4.31e-02, -3.97e-02, -1.13e-04, -2.60e-03, -5.25e-02,\n",
      "         3.47e-02, -2.97e-02, -2.18e-02, -3.86e-03, -2.88e-02,  7.84e-03,\n",
      "        -2.95e-03, -8.93e-02, -7.35e-02,  3.34e-02, -2.48e-02, -3.38e-02,\n",
      "        -2.90e-02, -6.36e-03, -3.44e-02, -8.28e-03,  5.85e-03, -4.46e-02,\n",
      "        -6.53e-02,  1.02e-02,  9.66e-03, -1.74e-02,  3.14e-03, -3.20e-02,\n",
      "        -2.60e-02, -9.01e-03, -1.04e-02, -1.13e-02,  1.41e-02, -2.02e-02,\n",
      "        -1.47e-02,  2.77e-03, -2.73e-02, -4.06e-02,  2.26e-03,  1.30e-02,\n",
      "         2.31e-02, -5.42e-02,  1.04e-02, -1.83e-02, -4.79e-02, -3.58e-02,\n",
      "        -3.95e-02, -9.58e-03, -1.40e-02, -5.35e-02,  2.68e-02,  5.50e-03,\n",
      "         2.41e-03,  6.82e-03, -3.07e-03,  1.01e-02, -4.79e-02,  7.52e-03,\n",
      "        -1.52e-02, -1.06e-02, -3.12e-02, -3.10e-02,  3.02e-02, -5.49e-02,\n",
      "        -1.97e-02, -5.07e-02,  2.48e-02,  2.77e-02,  1.44e-02,  2.46e-02,\n",
      "        -5.20e-02, -4.37e-02, -2.34e-02,  2.42e-02, -7.22e-03, -4.31e-02,\n",
      "        -2.15e-03, -5.78e-02, -2.96e-02, -6.49e-02, -1.58e-02, -2.34e-03,\n",
      "        -5.71e-02, -3.45e-03, -5.18e-02, -1.10e-02, -5.96e-03, -6.23e-02,\n",
      "        -6.70e-02, -3.22e-02, -5.66e-04, -3.90e-02, -1.81e-02, -1.18e-02,\n",
      "         9.58e-03, -4.71e-03,  8.53e-04, -3.10e-03,  7.90e-03,  1.54e-03,\n",
      "        -3.23e-02,  4.19e-03, -4.01e-02, -6.62e-02,  2.45e-02, -4.51e-02,\n",
      "        -1.29e-01, -1.07e-02, -8.83e-02, -4.80e-02, -3.73e-04,  6.95e-03,\n",
      "        -1.34e-02,  1.02e-02, -2.29e-02, -1.10e-02,  2.18e-02, -1.70e-02,\n",
      "        -2.73e-02, -1.03e-02, -3.17e-02, -9.38e-02,  2.11e-02, -2.77e-02,\n",
      "        -1.91e-02, -3.09e-02,  1.05e-02,  2.28e-02,  4.08e-02, -2.00e-02,\n",
      "        -4.50e-02,  7.64e-03, -3.61e-02,  2.73e-02, -4.15e-02, -1.47e-02,\n",
      "         2.87e-02, -1.43e-02, -4.95e-03, -3.88e-02,  2.73e-02, -4.92e-02,\n",
      "        -4.29e-02,  9.54e-03, -1.02e-03, -1.21e-01, -4.82e-02, -2.63e-02,\n",
      "        -1.35e-02, -1.39e-02], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 1.11e-01,  1.19e-02,  1.21e-02,  1.59e-02,  5.69e-03,  3.90e-02,\n",
      "         2.66e-02,  1.53e-02,  6.30e-02, -7.76e-03,  1.76e-02,  2.81e-02,\n",
      "         1.17e-02,  2.75e-02,  5.91e-02,  1.44e-02,  8.05e-03,  4.07e-02,\n",
      "         1.57e-02,  3.13e-02,  2.34e-02,  3.35e-02,  1.74e-02,  1.77e-02,\n",
      "         2.07e-02,  4.54e-02,  2.01e-02,  1.82e-02,  3.84e-02, -2.52e-02,\n",
      "         6.43e-02,  3.24e-02,  3.48e-02, -1.75e-02,  1.68e-02,  1.35e-02,\n",
      "         1.91e-02,  5.65e-02,  4.67e-02,  9.18e-03,  1.81e-02,  2.32e-02,\n",
      "         2.90e-02,  3.53e-02,  3.17e-02,  3.29e-02,  1.96e-02,  1.45e-02,\n",
      "         2.03e-02,  8.78e-03,  3.00e-02,  2.29e-02, -8.38e-03,  3.67e-02,\n",
      "         6.44e-03,  2.57e-02,  9.56e-03,  1.21e-02,  3.75e-02,  7.48e-03,\n",
      "         9.02e-03,  1.19e-03,  4.86e-02,  1.20e-02,  2.96e-02,  2.25e-02,\n",
      "         1.49e-02, -8.39e-03, -9.56e-03,  1.46e-02,  3.26e-02,  5.01e-02,\n",
      "         5.03e-03,  3.25e-02,  1.88e-02, -1.61e-02,  2.37e-02, -2.69e-02,\n",
      "         3.60e-02, -2.65e-02,  1.38e-02,  6.75e-02,  1.70e-02,  2.35e-02,\n",
      "         1.02e-02,  4.33e-02,  1.20e-02,  2.39e-02,  6.42e-03,  3.14e-02,\n",
      "         5.39e-02,  2.85e-02,  2.46e-02,  2.05e-02,  2.75e-02,  4.25e-02,\n",
      "         6.13e-02, -1.93e-02,  4.31e-02,  2.31e-02,  1.03e-02,  6.14e-02,\n",
      "         3.19e-02,  1.51e-02,  1.10e-02,  9.08e-03,  2.14e-02,  1.88e-02,\n",
      "         1.61e-02,  3.24e-02,  3.38e-03,  5.65e-02, -1.12e-02,  8.94e-03,\n",
      "         1.25e-02, -5.81e-03,  5.26e-02, -9.70e-03,  3.25e-02,  2.73e-02,\n",
      "         2.45e-02,  1.75e-02,  4.72e-03,  4.51e-03,  2.38e-02,  2.73e-02,\n",
      "         1.14e-02,  2.84e-02,  4.59e-02, -8.83e-03, -8.76e-03, -3.92e-02,\n",
      "        -1.25e-02, -2.45e-03, -1.90e-02, -5.62e-03,  1.97e-02,  3.09e-02,\n",
      "         5.89e-03,  8.78e-03,  3.41e-02, -3.07e-03,  9.17e-04,  5.33e-03,\n",
      "         2.73e-02,  1.49e-02,  4.48e-03,  1.30e-02,  4.05e-02,  5.37e-02,\n",
      "         3.12e-03,  1.37e-02,  5.12e-05,  3.09e-02,  3.79e-02, -2.61e-03,\n",
      "         2.45e-02,  8.58e-03,  7.02e-03,  4.51e-02, -1.09e-03,  8.19e-03,\n",
      "        -4.59e-03,  3.17e-02,  3.18e-02,  2.93e-02, -4.03e-03,  4.13e-03,\n",
      "        -1.97e-02,  2.25e-02,  1.07e-02,  4.74e-03,  1.15e-02,  6.10e-02,\n",
      "        -5.66e-03,  9.93e-03, -1.81e-02,  1.05e-02, -1.12e-02, -8.09e-03,\n",
      "         2.32e-02,  1.24e-02,  6.01e-03, -3.36e-02,  3.46e-02, -1.22e-02,\n",
      "        -1.85e-02, -9.31e-04, -1.93e-02, -1.99e-02,  2.01e-03,  2.70e-03,\n",
      "        -2.96e-02,  5.19e-03, -9.98e-03, -4.56e-02,  5.18e-02, -6.60e-04,\n",
      "         1.82e-02,  4.76e-02, -1.38e-02,  4.34e-02, -1.16e-02, -4.57e-03,\n",
      "         4.81e-03, -8.85e-03,  1.68e-03, -1.48e-02,  2.17e-02, -1.82e-03,\n",
      "         2.92e-02, -1.47e-02, -2.90e-02,  2.08e-02,  2.67e-02, -2.81e-02,\n",
      "         1.54e-02, -2.81e-02, -8.15e-05, -1.62e-02, -2.67e-03,  1.37e-02,\n",
      "        -2.22e-03,  3.33e-02, -1.12e-02,  1.69e-02,  5.32e-03, -2.59e-02,\n",
      "         3.24e-02, -1.61e-02,  5.36e-03, -6.07e-03,  1.50e-02,  7.87e-04,\n",
      "         3.24e-02, -4.23e-04,  3.54e-03, -8.62e-03,  8.65e-03, -3.13e-02,\n",
      "         1.66e-02,  4.08e-03,  7.12e-03, -2.04e-03, -2.36e-02, -2.21e-02,\n",
      "        -1.25e-02, -8.34e-03,  2.05e-03,  2.26e-02,  7.97e-03,  1.49e-02,\n",
      "        -2.61e-02, -4.24e-03, -1.86e-02,  1.03e-02,  1.52e-02,  1.06e-02,\n",
      "        -1.93e-02, -5.43e-04, -2.45e-02,  1.19e-02, -1.26e-02,  1.44e-02,\n",
      "        -4.93e-02, -2.23e-02,  7.32e-02,  2.27e-02, -8.03e-05, -5.29e-02,\n",
      "         1.00e-02,  1.23e-02,  2.82e-02,  2.60e-02,  3.34e-02, -4.58e-02,\n",
      "        -3.66e-02,  2.23e-02, -2.14e-02, -3.65e-02, -6.57e-03, -2.97e-02,\n",
      "         1.38e-02,  6.67e-03, -1.71e-02,  2.66e-03,  2.74e-02, -7.43e-02,\n",
      "        -2.27e-02, -7.30e-03,  1.71e-02, -9.55e-03, -2.12e-02,  5.92e-03,\n",
      "        -2.72e-02,  2.06e-02, -2.19e-02, -4.57e-02, -3.90e-02,  6.38e-03,\n",
      "         8.18e-04, -2.16e-02,  1.63e-02, -1.93e-02,  6.11e-03, -2.48e-03,\n",
      "        -1.54e-02, -2.06e-02, -3.96e-02, -4.10e-02,  2.54e-02,  3.79e-02,\n",
      "         8.37e-03,  1.12e-02, -3.60e-02, -1.13e-03, -4.33e-02,  1.31e-02,\n",
      "         1.22e-03,  3.75e-03, -2.86e-02,  5.43e-03,  3.38e-03, -2.05e-02,\n",
      "        -2.71e-02,  1.39e-02, -4.94e-02, -6.35e-02,  2.71e-03, -2.11e-03,\n",
      "        -3.59e-02, -1.55e-02, -2.25e-02, -2.32e-02, -4.23e-02, -2.44e-02,\n",
      "         2.22e-02,  1.56e-02, -1.11e-02, -2.52e-02,  1.01e-02, -8.84e-03,\n",
      "        -1.96e-02, -2.11e-02,  4.17e-03, -2.20e-02,  1.27e-02, -3.02e-02,\n",
      "         2.56e-02, -3.25e-02,  3.36e-02, -4.65e-02, -7.51e-03, -2.65e-02,\n",
      "        -2.95e-02, -2.97e-03, -4.81e-02,  1.26e-02, -5.44e-03,  5.32e-02,\n",
      "        -7.26e-03, -4.46e-02, -3.96e-02,  2.42e-03, -6.27e-03, -4.04e-02,\n",
      "         3.17e-02, -2.97e-02, -2.19e-02, -3.89e-03, -2.59e-02,  8.10e-03,\n",
      "        -5.08e-03, -9.91e-02, -6.96e-02,  3.44e-02, -2.68e-02, -3.42e-02,\n",
      "         5.75e-03, -6.61e-03, -2.54e-02, -8.03e-03,  5.02e-03, -3.52e-02,\n",
      "        -5.07e-02, -3.06e-02,  4.33e-03, -1.71e-02,  4.75e-03, -3.24e-02,\n",
      "        -2.09e-02, -2.01e-02, -1.81e-02, -1.17e-02,  1.25e-02, -2.36e-02,\n",
      "        -1.38e-02, -3.97e-03, -2.10e-02, -4.92e-02,  2.04e-03,  1.45e-02,\n",
      "         6.74e-03, -5.50e-02,  9.95e-03, -1.43e-02, -4.38e-02, -3.63e-02,\n",
      "        -3.90e-02,  2.30e-02, -1.22e-02, -5.68e-02,  2.07e-02,  1.29e-02,\n",
      "         3.52e-03,  5.60e-03, -4.06e-03,  7.30e-03, -4.94e-02,  4.98e-03,\n",
      "        -3.32e-02, -1.11e-02, -3.15e-02, -2.65e-02,  3.01e-02, -5.98e-02,\n",
      "        -3.07e-02, -1.20e-02, -1.25e-02,  2.71e-02,  1.35e-02,  1.92e-02,\n",
      "        -6.00e-02, -4.62e-02, -2.19e-02,  2.21e-02, -6.91e-03, -4.31e-02,\n",
      "        -2.49e-03, -5.79e-02, -2.95e-02, -6.46e-02, -2.09e-02,  1.44e-02,\n",
      "        -4.92e-02, -7.33e-03, -2.29e-02, -1.16e-02, -5.81e-03, -6.91e-02,\n",
      "        -5.88e-02, -3.20e-02, -1.05e-04, -9.59e-02, -1.91e-02, -1.42e-02,\n",
      "         9.53e-03, -6.15e-03,  4.47e-04, -2.15e-03, -5.34e-02,  3.56e-04,\n",
      "        -2.91e-02, -1.35e-02, -4.27e-03, -6.94e-02,  2.17e-02, -3.73e-02,\n",
      "        -8.36e-02, -5.29e-03, -4.00e-02, -5.36e-02, -1.39e-03, -1.22e-03,\n",
      "        -1.67e-02,  9.43e-03, -3.13e-02, -1.54e-02,  2.71e-02,  2.34e-02,\n",
      "        -2.67e-02, -1.22e-02, -1.44e-02, -9.19e-02, -1.09e-02, -2.41e-02,\n",
      "        -1.81e-02, -3.14e-02, -7.92e-04,  2.30e-02,  4.11e-02, -1.91e-02,\n",
      "        -5.23e-02,  1.18e-02, -3.90e-02,  2.67e-02, -4.05e-02, -1.55e-02,\n",
      "         3.64e-02, -1.82e-02, -5.69e-03, -5.78e-02,  2.71e-02, -5.01e-02,\n",
      "        -3.06e-02,  5.51e-03, -1.58e-03, -1.15e-01, -6.36e-02,  1.11e-03,\n",
      "        -1.32e-02, -1.61e-02], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.07e-01,  1.23e-02,  1.74e-02,  1.33e-02,  2.23e-02,  4.23e-02,\n",
      "         3.63e-02,  2.74e-02,  6.25e-02, -6.24e-03,  1.94e-02,  2.82e-02,\n",
      "         1.65e-02,  7.69e-03,  2.10e-02,  1.46e-02,  4.45e-04,  4.06e-02,\n",
      "         2.76e-02,  2.88e-02,  1.58e-02,  3.18e-02,  1.80e-02, -1.61e-02,\n",
      "         3.79e-02,  4.47e-02,  1.69e-02,  1.57e-02,  3.75e-02, -4.86e-02,\n",
      "         5.96e-02, -6.76e-03,  3.73e-02, -1.56e-02,  2.63e-02,  1.40e-02,\n",
      "         2.04e-02,  3.76e-02,  4.46e-02,  1.08e-02,  1.80e-02,  2.06e-02,\n",
      "         3.14e-02,  3.56e-02,  3.33e-02,  1.84e-02,  1.95e-02,  1.42e-02,\n",
      "         1.67e-02,  1.21e-02,  3.25e-02,  1.90e-02,  3.63e-02,  1.83e-02,\n",
      "         1.61e-03,  2.52e-02,  4.46e-04,  1.22e-02,  4.02e-02,  1.06e-03,\n",
      "         9.50e-03,  1.44e-03,  4.35e-02,  9.79e-03,  2.46e-02,  3.34e-02,\n",
      "         1.65e-02,  1.48e-02, -9.30e-03,  1.93e-02,  3.73e-02,  4.95e-02,\n",
      "         5.72e-03,  4.71e-02,  2.03e-02, -2.98e-02,  2.42e-02, -1.56e-02,\n",
      "         3.58e-03, -3.03e-02,  1.81e-02,  5.21e-02,  1.77e-02,  3.37e-02,\n",
      "         1.06e-02,  1.98e-02,  1.22e-02,  2.29e-02,  6.38e-03,  2.83e-02,\n",
      "         2.02e-02,  2.68e-02,  2.58e-02,  2.01e-02,  2.86e-02,  4.28e-02,\n",
      "         8.11e-02, -1.80e-02,  5.86e-02,  2.51e-02,  2.00e-02,  4.93e-02,\n",
      "         3.28e-02,  1.34e-02,  9.67e-03,  9.45e-03,  3.16e-02,  1.82e-02,\n",
      "         1.34e-02,  3.28e-02,  3.79e-03,  5.25e-02, -1.00e-02, -1.51e-02,\n",
      "         1.65e-02, -5.71e-03,  5.92e-02, -2.30e-04,  3.06e-02,  2.76e-02,\n",
      "         1.57e-02,  2.55e-02,  1.04e-02,  6.77e-03,  1.98e-02,  3.08e-02,\n",
      "         6.20e-03,  2.14e-02,  4.22e-02, -3.25e-02, -8.49e-03, -3.75e-02,\n",
      "        -5.27e-03, -2.67e-04, -1.84e-02,  2.46e-02,  2.38e-02,  4.05e-02,\n",
      "         6.05e-03,  1.13e-02,  3.80e-02, -5.91e-03,  8.10e-03, -6.50e-04,\n",
      "         2.83e-02,  3.17e-02,  2.33e-03,  1.26e-02,  2.40e-02,  4.92e-02,\n",
      "         3.43e-02,  1.48e-02,  5.03e-05,  3.23e-02,  4.04e-02, -1.62e-03,\n",
      "         3.05e-02,  1.65e-02,  3.06e-03,  4.10e-02, -1.97e-03,  1.36e-02,\n",
      "         1.69e-03,  4.76e-02,  3.17e-02,  3.01e-02, -3.31e-03, -1.14e-02,\n",
      "        -1.98e-02,  2.63e-02,  1.31e-02,  5.78e-03,  2.12e-02,  5.63e-02,\n",
      "        -5.46e-03,  1.16e-02, -1.78e-02,  1.13e-02, -9.47e-03, -6.15e-03,\n",
      "         5.81e-02,  9.84e-03,  6.46e-03, -3.26e-02,  3.80e-02, -9.70e-03,\n",
      "        -1.80e-02,  4.36e-03, -2.10e-02, -2.10e-02,  2.89e-03,  1.72e-02,\n",
      "        -2.89e-02,  1.16e-02, -1.69e-02, -4.54e-02,  4.95e-02, -4.90e-03,\n",
      "         2.58e-02,  4.33e-02, -1.57e-02,  5.28e-02, -1.03e-02, -4.35e-03,\n",
      "         1.17e-03,  2.52e-03,  1.66e-02, -2.34e-02,  2.39e-02, -1.62e-03,\n",
      "         1.54e-02, -1.01e-02, -2.90e-02,  2.38e-02,  3.00e-02, -1.61e-02,\n",
      "         1.26e-02, -2.08e-02,  1.21e-03, -1.17e-02, -8.83e-03,  1.42e-02,\n",
      "         3.29e-02,  2.50e-02,  3.89e-04,  1.98e-02,  6.16e-03, -2.56e-02,\n",
      "         4.40e-02, -1.36e-02,  3.83e-03, -7.92e-03,  1.65e-02, -9.11e-05,\n",
      "         4.15e-02, -1.12e-03,  5.16e-03, -8.28e-03,  8.18e-03, -3.69e-02,\n",
      "         1.68e-02,  3.60e-03,  8.05e-03, -5.65e-03, -1.25e-02, -2.68e-02,\n",
      "        -9.11e-03, -6.72e-03,  4.13e-03,  2.02e-02,  8.58e-03,  1.34e-02,\n",
      "        -3.65e-02, -5.56e-03,  3.01e-03,  1.54e-02,  1.50e-02,  1.11e-02,\n",
      "        -1.94e-02, -8.81e-03, -3.44e-02,  1.27e-02, -6.52e-03, -7.69e-03,\n",
      "        -3.75e-02,  7.06e-03,  6.32e-02,  2.26e-02,  1.96e-03, -5.84e-02,\n",
      "         1.64e-02,  1.06e-02,  2.02e-02,  2.46e-02,  3.46e-02, -6.72e-02,\n",
      "        -3.64e-02,  1.51e-02, -2.15e-02, -3.36e-02, -7.05e-03, -3.16e-02,\n",
      "         1.57e-02,  7.43e-03, -5.49e-03, -1.15e-02,  2.71e-02, -5.56e-02,\n",
      "        -2.18e-02, -1.46e-02,  1.58e-02, -9.34e-03, -1.83e-02,  1.10e-02,\n",
      "        -2.79e-02,  2.12e-02, -1.04e-02, -2.99e-02, -3.47e-02,  6.34e-03,\n",
      "        -2.02e-02, -2.88e-02,  2.16e-02, -1.95e-02,  6.09e-03, -2.69e-03,\n",
      "        -1.67e-02, -2.08e-02, -3.72e-02, -4.06e-02,  2.37e-02,  2.53e-02,\n",
      "         1.68e-02, -1.68e-02, -3.65e-02,  2.21e-03, -4.28e-02,  1.02e-02,\n",
      "         1.90e-03,  6.73e-03, -3.20e-02, -4.41e-03, -6.05e-03, -2.02e-02,\n",
      "        -3.60e-02,  1.49e-02, -4.48e-02, -6.58e-02,  6.09e-03,  1.95e-03,\n",
      "        -3.39e-02, -1.59e-02, -2.90e-02, -2.33e-02, -4.24e-02, -1.16e-02,\n",
      "         1.86e-02,  1.47e-02, -7.83e-03, -1.79e-02,  9.52e-03, -9.05e-03,\n",
      "        -1.56e-02, -3.43e-02, -1.33e-02, -2.20e-02,  1.39e-02, -1.78e-02,\n",
      "         2.50e-02, -3.30e-02,  1.58e-02, -4.66e-02, -7.16e-03, -2.27e-02,\n",
      "        -2.45e-02,  3.75e-03, -4.58e-02,  1.05e-02, -4.72e-03,  5.23e-02,\n",
      "        -5.00e-03, -4.75e-02, -4.02e-02, -2.95e-03, -4.71e-03, -5.96e-02,\n",
      "         3.34e-02, -2.83e-02, -2.24e-02, -3.65e-03, -2.86e-02,  8.79e-03,\n",
      "        -7.11e-03, -8.99e-02, -5.98e-02,  3.28e-02, -2.11e-02, -3.44e-02,\n",
      "         1.08e-02, -6.88e-03, -2.98e-02, -1.57e-02,  1.34e-02, -3.36e-02,\n",
      "        -7.95e-02, -2.91e-02,  5.25e-03, -1.75e-02,  3.90e-04, -3.49e-02,\n",
      "        -2.46e-02, -2.05e-02, -1.86e-02, -1.19e-02,  9.09e-03, -2.46e-02,\n",
      "        -1.57e-02,  2.80e-02, -4.07e-02, -5.72e-02,  1.94e-03, -2.88e-03,\n",
      "         5.76e-03, -3.68e-02,  9.42e-03, -4.45e-02, -4.81e-02, -3.12e-02,\n",
      "        -4.04e-02, -1.19e-02, -1.52e-02, -5.63e-02,  2.69e-02,  1.25e-02,\n",
      "         1.63e-03,  4.52e-03, -5.32e-03,  5.86e-04, -5.11e-02,  8.92e-03,\n",
      "        -3.43e-02, -1.12e-02, -3.15e-02, -3.31e-02,  2.89e-02, -2.50e-02,\n",
      "        -1.85e-02, -4.43e-02,  2.22e-02,  2.76e-02,  1.37e-02, -4.41e-03,\n",
      "        -5.57e-02, -4.68e-02, -2.45e-02,  1.57e-02, -6.61e-03, -4.49e-02,\n",
      "        -2.13e-03, -5.74e-02, -2.92e-02, -7.11e-02, -2.71e-02, -7.61e-03,\n",
      "        -6.13e-02, -9.83e-03, -5.29e-02, -1.16e-02, -1.18e-02, -5.38e-02,\n",
      "        -1.05e-02, -1.36e-02, -4.21e-04, -9.76e-02, -1.83e-02, -1.76e-02,\n",
      "         8.55e-03, -6.54e-03, -1.39e-04, -6.39e-03, -5.45e-02, -3.33e-04,\n",
      "        -3.43e-02,  3.18e-03, -4.57e-02, -2.85e-02,  2.38e-02, -5.39e-02,\n",
      "        -1.01e-01, -8.92e-03, -7.63e-02, -4.50e-02,  6.90e-03, -4.01e-03,\n",
      "        -1.49e-02,  9.11e-03, -3.35e-02, -1.52e-02,  9.83e-03, -2.28e-02,\n",
      "        -2.69e-02, -6.96e-03, -4.49e-02, -1.01e-01, -1.12e-02, -2.23e-02,\n",
      "        -1.86e-02, -3.17e-02, -5.96e-03,  1.78e-02,  4.06e-02, -2.20e-02,\n",
      "        -4.71e-02,  5.02e-03, -4.96e-02,  4.67e-02, -4.56e-02, -1.61e-02,\n",
      "         2.97e-02, -9.86e-03, -5.99e-03, -3.94e-02,  2.66e-02, -4.04e-02,\n",
      "        -4.33e-02,  1.04e-02, -1.98e-03, -1.14e-01, -5.94e-02, -2.65e-02,\n",
      "         9.87e-03, -1.69e-02], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 0.12,  0.01,  0.01,  0.01,  0.01,  0.02,  0.04,  0.02,  0.06, -0.01,\n",
      "         0.00,  0.03,  0.02,  0.03,  0.03,  0.01,  0.01,  0.04,  0.03,  0.03,\n",
      "         0.02,  0.03,  0.01,  0.01,  0.03,  0.04,  0.03,  0.02,  0.04, -0.02,\n",
      "         0.06, -0.01,  0.04, -0.02,  0.02,  0.01,  0.02,  0.03,  0.05,  0.01,\n",
      "         0.02,  0.02,  0.03,  0.03,  0.03,  0.03,  0.02,  0.02,  0.02,  0.01,\n",
      "         0.03,  0.02,  0.04,  0.01,  0.01,  0.03,  0.02,  0.01,  0.04,  0.01,\n",
      "         0.01,  0.00,  0.03,  0.01,  0.04,  0.04,  0.02, -0.01, -0.01,  0.02,\n",
      "         0.00,  0.05,  0.01,  0.05,  0.02, -0.02,  0.03, -0.02,  0.04, -0.03,\n",
      "         0.02,  0.06,  0.02,  0.05,  0.01,  0.04,  0.01,  0.02,  0.01,  0.03,\n",
      "         0.04,  0.03,  0.03,  0.02,  0.02,  0.04, -0.02, -0.02,  0.05,  0.03,\n",
      "         0.01,  0.04,  0.03,  0.01,  0.02,  0.01,  0.03,  0.02,  0.01,  0.03,\n",
      "         0.00,  0.05, -0.00,  0.01,  0.02, -0.01,  0.05, -0.00,  0.03,  0.03,\n",
      "         0.01,  0.03,  0.01,  0.00,  0.02,  0.03,  0.01,  0.02,  0.04, -0.00,\n",
      "        -0.01, -0.04, -0.00,  0.00, -0.02,  0.02,  0.03,  0.06,  0.00,  0.01,\n",
      "         0.04, -0.00,  0.00,  0.01,  0.03,  0.04,  0.00,  0.01,  0.03,  0.05,\n",
      "        -0.01,  0.01,  0.01,  0.03,  0.03, -0.00,  0.02,  0.01,  0.01,  0.05,\n",
      "        -0.00,  0.01, -0.01,  0.04,  0.03,  0.03, -0.00,  0.00, -0.02,  0.03,\n",
      "         0.01,  0.01,  0.02,  0.05, -0.01,  0.01, -0.02,  0.01, -0.01, -0.01,\n",
      "         0.06,  0.02,  0.01, -0.03,  0.04, -0.01, -0.02,  0.01, -0.02, -0.02,\n",
      "         0.00,  0.04, -0.03,  0.01, -0.01, -0.04,  0.05, -0.00,  0.02,  0.04,\n",
      "        -0.01,  0.05, -0.01, -0.00,  0.01, -0.01,  0.03, -0.02,  0.02, -0.00,\n",
      "         0.01, -0.01, -0.03,  0.02,  0.04, -0.01,  0.00, -0.04,  0.00, -0.01,\n",
      "        -0.00,  0.01,  0.04,  0.04, -0.00,  0.01,  0.01, -0.03,  0.05, -0.01,\n",
      "         0.01, -0.01,  0.02,  0.00,  0.04,  0.00,  0.00, -0.01,  0.01, -0.03,\n",
      "         0.02,  0.00,  0.01, -0.00, -0.01, -0.02, -0.01, -0.01,  0.01,  0.02,\n",
      "         0.01,  0.01, -0.02,  0.01, -0.01,  0.02,  0.01,  0.01, -0.02,  0.00,\n",
      "        -0.03,  0.01, -0.00, -0.00, -0.04,  0.00,  0.07,  0.02,  0.00, -0.06,\n",
      "         0.01,  0.01,  0.02,  0.03,  0.03, -0.03, -0.04,  0.02, -0.02, -0.04,\n",
      "        -0.01, -0.03,  0.02,  0.01, -0.01, -0.02,  0.03, -0.05, -0.01, -0.02,\n",
      "         0.02, -0.01, -0.02, -0.00, -0.03,  0.02, -0.01, -0.03, -0.04,  0.01,\n",
      "        -0.02, -0.03,  0.01, -0.02,  0.01, -0.00, -0.02, -0.01, -0.03, -0.04,\n",
      "         0.02,  0.03,  0.01, -0.01, -0.04,  0.00, -0.04,  0.01,  0.00,  0.01,\n",
      "        -0.03, -0.02, -0.00, -0.02, -0.03,  0.01, -0.03, -0.07,  0.01,  0.00,\n",
      "        -0.03, -0.02, -0.04,  0.00, -0.04, -0.01,  0.02,  0.01, -0.01, -0.01,\n",
      "         0.01, -0.01, -0.01, -0.02, -0.02, -0.02,  0.01, -0.05,  0.02, -0.03,\n",
      "         0.01, -0.05, -0.00, -0.02, -0.02, -0.01, -0.04,  0.00, -0.00,  0.05,\n",
      "        -0.00, -0.05, -0.04, -0.00, -0.01, -0.05,  0.03, -0.03, -0.02, -0.00,\n",
      "        -0.03,  0.01, -0.01, -0.06, -0.07,  0.03, -0.02, -0.03,  0.00, -0.01,\n",
      "        -0.04, -0.01,  0.00, -0.02, -0.06, -0.04,  0.00, -0.02,  0.03, -0.04,\n",
      "        -0.03, -0.02, -0.02, -0.01,  0.01, -0.02, -0.02, -0.00, -0.02, -0.04,\n",
      "         0.00, -0.00,  0.00, -0.06,  0.01, -0.04, -0.06, -0.04, -0.04, -0.01,\n",
      "        -0.02, -0.06,  0.02,  0.00,  0.00,  0.01, -0.01, -0.01, -0.05,  0.01,\n",
      "        -0.04, -0.01, -0.03, -0.03,  0.03, -0.06, -0.03, -0.05, -0.01,  0.03,\n",
      "         0.01, -0.00, -0.06, -0.04,  0.00,  0.02, -0.01, -0.05, -0.00, -0.06,\n",
      "        -0.03, -0.06, -0.02, -0.01, -0.06, -0.01, -0.05, -0.01, -0.01, -0.07,\n",
      "        -0.06, -0.02, -0.00, -0.04, -0.02, -0.02,  0.01, -0.01,  0.00, -0.01,\n",
      "        -0.05,  0.00, -0.03, -0.02, -0.04, -0.07,  0.02, -0.05, -0.09, -0.01,\n",
      "        -0.08, -0.05,  0.00, -0.00, -0.01,  0.01, -0.04, -0.02,  0.01, -0.02,\n",
      "        -0.03, -0.00, -0.04, -0.09, -0.02, -0.02, -0.02, -0.03, -0.01,  0.01,\n",
      "         0.04, -0.02, -0.05,  0.00, -0.05,  0.02, -0.05, -0.01,  0.02, -0.01,\n",
      "        -0.01, -0.05,  0.03, -0.06, -0.04,  0.01, -0.00, -0.11, -0.06, -0.03,\n",
      "        -0.02, -0.02], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.12,  0.01,  0.02, -0.01,  0.01,  0.03,  0.03,  0.03,  0.06, -0.01,\n",
      "         0.02,  0.03,  0.01,  0.03,  0.04,  0.01,  0.00,  0.04,  0.02,  0.03,\n",
      "         0.02,  0.03,  0.01,  0.01,  0.03,  0.03,  0.02,  0.01,  0.03, -0.01,\n",
      "         0.06,  0.04,  0.04, -0.03,  0.04,  0.02,  0.02,  0.04,  0.04,  0.02,\n",
      "         0.02, -0.01,  0.03,  0.03,  0.03,  0.02,  0.02,  0.01,  0.01,  0.00,\n",
      "         0.03,  0.02,  0.03,  0.05,  0.00,  0.03,  0.01,  0.01,  0.05,  0.01,\n",
      "         0.01,  0.01,  0.05,  0.01,  0.02,  0.04,  0.02, -0.00, -0.01,  0.02,\n",
      "         0.03,  0.05,  0.01,  0.01,  0.02, -0.03,  0.03, -0.02,  0.00, -0.03,\n",
      "        -0.00,  0.03,  0.02,  0.03,  0.00,  0.04,  0.01,  0.02,  0.01,  0.02,\n",
      "         0.05,  0.02,  0.03,  0.02,  0.03,  0.04,  0.05, -0.02,  0.05,  0.03,\n",
      "        -0.00,  0.05,  0.04,  0.02,  0.02,  0.01,  0.03,  0.02,  0.01,  0.03,\n",
      "         0.00,  0.05, -0.00,  0.01,  0.02, -0.00,  0.02,  0.01,  0.03,  0.03,\n",
      "         0.01,  0.03,  0.01,  0.00,  0.02,  0.03,  0.00,  0.02,  0.04, -0.00,\n",
      "        -0.01, -0.04, -0.00,  0.00, -0.02,  0.02,  0.03,  0.07,  0.01,  0.01,\n",
      "         0.04, -0.00, -0.01,  0.01,  0.03,  0.05,  0.00,  0.01,  0.01,  0.05,\n",
      "         0.01,  0.02,  0.00,  0.02,  0.03, -0.01,  0.03,  0.02,  0.01,  0.04,\n",
      "         0.00,  0.01,  0.00, -0.01,  0.03,  0.03,  0.00,  0.01, -0.02,  0.03,\n",
      "         0.01,  0.01,  0.02,  0.05, -0.00,  0.01, -0.02,  0.01, -0.01, -0.01,\n",
      "         0.05,  0.01,  0.01, -0.03,  0.04, -0.01, -0.02,  0.01, -0.01, -0.02,\n",
      "         0.00,  0.03, -0.03,  0.01, -0.01, -0.04,  0.05, -0.00,  0.02,  0.04,\n",
      "        -0.01,  0.03, -0.01, -0.00,  0.01, -0.00,  0.03, -0.02,  0.02,  0.00,\n",
      "         0.02, -0.01, -0.03,  0.03,  0.05, -0.03,  0.02, -0.01,  0.01, -0.01,\n",
      "        -0.01,  0.01,  0.03,  0.04, -0.00,  0.02,  0.01, -0.03,  0.04, -0.02,\n",
      "         0.01, -0.01,  0.02,  0.01,  0.04,  0.00,  0.01, -0.01,  0.02, -0.03,\n",
      "         0.02,  0.00,  0.01, -0.01, -0.02, -0.01, -0.01, -0.01,  0.02,  0.02,\n",
      "         0.01,  0.01, -0.03, -0.00, -0.02,  0.01,  0.01,  0.01, -0.02,  0.00,\n",
      "        -0.04,  0.02, -0.03, -0.00, -0.03, -0.01,  0.05,  0.02,  0.00,  0.01,\n",
      "         0.01,  0.01,  0.01,  0.02,  0.03, -0.05, -0.04,  0.01, -0.02, -0.03,\n",
      "        -0.01, -0.03,  0.02,  0.01, -0.00, -0.00,  0.03, -0.05, -0.02, -0.03,\n",
      "         0.01, -0.01, -0.02, -0.00, -0.03,  0.02, -0.01, -0.02, -0.01,  0.01,\n",
      "        -0.02, -0.00,  0.01, -0.02,  0.01, -0.00, -0.02, -0.02, -0.03, -0.04,\n",
      "         0.04,  0.03,  0.01, -0.02, -0.04, -0.00, -0.04,  0.01, -0.00,  0.01,\n",
      "        -0.03, -0.02,  0.01, -0.02, -0.04,  0.01, -0.04, -0.05,  0.01, -0.00,\n",
      "        -0.03, -0.02, -0.03, -0.03, -0.04, -0.01,  0.02,  0.02, -0.02, -0.02,\n",
      "         0.01, -0.01, -0.02, -0.01, -0.02, -0.02,  0.01, -0.04,  0.03, -0.04,\n",
      "        -0.00, -0.05, -0.01, -0.03, -0.03, -0.01, -0.04,  0.00, -0.01,  0.05,\n",
      "        -0.00, -0.05, -0.04,  0.01,  0.00, -0.05,  0.03, -0.03, -0.02, -0.00,\n",
      "        -0.03,  0.01,  0.01, -0.02, -0.07,  0.03, -0.02, -0.03,  0.02, -0.01,\n",
      "        -0.03, -0.01,  0.01, -0.03, -0.07, -0.04, -0.00, -0.02,  0.01, -0.04,\n",
      "        -0.03, -0.02, -0.03, -0.01,  0.02, -0.02, -0.02, -0.01, -0.05, -0.03,\n",
      "         0.00, -0.00,  0.00, -0.06,  0.01, -0.05, -0.05, -0.04, -0.04, -0.02,\n",
      "        -0.02,  0.01,  0.02,  0.00,  0.00,  0.00, -0.01,  0.02, -0.01,  0.01,\n",
      "        -0.04, -0.01, -0.03, -0.03,  0.03, -0.05, -0.02, -0.05, -0.01,  0.03,\n",
      "         0.01, -0.03,  0.01, -0.05, -0.02,  0.01, -0.01, -0.05, -0.00, -0.06,\n",
      "        -0.03, -0.07, -0.02, -0.01, -0.06, -0.02, -0.05, -0.01, -0.01, -0.06,\n",
      "        -0.06, -0.01, -0.00, -0.10, -0.02, -0.02,  0.01, -0.01, -0.00, -0.01,\n",
      "        -0.06, -0.00, -0.04, -0.02, -0.04, -0.06,  0.02, -0.06, -0.11, -0.01,\n",
      "        -0.07, -0.05,  0.00, -0.01, -0.02,  0.01, -0.04, -0.02,  0.01, -0.03,\n",
      "        -0.03, -0.00, -0.03, -0.10,  0.01, -0.02, -0.02, -0.03, -0.01,  0.00,\n",
      "         0.04, -0.02, -0.05,  0.01, -0.00,  0.02, -0.05, -0.02,  0.03, -0.02,\n",
      "        -0.01, -0.05,  0.03, -0.06, -0.04,  0.01, -0.00, -0.11, -0.07, -0.03,\n",
      "        -0.02, -0.01], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 0.11,  0.01,  0.02,  0.01,  0.01,  0.02,  0.03,  0.02,  0.06, -0.01,\n",
      "         0.02,  0.03,  0.01,  0.03,  0.03,  0.01, -0.00,  0.04,  0.03,  0.03,\n",
      "         0.02,  0.03,  0.01,  0.00,  0.03,  0.04,  0.02,  0.01,  0.03, -0.02,\n",
      "         0.06,  0.04, -0.00, -0.01,  0.02,  0.02,  0.02,  0.04,  0.04,  0.01,\n",
      "         0.02,  0.01,  0.03,  0.03,  0.03,  0.03,  0.02,  0.02,  0.02,  0.00,\n",
      "         0.03,  0.02,  0.04,  0.03,  0.01,  0.03,  0.02,  0.01,  0.05,  0.02,\n",
      "         0.01,  0.01,  0.04, -0.00,  0.03,  0.04,  0.02,  0.03, -0.01,  0.02,\n",
      "         0.04,  0.05,  0.01,  0.05, -0.01, -0.01,  0.00, -0.01,  0.05, -0.03,\n",
      "         0.02,  0.06,  0.02,  0.04,  0.01,  0.04,  0.01,  0.01,  0.01,  0.01,\n",
      "         0.02,  0.02,  0.02,  0.02,  0.03,  0.03, -0.01, -0.02,  0.04,  0.02,\n",
      "         0.01,  0.04,  0.03,  0.01,  0.02,  0.01,  0.03,  0.02,  0.01,  0.03,\n",
      "         0.00,  0.05,  0.00,  0.01,  0.02, -0.00,  0.05, -0.01,  0.03,  0.03,\n",
      "         0.01,  0.03,  0.01,  0.00,  0.02,  0.03,  0.01,  0.03,  0.05, -0.01,\n",
      "        -0.01, -0.04, -0.00,  0.00, -0.02,  0.03,  0.03,  0.04,  0.01,  0.01,\n",
      "         0.04, -0.00,  0.01,  0.01,  0.03,  0.04,  0.00,  0.01,  0.02,  0.04,\n",
      "        -0.00,  0.01,  0.00,  0.04,  0.03, -0.01,  0.03,  0.01,  0.01,  0.04,\n",
      "         0.01,  0.01, -0.00,  0.04,  0.03,  0.03,  0.00,  0.01, -0.01,  0.03,\n",
      "         0.03,  0.01,  0.03,  0.06, -0.01,  0.01, -0.02,  0.01, -0.00, -0.00,\n",
      "         0.04,  0.00,  0.01, -0.03,  0.04, -0.01, -0.02,  0.01, -0.02, -0.02,\n",
      "         0.00,  0.03, -0.03,  0.04, -0.01, -0.04,  0.04,  0.00,  0.02,  0.04,\n",
      "        -0.01,  0.06, -0.01, -0.00,  0.01,  0.00,  0.02, -0.01,  0.02,  0.00,\n",
      "         0.03, -0.01, -0.03,  0.02,  0.04,  0.00,  0.02, -0.00,  0.01, -0.01,\n",
      "        -0.00,  0.02,  0.03,  0.03, -0.00,  0.01,  0.01, -0.02,  0.04, -0.01,\n",
      "         0.00, -0.01,  0.02,  0.00,  0.05,  0.00,  0.01, -0.01,  0.01, -0.04,\n",
      "         0.02,  0.00,  0.01,  0.00, -0.01, -0.01, -0.01, -0.00,  0.01,  0.02,\n",
      "         0.01,  0.01, -0.03, -0.00,  0.03,  0.01,  0.01,  0.01, -0.02,  0.00,\n",
      "        -0.02,  0.02, -0.01, -0.01, -0.04,  0.01,  0.04,  0.02,  0.00, -0.05,\n",
      "         0.01,  0.01,  0.01,  0.03,  0.03, -0.04, -0.04,  0.02, -0.02, -0.03,\n",
      "        -0.01, -0.03,  0.02,  0.01, -0.00,  0.01,  0.03, -0.05, -0.02, -0.03,\n",
      "         0.02, -0.01, -0.01, -0.00, -0.04,  0.02, -0.01, -0.01, -0.03,  0.01,\n",
      "        -0.01, -0.02,  0.01, -0.02,  0.01, -0.00, -0.02, -0.01, -0.03, -0.04,\n",
      "         0.02,  0.04,  0.00, -0.01, -0.04,  0.00, -0.04,  0.01, -0.00,  0.01,\n",
      "        -0.03, -0.02, -0.01, -0.02, -0.04,  0.01, -0.04, -0.05,  0.01,  0.00,\n",
      "        -0.03, -0.02, -0.04, -0.02, -0.04, -0.00,  0.02,  0.01, -0.02, -0.01,\n",
      "         0.01, -0.01, -0.01, -0.02, -0.01, -0.02,  0.01, -0.05,  0.02, -0.03,\n",
      "         0.00, -0.05, -0.01, -0.03, -0.03, -0.00, -0.04,  0.01, -0.00,  0.05,\n",
      "        -0.01, -0.05, -0.04, -0.01, -0.01, -0.05,  0.03, -0.03, -0.02, -0.01,\n",
      "        -0.03,  0.01, -0.01, -0.09, -0.07,  0.03, -0.02, -0.03, -0.01, -0.01,\n",
      "        -0.04, -0.02,  0.01, -0.03, -0.09, -0.04, -0.00, -0.02,  0.00, -0.04,\n",
      "        -0.02, -0.02, -0.03, -0.01,  0.00, -0.02, -0.01, -0.01, -0.04, -0.07,\n",
      "        -0.00, -0.00,  0.00, -0.06,  0.01, -0.04, -0.07, -0.04, -0.04, -0.02,\n",
      "        -0.01, -0.05,  0.03, -0.00,  0.00,  0.00, -0.01, -0.01, -0.05,  0.01,\n",
      "        -0.01, -0.01, -0.03, -0.03,  0.03, -0.05, -0.02, -0.05,  0.02,  0.03,\n",
      "         0.01, -0.02, -0.06, -0.05, -0.02,  0.03, -0.01, -0.05, -0.00, -0.06,\n",
      "        -0.03, -0.06, -0.02,  0.01, -0.05, -0.02, -0.05, -0.01, -0.01, -0.06,\n",
      "        -0.06, -0.00, -0.00, -0.09, -0.02, -0.02,  0.01, -0.01, -0.00, -0.01,\n",
      "        -0.05, -0.00, -0.03,  0.00, -0.05, -0.05,  0.02, -0.03, -0.12, -0.01,\n",
      "        -0.08, -0.05,  0.00, -0.01, -0.02,  0.01, -0.05, -0.02,  0.01, -0.03,\n",
      "        -0.03, -0.01, -0.03, -0.10, -0.01, -0.02, -0.02, -0.03, -0.01,  0.01,\n",
      "         0.04, -0.03, -0.05,  0.00, -0.05,  0.02, -0.05, -0.02,  0.02, -0.02,\n",
      "        -0.01, -0.05,  0.03, -0.02, -0.04,  0.00, -0.00, -0.10, -0.05, -0.03,\n",
      "        -0.02, -0.02], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 0.11,  0.01,  0.01,  0.00,  0.01,  0.02,  0.02,  0.02,  0.06, -0.01,\n",
      "         0.02,  0.03,  0.01,  0.03,  0.03,  0.01, -0.00,  0.04,  0.02,  0.03,\n",
      "         0.02,  0.03,  0.01, -0.00,  0.03,  0.04, -0.01,  0.01,  0.03, -0.01,\n",
      "         0.06, -0.01,  0.04, -0.03,  0.04,  0.02,  0.02,  0.02,  0.04,  0.01,\n",
      "         0.02,  0.01,  0.03,  0.03,  0.02,  0.03,  0.02,  0.01,  0.02,  0.01,\n",
      "         0.01,  0.02,  0.04,  0.04,  0.01,  0.03,  0.02,  0.01,  0.05,  0.02,\n",
      "         0.01,  0.01,  0.05,  0.00,  0.03,  0.04,  0.02,  0.02, -0.01,  0.02,\n",
      "         0.04,  0.04,  0.01,  0.05,  0.03, -0.01,  0.04, -0.01,  0.05, -0.02,\n",
      "         0.02,  0.06,  0.01,  0.03,  0.00,  0.02,  0.01,  0.02,  0.01,  0.02,\n",
      "         0.03,  0.02,  0.02,  0.02,  0.03,  0.03, -0.03, -0.02,  0.04,  0.03,\n",
      "         0.01,  0.02,  0.03,  0.02,  0.03,  0.01,  0.03,  0.02,  0.00,  0.03,\n",
      "         0.00,  0.05, -0.00, -0.01,  0.02, -0.00,  0.06, -0.01,  0.03,  0.03,\n",
      "         0.01,  0.03,  0.01,  0.00,  0.02,  0.05,  0.01,  0.02,  0.06, -0.00,\n",
      "        -0.01, -0.03, -0.00,  0.01, -0.01,  0.03,  0.03,  0.05,  0.01,  0.01,\n",
      "         0.04, -0.00,  0.00,  0.02,  0.03,  0.05,  0.00,  0.01,  0.02,  0.04,\n",
      "        -0.01,  0.01,  0.01,  0.04,  0.04, -0.01,  0.02,  0.02,  0.01,  0.04,\n",
      "        -0.01,  0.01, -0.01,  0.02,  0.03,  0.03,  0.00,  0.01, -0.01,  0.03,\n",
      "         0.02, -0.00,  0.02,  0.05, -0.01,  0.01, -0.02,  0.01, -0.00, -0.00,\n",
      "         0.07,  0.02, -0.03, -0.03,  0.04, -0.01, -0.02,  0.01, -0.01, -0.01,\n",
      "         0.01,  0.04, -0.03,  0.03, -0.01, -0.04,  0.04, -0.00,  0.02,  0.03,\n",
      "        -0.01,  0.05, -0.01, -0.00,  0.02,  0.01,  0.03, -0.01,  0.02,  0.00,\n",
      "         0.03, -0.00, -0.03,  0.03,  0.04,  0.00,  0.02, -0.02,  0.01, -0.01,\n",
      "         0.00,  0.00,  0.02,  0.04, -0.00,  0.01,  0.01, -0.02,  0.05, -0.01,\n",
      "         0.00, -0.01,  0.02,  0.00,  0.05,  0.00, -0.01, -0.01,  0.02, -0.03,\n",
      "         0.02,  0.00,  0.01,  0.02, -0.01, -0.01, -0.01, -0.00,  0.03,  0.02,\n",
      "         0.01,  0.01, -0.01,  0.00,  0.00,  0.01,  0.01,  0.02, -0.02,  0.00,\n",
      "        -0.03,  0.02, -0.02,  0.01, -0.04, -0.00,  0.06,  0.02,  0.00, -0.06,\n",
      "         0.01,  0.01,  0.02,  0.02,  0.03, -0.04, -0.04,  0.01, -0.02, -0.03,\n",
      "        -0.01, -0.02,  0.02,  0.01,  0.00, -0.01,  0.03, -0.04, -0.01, -0.03,\n",
      "         0.02, -0.01, -0.02,  0.00, -0.04,  0.02, -0.01, -0.00, -0.03,  0.01,\n",
      "        -0.01, -0.02,  0.01, -0.02,  0.01, -0.00, -0.02, -0.01, -0.03, -0.03,\n",
      "         0.02,  0.03,  0.00, -0.02, -0.04,  0.00, -0.03,  0.01, -0.00,  0.01,\n",
      "        -0.03, -0.00,  0.01, -0.02, -0.04,  0.01, -0.04, -0.04,  0.01, -0.00,\n",
      "        -0.03, -0.02, -0.03, -0.03, -0.04, -0.01,  0.02,  0.01, -0.02, -0.02,\n",
      "         0.01, -0.01, -0.01, -0.02, -0.01, -0.02,  0.01, -0.05,  0.02, -0.03,\n",
      "         0.03, -0.05, -0.01, -0.02, -0.03, -0.01, -0.04,  0.00, -0.01,  0.05,\n",
      "        -0.01, -0.05, -0.04, -0.00, -0.01, -0.05,  0.03, -0.03, -0.02, -0.01,\n",
      "        -0.03,  0.01, -0.01, -0.09, -0.05,  0.03, -0.02, -0.04,  0.00, -0.01,\n",
      "        -0.03, -0.02,  0.01, -0.03, -0.08,  0.01, -0.01, -0.02,  0.00, -0.04,\n",
      "         0.01, -0.00, -0.03, -0.01,  0.00, -0.02, -0.01, -0.01, -0.05, -0.07,\n",
      "         0.00, -0.01, -0.00, -0.06,  0.01, -0.04, -0.06, -0.04, -0.04, -0.02,\n",
      "        -0.02, -0.05,  0.02, -0.00,  0.00,  0.00, -0.01, -0.01, -0.05,  0.01,\n",
      "        -0.04, -0.01, -0.03, -0.04,  0.03, -0.06, -0.03, -0.05, -0.02,  0.03,\n",
      "         0.01, -0.04, -0.07, -0.05, -0.03,  0.01, -0.01, -0.05, -0.00, -0.06,\n",
      "        -0.03, -0.02, -0.04, -0.01, -0.05, -0.02, -0.02, -0.01, -0.01, -0.06,\n",
      "        -0.06, -0.02, -0.00, -0.09, -0.02, -0.02,  0.01, -0.01, -0.00, -0.02,\n",
      "        -0.05, -0.00, -0.04, -0.02, -0.05, -0.06,  0.02, -0.04, -0.08, -0.01,\n",
      "        -0.06, -0.05, -0.00,  0.01, -0.02,  0.01, -0.06, -0.02,  0.00, -0.03,\n",
      "        -0.03, -0.01, -0.04, -0.10,  0.01,  0.00, -0.02, -0.03, -0.01,  0.01,\n",
      "         0.04, -0.03, -0.06,  0.00, -0.06,  0.02, -0.05, -0.02,  0.03, -0.03,\n",
      "        -0.01, -0.05,  0.03, -0.06, -0.04,  0.00, -0.00, -0.10, -0.06, -0.03,\n",
      "        -0.02, -0.02], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.12,  0.00,  0.01,  0.01, -0.00,  0.02,  0.03,  0.02,  0.06, -0.01,\n",
      "         0.01,  0.03,  0.01,  0.03,  0.01,  0.01, -0.00,  0.04,  0.02,  0.03,\n",
      "         0.01,  0.03,  0.01,  0.00,  0.03,  0.03, -0.01,  0.01,  0.03, -0.01,\n",
      "         0.05,  0.04,  0.04, -0.01,  0.03,  0.01,  0.02,  0.03,  0.04,  0.01,\n",
      "         0.02,  0.01,  0.03,  0.03,  0.02,  0.03,  0.02,  0.02,  0.02,  0.01,\n",
      "         0.04,  0.02, -0.01,  0.03,  0.01,  0.03,  0.02,  0.02,  0.05,  0.02,\n",
      "         0.01,  0.01,  0.04,  0.01,  0.03,  0.03,  0.02, -0.00, -0.01,  0.02,\n",
      "         0.03,  0.04,  0.01,  0.01,  0.03, -0.03,  0.04, -0.01,  0.05, -0.02,\n",
      "         0.00,  0.06,  0.01,  0.02,  0.01,  0.04,  0.01,  0.02,  0.01,  0.02,\n",
      "         0.04,  0.02,  0.02,  0.02,  0.03,  0.03,  0.03, -0.02,  0.04,  0.03,\n",
      "         0.00,  0.04,  0.03,  0.02,  0.03,  0.01,  0.04,  0.02,  0.01,  0.04,\n",
      "         0.00,  0.08, -0.00,  0.01, -0.00, -0.00,  0.06, -0.00,  0.03,  0.03,\n",
      "         0.01,  0.03,  0.01,  0.00,  0.02,  0.04,  0.01,  0.02,  0.05, -0.00,\n",
      "        -0.00, -0.03,  0.00,  0.01, -0.01,  0.03,  0.03,  0.05,  0.01,  0.01,\n",
      "         0.04, -0.00,  0.00,  0.02,  0.03,  0.04,  0.00,  0.01,  0.02,  0.04,\n",
      "         0.01,  0.01,  0.00,  0.04,  0.00, -0.00,  0.03,  0.01,  0.01,  0.04,\n",
      "        -0.01,  0.01, -0.00,  0.02,  0.03,  0.03,  0.00,  0.01, -0.01,  0.03,\n",
      "         0.02,  0.01,  0.03,  0.05, -0.00,  0.01, -0.02,  0.01, -0.02, -0.00,\n",
      "         0.07,  0.02,  0.02, -0.03,  0.04, -0.00, -0.02,  0.01, -0.02, -0.01,\n",
      "         0.01,  0.06, -0.02,  0.04, -0.01, -0.04,  0.04,  0.00,  0.02,  0.03,\n",
      "        -0.01,  0.05, -0.01, -0.00,  0.02,  0.01,  0.03, -0.01,  0.02,  0.00,\n",
      "         0.03, -0.00, -0.03,  0.03,  0.05,  0.00,  0.02, -0.02,  0.01, -0.00,\n",
      "         0.00,  0.02,  0.01,  0.04, -0.00,  0.03,  0.01, -0.02,  0.05, -0.01,\n",
      "         0.01, -0.01,  0.02,  0.00,  0.04,  0.00,  0.02, -0.01,  0.02, -0.02,\n",
      "         0.02,  0.00,  0.01,  0.00, -0.02, -0.01, -0.01, -0.00,  0.03,  0.02,\n",
      "         0.01,  0.01, -0.02,  0.01,  0.03,  0.01,  0.01,  0.01, -0.02,  0.01,\n",
      "        -0.03,  0.02, -0.01,  0.02, -0.04,  0.01,  0.06,  0.02,  0.00, -0.06,\n",
      "         0.01,  0.01,  0.02,  0.02,  0.03, -0.04, -0.03,  0.03, -0.01, -0.03,\n",
      "        -0.00, -0.04,  0.02,  0.01,  0.00, -0.00,  0.03, -0.04, -0.02, -0.03,\n",
      "         0.02, -0.01, -0.01,  0.00, -0.04,  0.02, -0.01, -0.03, -0.03,  0.01,\n",
      "        -0.01, -0.03,  0.01, -0.02,  0.01, -0.00, -0.02, -0.01, -0.02, -0.03,\n",
      "         0.04,  0.03,  0.02, -0.01, -0.04,  0.00, -0.03,  0.01,  0.00,  0.01,\n",
      "        -0.03,  0.00, -0.01, -0.02, -0.04,  0.01, -0.04, -0.05,  0.01,  0.00,\n",
      "        -0.03, -0.02, -0.04, -0.03, -0.04, -0.01,  0.02,  0.01, -0.02, -0.02,\n",
      "         0.01, -0.01, -0.01, -0.01, -0.02, -0.02,  0.01, -0.06,  0.02, -0.03,\n",
      "        -0.00, -0.05, -0.01, -0.02, -0.03, -0.00, -0.05,  0.02, -0.01,  0.05,\n",
      "        -0.01, -0.05, -0.04, -0.00, -0.01, -0.05,  0.03, -0.03, -0.02, -0.01,\n",
      "        -0.03,  0.01, -0.02, -0.09, -0.05,  0.03, -0.02, -0.04, -0.01, -0.01,\n",
      "        -0.03,  0.00,  0.01, -0.03, -0.02, -0.04, -0.01, -0.02,  0.00, -0.04,\n",
      "        -0.03,  0.00, -0.03, -0.01,  0.00, -0.02, -0.02, -0.02, -0.05, -0.06,\n",
      "        -0.00, -0.01, -0.00, -0.06,  0.01, -0.04,  0.00, -0.04, -0.04, -0.02,\n",
      "        -0.02, -0.06,  0.02, -0.00,  0.00,  0.00, -0.01, -0.02, -0.05,  0.00,\n",
      "        -0.04, -0.01, -0.03, -0.03,  0.03, -0.05, -0.00, -0.07, -0.02,  0.02,\n",
      "         0.01, -0.04, -0.07, -0.05, -0.03,  0.01, -0.01, -0.05, -0.00, -0.06,\n",
      "        -0.03, -0.06, -0.05,  0.01, -0.05, -0.02, -0.05, -0.01, -0.01, -0.06,\n",
      "        -0.05, -0.01, -0.00, -0.09, -0.02, -0.03,  0.01, -0.01, -0.00, -0.01,\n",
      "        -0.06, -0.00, -0.04, -0.02, -0.01, -0.06,  0.01, -0.03, -0.09, -0.01,\n",
      "        -0.08, -0.05, -0.00, -0.01, -0.02,  0.00, -0.07, -0.03,  0.00, -0.03,\n",
      "        -0.03, -0.00, -0.01, -0.03, -0.02, -0.02, -0.02, -0.03, -0.01,  0.00,\n",
      "         0.04, -0.03, -0.06,  0.00, -0.06,  0.02, -0.05, -0.02,  0.03, -0.02,\n",
      "        -0.01, -0.05,  0.02, -0.06, -0.04,  0.00, -0.00, -0.05, -0.06, -0.03,\n",
      "         0.01, -0.02], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "tensor([ 1.12e-01,  2.26e-03,  5.16e-03,  1.58e-04,  9.52e-03,  1.30e-02,\n",
      "         1.64e-02,  2.14e-02,  5.70e-02, -6.45e-03,  1.43e-02,  2.89e-02,\n",
      "         6.45e-03,  2.80e-02,  2.50e-02,  1.30e-02, -1.65e-03,  4.03e-02,\n",
      "         2.09e-02,  2.47e-02,  1.66e-02,  2.53e-02,  6.23e-03, -2.78e-03,\n",
      "         3.17e-02,  3.75e-02,  1.80e-02,  6.50e-03,  2.89e-02, -1.73e-02,\n",
      "         5.80e-02,  3.97e-02,  3.78e-02, -8.65e-03,  1.59e-02,  1.65e-02,\n",
      "         2.04e-02,  2.53e-02,  3.86e-02,  9.22e-03,  1.79e-02, -5.73e-03,\n",
      "         2.78e-02,  3.07e-02,  9.72e-03,  3.06e-02,  1.93e-02,  1.51e-02,\n",
      "         1.76e-02,  1.11e-02,  3.28e-02,  1.79e-02,  3.30e-02,  3.49e-02,\n",
      "         1.99e-03,  2.95e-02,  7.05e-03,  1.46e-02,  4.41e-02,  1.63e-02,\n",
      "         1.43e-02,  8.43e-03,  4.12e-02,  7.81e-03,  3.02e-02,  3.76e-02,\n",
      "         1.94e-02,  2.84e-02, -7.96e-03,  1.70e-02,  3.93e-02,  4.17e-02,\n",
      "         4.19e-03,  4.40e-02,  2.95e-02, -1.50e-02,  4.00e-02, -9.17e-03,\n",
      "         5.37e-02, -2.51e-02,  1.82e-03,  5.07e-02,  1.37e-02,  2.89e-02,\n",
      "         4.88e-03,  3.56e-02,  1.37e-02, -1.85e-03,  7.54e-03,  2.25e-02,\n",
      "         1.97e-02,  1.95e-02,  1.55e-02,  1.88e-02,  2.82e-02,  3.05e-02,\n",
      "         3.63e-02, -1.79e-02,  4.29e-02,  2.77e-02,  9.44e-03,  2.16e-02,\n",
      "         2.66e-02,  1.57e-02,  3.09e-02,  1.10e-02,  2.08e-02,  2.33e-02,\n",
      "         1.27e-02,  2.60e-02,  3.56e-03,  4.85e-02,  9.64e-04,  1.70e-02,\n",
      "         2.28e-02, -8.90e-04,  6.19e-02, -5.77e-03,  2.75e-02,  2.70e-02,\n",
      "         1.06e-02,  2.77e-02,  1.50e-02,  2.01e-03,  2.54e-02,  5.02e-02,\n",
      "         1.28e-02,  2.55e-02,  5.62e-02,  1.74e-03, -9.67e-03, -3.26e-02,\n",
      "         2.79e-03, -4.79e-04, -1.40e-02,  2.96e-02,  3.38e-02,  3.62e-02,\n",
      "         8.09e-03,  9.98e-03,  3.75e-02,  1.26e-05,  8.72e-03,  1.96e-02,\n",
      "         2.93e-02,  1.49e-03,  2.20e-03,  1.22e-02,  1.79e-02,  5.72e-02,\n",
      "        -9.31e-03,  1.54e-02,  5.76e-03,  2.00e-02,  3.65e-02, -1.06e-02,\n",
      "         2.72e-02,  1.46e-02,  1.26e-02,  4.67e-02, -3.63e-03,  1.18e-02,\n",
      "        -7.05e-03,  2.87e-02,  3.31e-02,  2.91e-02,  4.45e-03,  1.43e-02,\n",
      "        -9.38e-03,  3.95e-02,  2.40e-02,  9.24e-03,  1.21e-02,  4.90e-02,\n",
      "        -4.32e-05,  1.44e-02, -1.60e-02,  9.11e-03,  9.65e-04, -7.33e-04,\n",
      "         8.13e-02,  2.00e-02,  2.59e-02, -2.50e-02,  3.78e-02, -2.43e-03,\n",
      "        -1.64e-02,  1.51e-02, -1.42e-02, -1.17e-02,  6.64e-03,  5.09e-02,\n",
      "        -2.37e-02,  3.75e-02, -5.06e-03, -4.11e-02,  5.43e-02,  8.56e-04,\n",
      "         2.16e-02,  2.74e-02, -1.48e-02,  5.12e-02, -5.04e-03, -2.48e-03,\n",
      "         1.70e-02,  7.68e-03,  3.57e-02, -1.04e-02,  2.58e-02,  6.52e-03,\n",
      "         4.62e-02, -4.80e-04, -2.17e-02,  3.20e-02,  4.26e-02, -2.30e-02,\n",
      "         2.36e-02, -1.05e-02,  1.45e-02, -5.62e-03,  3.46e-03,  2.24e-02,\n",
      "         2.46e-02,  3.41e-02, -1.57e-03,  1.68e-02,  9.87e-03, -2.39e-02,\n",
      "         3.76e-02, -9.21e-03,  1.54e-02, -1.30e-03,  1.92e-02,  7.39e-03,\n",
      "         4.55e-02,  5.25e-03, -7.23e-03, -7.21e-03,  1.94e-02, -2.46e-02,\n",
      "         1.92e-02,  4.41e-03,  1.04e-02,  9.22e-03, -4.72e-03, -3.08e-03,\n",
      "        -3.71e-03, -1.74e-03,  2.17e-02,  1.75e-02,  1.07e-02,  1.38e-02,\n",
      "        -2.19e-02,  5.67e-03,  2.55e-02,  1.44e-02,  1.50e-02,  2.16e-02,\n",
      "        -1.70e-02,  7.32e-03, -2.43e-02,  2.09e-02, -1.35e-02,  1.99e-02,\n",
      "        -3.31e-02,  1.14e-02,  6.21e-02,  2.21e-02,  5.60e-03, -5.28e-02,\n",
      "         8.01e-03,  1.24e-02,  1.30e-02,  2.49e-02,  3.24e-02, -3.96e-02,\n",
      "        -3.49e-02,  2.62e-02, -1.46e-02, -2.91e-02, -4.29e-03, -3.03e-02,\n",
      "         1.86e-02,  5.07e-03,  8.76e-03,  5.91e-03,  2.58e-02, -2.78e-02,\n",
      "        -1.03e-02, -2.50e-02,  1.57e-02, -9.78e-03, -1.52e-02,  3.44e-03,\n",
      "        -3.71e-02,  2.07e-02, -1.29e-02, -2.33e-03, -2.09e-02,  5.65e-03,\n",
      "        -3.60e-03, -2.42e-02,  1.28e-02, -2.10e-02,  1.20e-02, -1.51e-03,\n",
      "        -6.53e-03, -1.38e-02, -2.06e-02, -3.17e-02,  1.90e-02,  3.32e-02,\n",
      "         6.50e-03, -1.04e-02, -3.75e-02,  2.64e-03, -3.01e-02,  1.57e-02,\n",
      "        -8.09e-04,  7.59e-03, -1.17e-02,  3.34e-03, -1.31e-02, -2.00e-02,\n",
      "        -1.23e-02,  1.26e-02, -2.85e-02, -1.60e-02,  9.86e-03,  4.85e-03,\n",
      "        -2.71e-02, -1.78e-02, -3.78e-02, -2.63e-02, -4.04e-02, -8.87e-03,\n",
      "         1.69e-02,  1.30e-02, -2.42e-02, -2.11e-02,  7.70e-03, -1.06e-02,\n",
      "        -1.55e-02, -2.20e-02, -2.51e-03, -1.96e-02,  1.05e-02, -6.29e-02,\n",
      "         2.31e-02, -3.42e-02, -9.52e-03, -4.76e-02, -7.26e-03, -1.54e-02,\n",
      "        -2.52e-02,  2.15e-03, -3.72e-02,  1.90e-03, -1.04e-03,  5.01e-02,\n",
      "        -8.27e-03, -3.23e-02, -4.15e-02, -3.78e-03, -6.59e-03, -5.88e-02,\n",
      "         2.92e-02, -3.06e-02, -2.42e-02, -5.57e-03, -2.58e-02,  1.07e-02,\n",
      "        -1.71e-02, -6.52e-02, -3.28e-02,  2.65e-02, -2.28e-02, -3.58e-02,\n",
      "        -2.14e-02, -8.58e-03, -2.74e-02, -6.93e-04,  8.31e-03, -1.67e-02,\n",
      "        -7.44e-02,  4.27e-03, -8.70e-03, -1.82e-02,  2.43e-03, -4.11e-02,\n",
      "        -3.64e-02, -3.02e-02, -3.64e-02, -1.39e-02, -6.53e-04, -2.39e-02,\n",
      "        -1.55e-02, -1.69e-02, -4.47e-02, -9.56e-03, -1.26e-03, -8.73e-03,\n",
      "        -4.19e-03, -6.38e-02,  7.58e-03, -3.99e-02, -8.91e-02, -3.89e-02,\n",
      "        -3.53e-02, -1.90e-02, -1.60e-02, -5.94e-02,  1.43e-02, -4.20e-03,\n",
      "        -1.08e-03,  8.08e-04, -9.15e-03, -2.05e-02, -5.02e-02,  7.68e-03,\n",
      "        -1.92e-02, -1.23e-02, -3.29e-02, -3.56e-02,  2.57e-02, -3.09e-02,\n",
      "        -3.70e-02,  1.00e-02, -2.38e-02,  2.38e-02,  1.47e-02, -3.77e-02,\n",
      "        -6.24e-02, -2.96e-02, -2.53e-02,  8.82e-03, -8.56e-03, -4.85e-02,\n",
      "        -4.84e-03, -5.45e-02, -2.89e-02, -2.28e-02, -4.05e-02, -1.25e-02,\n",
      "        -3.97e-02, -2.03e-02, -4.17e-02, -1.04e-02, -7.74e-03, -3.42e-02,\n",
      "        -5.51e-02, -1.63e-03, -2.80e-03, -8.27e-02, -2.41e-02, -2.81e-02,\n",
      "         2.61e-03, -8.38e-03, -3.22e-03, -1.71e-02, -5.50e-02, -5.53e-03,\n",
      "        -3.57e-02, -2.50e-02, -4.49e-02, -5.61e-02,  6.07e-03, -3.87e-02,\n",
      "        -7.42e-02, -8.71e-03, -5.95e-02, -5.19e-02,  4.96e-03, -1.81e-02,\n",
      "        -1.64e-02,  3.65e-03, -7.06e-02, -2.89e-02, -3.23e-03, -2.89e-02,\n",
      "        -2.87e-02, -3.58e-03, -5.53e-02, -9.60e-02, -1.58e-02, -1.50e-02,\n",
      "        -2.04e-02, -3.55e-02, -1.20e-02,  3.79e-02,  3.74e-02, -3.94e-02,\n",
      "        -5.44e-02,  6.72e-04, -4.51e-03,  1.48e-02, -5.21e-02, -1.98e-02,\n",
      "         1.97e-02, -2.85e-02, -1.10e-02, -6.12e-02,  2.31e-02, -6.03e-02,\n",
      "        -4.42e-02,  1.82e-03, -4.82e-03, -8.77e-02, -6.01e-05, -3.90e-02,\n",
      "         8.31e-03, -2.33e-02], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.05e-02,  8.90e-04,  1.53e-04, -5.05e-04,  1.55e-02,  2.53e-02,\n",
      "         2.31e-02,  2.14e-02,  5.58e-02, -6.66e-03,  1.10e-02,  2.91e-02,\n",
      "         7.63e-03,  2.66e-02,  1.75e-02,  1.36e-02, -2.89e-03,  4.02e-02,\n",
      "         1.19e-02,  2.36e-02,  1.61e-02,  2.44e-02,  5.01e-03, -1.29e-03,\n",
      "         2.87e-02,  3.13e-02,  1.73e-02,  7.75e-03,  3.38e-02, -3.46e-02,\n",
      "         5.58e-02,  3.57e-02,  3.39e-02, -9.59e-03,  3.28e-02,  1.64e-02,\n",
      "         1.94e-02,  2.67e-02,  3.86e-02,  1.10e-02,  1.79e-02,  8.60e-03,\n",
      "         2.63e-02,  3.04e-02,  1.88e-02,  2.71e-02,  1.95e-02,  1.56e-02,\n",
      "         2.15e-02,  1.27e-02,  3.71e-02,  1.65e-02,  3.04e-02,  3.17e-02,\n",
      "         7.67e-03,  2.84e-02,  4.16e-03,  1.44e-02,  5.08e-02, -8.12e-03,\n",
      "         1.68e-02,  1.59e-02,  4.40e-02,  5.96e-03,  2.97e-02,  3.99e-02,\n",
      "         2.00e-02,  2.34e-02, -7.72e-03,  1.64e-02,  4.33e-02,  3.91e-02,\n",
      "         3.19e-03,  4.04e-02,  2.88e-02, -2.78e-02,  4.29e-02, -5.97e-03,\n",
      "         5.52e-02, -2.63e-02,  2.16e-02,  6.58e-04,  1.38e-02,  1.74e-02,\n",
      "         6.83e-03,  3.84e-02,  1.30e-02, -4.21e-03,  8.13e-03,  2.32e-02,\n",
      "         1.90e-02,  1.88e-02,  1.93e-02, -1.85e-03,  2.84e-02,  2.74e-02,\n",
      "         3.73e-02, -1.79e-02,  1.92e-02,  2.73e-02, -1.24e-03,  3.23e-02,\n",
      "         2.44e-02,  1.20e-02,  3.57e-02,  1.13e-02,  3.26e-02,  2.33e-02,\n",
      "         9.69e-03,  2.16e-02,  3.05e-03,  4.46e-02, -7.05e-04,  1.44e-02,\n",
      "         2.35e-02, -1.83e-02,  5.94e-02, -2.32e-03,  2.69e-02,  2.63e-02,\n",
      "         1.51e-02,  2.11e-02,  9.83e-03,  2.13e-03,  2.69e-02,  3.51e-02,\n",
      "         1.30e-02,  2.46e-02,  5.44e-02,  8.31e-03, -5.87e-04, -3.27e-02,\n",
      "         4.09e-03,  1.14e-02, -1.27e-02,  3.30e-02,  3.36e-02,  5.01e-02,\n",
      "         5.91e-03,  1.16e-02,  3.69e-02,  2.76e-03,  3.92e-03,  1.95e-02,\n",
      "         2.92e-02, -6.86e-03,  2.74e-03,  1.25e-02,  1.07e-02,  4.21e-02,\n",
      "        -1.49e-02,  8.94e-03,  6.55e-03,  4.70e-02,  3.51e-02, -5.60e-03,\n",
      "         2.42e-02,  1.58e-02,  1.46e-02,  4.20e-02, -4.57e-03,  1.23e-02,\n",
      "        -1.01e-02,  1.67e-02,  3.33e-02,  3.02e-02,  5.20e-03,  1.25e-02,\n",
      "        -8.89e-03,  3.74e-02,  1.92e-02, -2.33e-03,  2.16e-02,  4.58e-02,\n",
      "         9.22e-05,  1.54e-02, -1.59e-02,  1.78e-02,  2.75e-03,  2.04e-03,\n",
      "         7.49e-02,  2.54e-02, -3.69e-02, -2.46e-02,  4.04e-02, -2.65e-04,\n",
      "        -1.59e-02,  2.24e-02, -1.33e-02, -9.30e-03,  7.36e-03,  7.17e-02,\n",
      "        -2.25e-02,  3.83e-02, -5.59e-03, -4.18e-02,  5.50e-02, -4.48e-05,\n",
      "         7.13e-03,  2.42e-02, -1.35e-02,  5.12e-02, -6.30e-03, -2.13e-03,\n",
      "         2.42e-02,  8.72e-03,  3.42e-02, -6.93e-03,  2.54e-02,  7.24e-03,\n",
      "         3.56e-02,  1.46e-03, -2.06e-02,  1.87e-02,  5.10e-02,  7.49e-03,\n",
      "         2.35e-02, -1.45e-02,  1.54e-02, -5.94e-03, -3.19e-03,  2.39e-02,\n",
      "         1.32e-02,  4.11e-02, -1.55e-03,  1.45e-02,  1.06e-02, -2.38e-02,\n",
      "         3.90e-02, -9.67e-03,  1.40e-02, -2.19e-03,  1.87e-02,  3.18e-03,\n",
      "         4.24e-02,  5.92e-03, -8.22e-03, -4.37e-03,  2.25e-02, -2.14e-02,\n",
      "         1.98e-02,  4.36e-03,  1.14e-02,  1.29e-02, -2.18e-03, -5.16e-03,\n",
      "        -3.36e-03, -6.43e-03,  3.13e-02,  2.30e-02,  1.23e-02,  1.08e-02,\n",
      "        -1.81e-02,  5.28e-03,  5.47e-03,  1.45e-02,  1.46e-02,  2.23e-02,\n",
      "        -1.62e-02,  8.73e-03, -2.81e-02,  2.24e-02, -2.97e-03,  3.08e-02,\n",
      "        -3.09e-02,  1.59e-02,  4.59e-02,  2.20e-02,  5.07e-03, -5.42e-02,\n",
      "         8.88e-03,  1.22e-02,  2.55e-02,  2.69e-02,  3.31e-02, -1.36e-02,\n",
      "        -3.41e-02,  2.53e-02, -1.41e-02, -2.86e-02, -4.17e-03, -3.08e-02,\n",
      "         1.87e-02,  6.27e-03,  7.86e-03,  6.70e-03,  2.72e-02, -1.92e-02,\n",
      "        -6.69e-03, -2.29e-03,  1.56e-02, -9.74e-03, -1.80e-02,  7.68e-03,\n",
      "        -3.89e-02,  2.07e-02, -1.25e-02, -6.57e-03, -2.09e-02,  5.50e-03,\n",
      "        -1.74e-03, -2.68e-02,  1.40e-02, -2.12e-02,  1.33e-02, -2.11e-03,\n",
      "        -1.86e-02, -7.58e-03, -1.44e-02, -3.04e-02,  1.85e-02,  2.45e-02,\n",
      "         6.43e-03, -9.94e-03, -2.95e-02,  2.89e-03, -2.61e-02,  1.62e-02,\n",
      "        -1.40e-03,  1.19e-02, -3.57e-02, -8.28e-03, -1.06e-02, -2.01e-02,\n",
      "        -3.19e-02,  2.02e-02, -3.24e-02, -9.48e-03,  8.02e-03, -4.55e-04,\n",
      "        -2.62e-02, -1.83e-02, -3.89e-02,  2.17e-03, -4.05e-02, -1.17e-02,\n",
      "         1.60e-02,  1.28e-02, -3.02e-02, -1.44e-02,  7.75e-03, -1.10e-02,\n",
      "        -1.22e-02, -2.21e-02, -1.09e-02, -1.94e-02,  1.30e-02, -5.29e-02,\n",
      "         2.29e-02, -3.47e-02, -8.85e-03, -4.78e-02, -7.36e-03, -1.15e-02,\n",
      "        -2.79e-02, -3.03e-03, -3.85e-02, -1.49e-04, -9.12e-03,  4.96e-02,\n",
      "        -1.26e-02, -5.13e-02, -4.18e-02, -2.17e-03, -5.70e-03, -4.91e-02,\n",
      "         2.92e-02, -3.37e-02, -2.45e-02, -6.39e-03, -2.66e-02,  1.06e-02,\n",
      "        -1.80e-02, -1.48e-02, -4.76e-02,  2.83e-02, -2.27e-02, -3.58e-02,\n",
      "         6.56e-03, -8.87e-03, -2.56e-02, -1.90e-02,  6.83e-03, -2.19e-02,\n",
      "        -7.61e-02, -3.63e-02, -1.06e-02, -1.83e-02,  2.08e-03, -9.23e-03,\n",
      "        -3.41e-02, -2.90e-02, -3.57e-02, -1.41e-02,  5.68e-05, -2.28e-02,\n",
      "        -1.62e-02, -2.18e-02, -4.76e-02, -5.45e-02, -1.83e-03, -8.86e-03,\n",
      "        -4.40e-03, -6.25e-02,  7.38e-03, -4.11e-02, -5.38e-02, -3.94e-02,\n",
      "        -3.53e-02, -1.89e-02, -1.50e-02,  9.07e-03,  1.58e-02, -4.01e-03,\n",
      "        -6.75e-04, -2.87e-03, -1.00e-02, -2.52e-02, -5.00e-02,  6.89e-03,\n",
      "        -3.85e-02, -1.22e-02, -3.39e-02, -3.59e-02,  2.61e-02, -5.19e-02,\n",
      "        -2.82e-02, -5.66e-02, -2.50e-02,  2.37e-02,  1.27e-02, -5.58e-02,\n",
      "        -6.13e-02, -4.75e-02, -3.31e-02,  1.04e-02, -8.78e-03, -4.82e-02,\n",
      "         8.37e-04, -5.83e-02, -2.93e-02, -5.54e-02, -3.52e-02, -1.41e-02,\n",
      "        -5.38e-02, -2.34e-02, -4.70e-02, -8.86e-03, -7.69e-03, -5.85e-02,\n",
      "        -6.44e-02,  9.63e-03, -3.47e-03, -8.06e-02, -2.48e-02, -2.94e-02,\n",
      "         3.84e-03, -8.59e-03, -3.69e-03, -1.57e-02, -5.69e-02, -5.86e-03,\n",
      "        -3.27e-02, -2.57e-02, -7.15e-03, -2.34e-02,  1.21e-02, -2.78e-02,\n",
      "         3.69e-03, -3.47e-03, -5.76e-02, -5.16e-02, -3.46e-03, -1.78e-02,\n",
      "         2.74e-03,  1.54e-03, -7.57e-02, -3.19e-02,  1.40e-04, -2.95e-02,\n",
      "        -3.08e-02, -2.78e-03, -3.76e-02, -9.70e-02, -2.20e-02, -1.71e-02,\n",
      "        -1.78e-02, -3.63e-02, -1.37e-02, -9.26e-04,  3.79e-02, -4.44e-02,\n",
      "        -5.65e-02, -4.85e-04, -5.94e-02,  1.23e-02, -5.56e-02, -1.90e-02,\n",
      "         2.41e-02, -3.41e-02, -1.11e-02, -5.42e-02,  2.26e-02, -6.47e-02,\n",
      "        -4.32e-02,  5.30e-03, -4.97e-03, -8.50e-02, -6.71e-02, -2.96e-04,\n",
      "        -2.17e-02, -2.58e-02], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/donatas_repecka/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-af996d554138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[1;32m     21\u001b[0m                                         pct_start=pct_start, **kwargs))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 162\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-dea5f415dce7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mextended_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlast_encoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_encoder_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_encoder_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mlast_encoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_encoder_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_encoder_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_default_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0msuffixes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dtype='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0msummarize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, truth =learner.get_preds(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4369)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46915959464697954\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "min_element = 0\n",
    "min_score = 1\n",
    "s = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "s_g = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "s_t = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "s_f = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "for row in range(len(truth)):\n",
    "\n",
    "    a = preds.argmax(dim=1)[row]\n",
    "    correct = 0\n",
    "    actual = 0\n",
    "    for i, t in enumerate(truth[row]):\n",
    "        s[t] = s[t]+1\n",
    "        if t != 0: # and t != 1:\n",
    "            s_g[a[i]] = s_g[a[i]] + 1\n",
    "            actual += 1\n",
    "            if a[i] == t:        \n",
    "                correct += 1\n",
    "                s_t[t] = s_t[t]+1\n",
    "            else:\n",
    "                s_f[a[i]] = s_f[a[i]]+1 \n",
    "    score = correct/actual\n",
    "    if min_score > score:\n",
    "        min_score = score\n",
    "        min_element = row\n",
    "    acc.append(score)\n",
    "\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6514  , 2.037437, 1.829964, 3.333135, 1.      , 3.774721, 2.948575, 2.648912])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.asarray(s[1:9])\n",
    "t = np.power(1-(w/w.sum()),3)\n",
    "t/min(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ind = np.arange(len(s[1:9]))+1\n",
    "width = 0.25\n",
    "ax.bar(ind-width, s[1:9], width, color='b')\n",
    "ax.bar(ind , s_f[1:9], width, color='r')\n",
    "ax.bar(ind + width, s_t[1:9], width, color='g')\n",
    "ax.bar(ind + width+ width, s_g[1:9], width, color='black')\n",
    "ax.set_xticks(ind + width+ width+width, len(s) + width / 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donatas_repecka/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([83138, 618, 10428, 12035, 2280, 20079, 0, 4436, 6250],\n",
       " [20, 0, 5600, 21489, 0, 29005, 0, 0, 12],\n",
       " [0, 0, 1733, 7759, 0, 15030, 0, 0, 1],\n",
       " [20, 0, 3867, 13730, 0, 13975, 0, 0, 11],\n",
       " array([0.000000e+00, 0.000000e+00, 1.661872e-01, 6.447029e-01, 0.000000e+00, 7.485433e-01,          nan, 0.000000e+00,\n",
       "        1.600000e-04]),\n",
       " array([2.405639e-04, 0.000000e+00, 3.708285e-01, 1.140839e+00, 0.000000e+00, 6.960008e-01,          nan, 0.000000e+00,\n",
       "        1.760000e-03]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, s_g, s_t, s_f, np.asarray(s_t)/np.asarray(s), np.asarray(s_f)/np.asarray(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.41e-04, 3.61e-02, 2.27e-01, 2.61e-01, 7.22e-02, 5.07e-02, 6.71e-04,\n",
       "         1.52e-01, 2.00e-01]), tensor(3), tensor(7))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision=2)\n",
    "preds[i][:,11], preds.argmax(dim=1)[i][11], truth[i][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09090909090909091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 3,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([2, 2, 2, 2, 8, 5, 5, 5, 5, 5, 5, 7, 2, 8, 8, 2, 3, 3, 3, 3, 7, 7, 7, 7,\n",
       "         2, 7, 7, 8, 8, 3, 3, 3, 7, 1, 7, 2, 1, 2, 2, 8, 8, 8, 2, 5, 5, 5, 5, 5,\n",
       "         5, 8, 8, 8, 8, 8, 7, 1, 2, 7, 7, 7, 1, 1, 2, 2, 1, 2, 8, 8, 2, 2, 2, 2,\n",
       "         2, 7, 7, 2, 2, 5, 5, 5, 5, 2, 4, 4, 4, 7, 7, 1, 2, 8, 8, 7, 2, 1, 2, 8,\n",
       "         8, 8, 8, 2, 2, 2, 2, 7, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         7, 2, 2, 2, 7, 7, 7, 2, 2, 8, 8, 2, 2, 2, 2, 7, 7, 7, 2, 2, 2, 2, 7, 7,\n",
       "         2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 7, 7, 2, 4, 4, 4, 2, 2,\n",
       "         4, 4, 4, 2, 2, 7, 7, 8, 8, 2, 7, 7, 7, 2, 2, 2, 2, 7, 2, 2, 2, 2, 3, 3,\n",
       "         3, 3, 3, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = min_element\n",
    "print(acc[i])\n",
    "preds.argmax(dim=1)[i], truth[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 0, 0,\n",
       "         0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 2, 2, 2, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 3, 2,\n",
       "         2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim=1)[0], preds.argmax(dim=1)[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
