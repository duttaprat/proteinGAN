{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading preprosed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVEL=\"sequence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../weights/auto_encoder{}/version_1\".format(LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256\n",
    "LAMBDA = 10\n",
    "NUM_EPOCH = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ACIDS = 21\n",
    "EMBEDDING_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donatasrep/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data = np.load(\"..//data//train_features_3.6.1.7LLevel_4.npy\")\n",
    "val_data = np.load(\"..//data//val_features_3.6.1.7LLevel_4.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((271, 120), (0,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_LENGTH=train_data.shape[1]\n",
    "SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEPS_PER_EPOCH = int(train_data.shape[0]/BATCH_SIZE)+1\n",
    "STEPS_PER_EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, is_training):\n",
    "\n",
    "    with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE) as scope:\n",
    "        print('discriminator')\n",
    "        conv1 = tf.layers.conv2d(\n",
    "            inputs=x,\n",
    "            filters=64,\n",
    "            kernel_size=[3,EMBEDDING_SIZE],\n",
    "            strides=(2,1),\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.leaky_relu,\n",
    "            name = \"dconv1\")\n",
    "        print(conv1.shape)\n",
    "        # Convolutional Layer #2\n",
    "        conv2 = tf.layers.conv2d(\n",
    "            inputs=conv1,\n",
    "            filters=128,\n",
    "            kernel_size=[3,EMBEDDING_SIZE],\n",
    "            strides=(2,1),\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.leaky_relu,\n",
    "            name = \"dconv2\")\n",
    "        conv2 = tf.layers.batch_normalization(conv2, name = \"dbn1\")\n",
    "        print(conv2.shape)\n",
    "        conv3 = tf.layers.conv2d(\n",
    "            inputs=conv2,\n",
    "            filters=256,\n",
    "            kernel_size=[3,EMBEDDING_SIZE],\n",
    "            strides=(2,1),\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.leaky_relu,\n",
    "            name = \"dconv3\")\n",
    "        conv3 = tf.layers.batch_normalization(conv3, name = \"dbn2\")\n",
    "        print(conv3.shape)\n",
    "        flat = tf.layers.flatten(conv3, name=\"dflat\")\n",
    "        output = tf.layers.dense(inputs=flat,\n",
    "                                 activation=None,\n",
    "                                 units=1,\n",
    "                                 name=\"doutput\")\n",
    "        print(output.shape)\n",
    "        output = tf.reshape(output, [-1])\n",
    "        print(output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def generator(input_batch=None, is_training=True):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        print('generator')\n",
    "        if input_batch is None:\n",
    "            input_batch = tf.random_normal([BATCH_SIZE, 128])\n",
    "        dim = math.floor(SEQUENCE_LENGTH/4)\n",
    "        print (input_batch.shape)   \n",
    "        dense1 = tf.layers.dense(inputs=input_batch,\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 bias_initializer=tf.zeros_initializer (),\n",
    "                                 units=dim*EMBEDDING_SIZE*256,\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 name=\"dense1\")\n",
    "        reshaped1 = tf.reshape(dense1, shape=[-1, -1, 1, 1], name='reshape1')\n",
    "        reshaped1 = tf.layers.batch_normalization(reshaped1, name = \"gbn1\")\n",
    "        print(reshaped1.shape)\n",
    "        up1 = tf.keras.layers.UpSampling2D(size=(2, 1))(reshaped1)\n",
    "        conv2 = tf.layers.conv2d(inputs=up1, \n",
    "                                 filters=128,\n",
    "                                 kernel_size=[3,EMBEDDING_SIZE],\n",
    "                                 padding=\"same\",\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 name = \"conv2\")\n",
    "        conv2 = tf.layers.batch_normalization(conv2, name = \"gbn2\")\n",
    "        print(conv2.shape)\n",
    "        up2 = tf.keras.layers.UpSampling2D(size=(2, 1))(conv2)\n",
    "        conv3 = tf.layers.conv2d(inputs=up2, \n",
    "                                 filters=64,\n",
    "                                 kernel_size=[3,EMBEDDING_SIZE],\n",
    "                                 padding=\"same\",\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 name = \"conv3\")\n",
    "        conv3 = tf.layers.batch_normalization(conv3, name = \"gbn3\")\n",
    "        print(conv3.shape)         \n",
    "        conv4 = tf.layers.conv2d(inputs=conv3, \n",
    "                                 filters=1,\n",
    "                                 kernel_size=[3,EMBEDDING_SIZE],\n",
    "                                 padding=\"same\",\n",
    "                                 activation=tf.nn.sigmoid,\n",
    "                                 name = \"conv4\")    \n",
    "        print(conv4.shape)\n",
    "        return conv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope('input'):\n",
    "    real_sequences = tf.placeholder(tf.int32, [None, SEQUENCE_LENGTH], name='real_sequence')\n",
    "    is_training = tf.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(real_sequences)\n",
    "dataset = dataset.shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(BATCH_SIZE)).repeat(NUM_EPOCH)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "acid_embeddings = tf.get_variable(\"acid_embeddings\", [NUM_OF_ACIDS, EMBEDDING_SIZE])\n",
    "\n",
    "batch_real_sequences = iterator.get_next()\n",
    "\n",
    "embedded_real_sequences = tf.nn.embedding_lookup(acid_embeddings, batch_real_sequences)\n",
    "embedded_real_sequences = tf.reshape(embedded_real_sequences, shape=[-1, SEQUENCE_LENGTH, EMBEDDING_SIZE, 1], name='embedded_real_sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator\n",
      "(256, 128)\n",
      "(256, 30, 8, 256)\n",
      "(256, 60, 8, 128)\n",
      "(256, 120, 8, 64)\n",
      "(256, 120, 8, 1)\n",
      "discriminator\n",
      "(256, 60, 8, 64)\n",
      "(256, 30, 8, 128)\n",
      "(256, 15, 8, 256)\n",
      "(256, 1)\n",
      "(256,)\n",
      "discriminator\n",
      "(256, 60, 8, 64)\n",
      "(256, 30, 8, 128)\n",
      "(256, 15, 8, 256)\n",
      "(256, 1)\n",
      "(256,)\n",
      "discriminator\n",
      "(256, 60, 8, 64)\n",
      "(256, 30, 8, 128)\n",
      "(256, 15, 8, 256)\n",
      "(256, 1)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "fake = generator(is_training=is_training)\n",
    "logits_real = discriminator(embedded_real_sequences, is_training)\n",
    "logits_fake = discriminator(fake, is_training)\n",
    "d_loss = tf.reduce_mean(logits_fake) - tf.reduce_mean(logits_real) # This optimizes the discriminator.\n",
    "g_loss = -tf.reduce_mean(logits_fake)  # This optimizes the generator.\n",
    "\n",
    "# # wgan-gp gradient panelty \n",
    "with tf.name_scope(\"Gradient_penalty\"):\n",
    "    eps = tf.random_uniform([BATCH_SIZE,1, 1, 1], minval=0.0,maxval=1.0)\n",
    "    interpolates = embedded_real_sequences + eps*(fake - embedded_real_sequences)\n",
    "\n",
    "    gradients = tf.gradients(discriminator(interpolates, is_training), [interpolates])[0]\n",
    "    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "    gradient_penalty = tf.reduce_mean(tf.square(slopes - 1.))\n",
    "    d_loss += 10 * gradient_penalty\n",
    "    \n",
    "D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,'discriminator')\n",
    "G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "\n",
    "trainer_d = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.5, beta2=0.9).minimize(d_loss, var_list=D_vars)\n",
    "trainer_g = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.5, beta2=0.9).minimize(g_loss, var_list=G_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers for training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " def save_weights(saver, sess, path):\n",
    "    save_path = saver.save(sess, path)\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(l):\n",
    "    if len(l) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(l) / float(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(steps, dLosses, gLosses):    \n",
    "    if steps % int(STEPS_PER_EPOCH*100) == 0:\n",
    "        print('steps:{} \\td_loss:{:.4f} \\tg_loss:{:.4f}'.format(steps, mean(dLosses), mean(gLosses)))\n",
    "        dLosses, gLosses = [], [] \n",
    "    return dLosses, gLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sequence():\n",
    "    sequences = reverse_embedding_lookup(acid_embeddings, tf.squeeze(fake))\n",
    "    generated_sequences, logits = sess.run([sequences, logits_fake], feed_dict={is_training: False})\n",
    "    indexToLetter= {0: '0', 1: 'A', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L', 11: 'M', 12: 'N', \n",
    "                13: 'P', 14: 'Q', 15: 'R', 16: 'S', 17: 'T', 18: 'V', 19: 'W', 20: 'Y'}\n",
    "    best_sequence = \"\".join([ indexToLetter[acid_index] for acid_index in generated_sequences[np.argmax(logits)]]) \n",
    "    worst_sequence = \"\".join([ indexToLetter[acid_index] for acid_index in generated_sequences[np.argmin(logits)]]) \n",
    "    print(\"{} | Discriminator value {}\".format(best_sequence, logits[np.argmax(logits)]))\n",
    "    print(\"{} | Discriminator value {}\".format(worst_sequence, logits[np.argmin(logits)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def save_model(saver, sess):\n",
    "    # Epoch ended\n",
    "    if steps % (STEPS_PER_EPOCH*100) == 0:\n",
    "        display_sequence()\n",
    "        print(\"Epoch {}. Fineshed at {}\".format((steps/STEPS_PER_EPOCH), str(datetime.datetime.now()).split('.')[0]))\n",
    "        save_weights(saver, sess, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(max_to_keep=3)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAUTION: Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with batch size: 256, epoch num: 1000000\n",
      "steps:200 \td_loss:-24.5621 \tg_loss:25.3325\n",
      "MFSYFSIIIIYEEFIIFEFFESS0FFEMSSSEEFRFSPFERGEGIFGEFFEEIISSSSSSESEESEFSFIEFEESSESFEFYPFIFFFFSIIYFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.818758010864258\n",
      "MSSFSMSFYEYEIIFEFRFFEERIFSSSGGSEYPEFMFFISFIIEFEISEIIYSEFMSFFSMSSSFSSFISPSSRIFRSFFSFESEISSSFYSFFIIFSFFFFFFFFFFFFFFFFFFFFF | Discriminator value -26.824750900268555\n",
      "Epoch 100.0. Fineshed at 2018-04-29 06:04:36\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:400 \td_loss:-24.5519 \tg_loss:25.6990\n",
      "MFFFSIEEYFIIIEESIEEGFFMFSSRSRFYESESEEFFFFSPFERGEFFFIEMREFCEESYESSEEEFSPGRFFSIIFFWSFFREIIEEFEERFEFFEEIFFFFFFFFFFFFFFFFFFF | Discriminator value -26.015729904174805\n",
      "MSSFRRFFSISISFEIIEYRFFIFFEFEFMESEGESRSSESFSFRISFSEESMEFFEFISSFIIGPEEFEFESISFESEEYFFSERFFSY0FFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -26.906044006347656\n",
      "Epoch 200.0. Fineshed at 2018-04-29 06:05:25\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:600 \td_loss:-24.4922 \tg_loss:26.4159\n",
      "MEFSSRISISIRFIFFFSISIIESEFRYSSGFSFSISISEEFFRFWRFERFEFFFEIFRFIFEFMFRFCEIEPEFFMFEFEESREESEEFSFFEFEECFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -23.43277931213379\n",
      "MSSFRRF0SFRIEIFIEGIEFMFFMYSIFEESSFEYFFWFCFSSSESFEIIGEFPYESFFSESESFSSFFRPSEEEREFEFEFFEESFFSEESFFFF0FFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.82621192932129\n",
      "Epoch 300.0. Fineshed at 2018-04-29 06:06:15\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:800 \td_loss:-24.4473 \tg_loss:25.1103\n",
      "MSIFFSFERIESYYFRFRFPFCFFEFRMFSIREFMFSSSRFFFFFSEFFSFEFMIIEFIFIIFRMSFWSRMEPPFFRFSEFEFEERREFSRFERFIIEFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.784076690673828\n",
      "MSEESERRIEFEFFIEGEFFRFSFEFSFEEFIIREFFRFYEFIEFEYSIFGEFEFGEEEEFSEEMEEYY0CSEESESFRIPFEFFYEYRYSFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.713836669921875\n",
      "Epoch 400.0. Fineshed at 2018-04-29 06:07:04\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:1000 \td_loss:-24.4834 \tg_loss:25.4496\n",
      "MSRSEFSFSFFYEFFERGIFICFRMYEEFEFRSIIFIESGSFESSIEFEEIIIFEEISFFSMSSSSSSIESPSSRIFRSFFSFESEISSSEYSFFSIRFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -23.06614112854004\n",
      "MSSFEMSFFSIEIIGEFIFFEIEEIIMEEIYEYFSFEFFFFEEIEEEFEFFFIFEFFEFEEIISRFSCFESMSSEESSSSIYSSFFRSIFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -23.948986053466797\n",
      "Epoch 500.0. Fineshed at 2018-04-29 06:07:53\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:1200 \td_loss:-24.5070 \tg_loss:23.9159\n",
      "MSRFMSFERIESYYFRIRIRFCEFIFRMFEFREFMFSSSRIWFFFSEFFSFEFMIIISFFIIFRM0FS0RMEPPFFMGEEFSFEEEEEFSRFERFYIRFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -23.18963623046875\n",
      "MMSIFEFFYIEIEGEIIEFFFRMEMEFRFREIEYEFSFCFPFFFEFIFIEMEFEFFFYEESYEEEEREFIFFIGRRYMSESPEFFRYFEGFRFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.267013549804688\n",
      "Epoch 600.0. Fineshed at 2018-04-29 06:08:42\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:1400 \td_loss:-24.4572 \tg_loss:23.9463\n",
      "MSFIEYFIFISIIIIEFRYFSIRIFMFYFIFESFIFFFFYFEIYFIIFFFFIERFIIEFIEIFSPFSFFESEISEESESFISSSFFRSIF0FF0FFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.045833587646484\n",
      "MFEFFFRSSFEIFFEEIIFEYMSSMEESSSSSEEEFYFSFFPFFEFEFCFEESFFIFFFIFCSSEEFPFFFFEFEYERYFFF0FFFIFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.990381240844727\n",
      "Epoch 700.0. Fineshed at 2018-04-29 06:09:32\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:1600 \td_loss:-24.5439 \tg_loss:25.4263\n",
      "MSIFFSFERIESYYFRIRIFFIEFEFREFEFREFEFFS0RESFFFSEFISFEFMYIIRIFIIFRMSFWSRMEPEFFRFSEFEFEEMREESRFERFIIMFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.100292205810547\n",
      "MFEEFRSSEEFYEIFIEFFFRSFISFMFSEFERSISIEFYRFERGIEIFEFCESFFFGREMSESSYRSFEEERERIFRSEFESFSEFSSIIFSFF0FRFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -26.116952896118164\n",
      "Epoch 800.0. Fineshed at 2018-04-29 06:10:21\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:1800 \td_loss:-24.5491 \tg_loss:25.3252\n",
      "MEEPFFSIFIEFFIEGIEFGEFIEEEEICFRSFEEFRFSFSFFEEIEISIIEIFSMFIEF0YRFIIRERSESEFSEFSIEWEFFSPFFREFEISSFFFFFMFFFFFFFFFFFF00FFF0F | Discriminator value -24.836605072021484\n",
      "MSRFEFSFSIRIIEIEFRFFIIEEFSSEESFGYFSFSFFEFIEYEFIEEFSFIFSEFFSFYSSEEESSRIFSFEEESIEEFESFFFFFFSFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.66176986694336\n",
      "Epoch 900.0. Fineshed at 2018-04-29 06:11:10\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:2000 \td_loss:-24.4917 \tg_loss:25.2234\n",
      "MFIRCESFIFSEIFIIFEFRYESEYEFSRSESSIYFSFSPFESFEFIFCEFEEEEFISSISISFSEGMSRISPIFRMFIRSFESIFRIMFESFSISSSSFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.671920776367188\n",
      "MESRSEISSFRIEPIEIEFFSYMFCYFIIRYYIEFFIRFSFFEREFFFFFEIRFFFEFSIREIPEIFSFEFGSFSFIEEFESEFFCEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.489370346069336\n",
      "Epoch 1000.0. Fineshed at 2018-04-29 06:12:00\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:2200 \td_loss:-24.5222 \tg_loss:24.3981\n",
      "MPR0IFSISFRFIIGIFMIIFISREYEEIEFSSIEFIFFFSFSESIEFEFIFEEPEESFFSMSSSSSSFISESSRIFRSFFSFESSISSSEYSFFSIRYFFFFFFFFFFFFFFFFFFFFF | Discriminator value -23.202392578125\n",
      "MSSFCIIFFFYERFIEFEFRYFSIEIFFSSESSEYFRFSFFGSFIFYFEEEEFEIFSSSISCESEFFRFIRPIIPFFSFRFSIYFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.325178146362305\n",
      "Epoch 1100.0. Fineshed at 2018-04-29 06:12:49\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:2400 \td_loss:-24.5194 \tg_loss:23.5133\n",
      "MSEFFSFERIFRMMIRESFIIFFFRESFRSSFEESICSGSGREEEFIFEFFFIEFEF0IESIEEEPRFFRGFFFEFEPFFFFFYSMIRPGERFSS0FSIFFFFFFFFFFFFFFFFFFFFF | Discriminator value -22.844499588012695\n",
      "MSCIYYSFIISEMFIIFFFRFSSM0RFIFYEYEESFRFRRFESFEFS0FIPFERFFFMIEFFEREEESFEPERFFGEEIFSSFFFEFIEEFMERFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -23.689332962036133\n",
      "Epoch 1200.0. Fineshed at 2018-04-29 06:13:38\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:2600 \td_loss:-24.5038 \tg_loss:22.4396\n",
      "MFSEFSMSESFIEFFFRSFFIREFRFSISSESIYFRFSFFGRGEFIFMEFMEFGSMFIEFSYRFIIREGFEEEEFEISME0YPFIFFFFSIYYFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -21.46122932434082\n",
      "MSSESCMRCFISFEFIYFSFRFSFSFYFEISSEYFRFSFFEFIEFCFSFEESRSFIIFMFISIFSPESEES0SEFESFEFEESEFRFRFFSFFSFRFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -22.244529724121094\n",
      "Epoch 1300.0. Fineshed at 2018-04-29 06:14:27\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:2800 \td_loss:-24.5247 \tg_loss:22.1126\n",
      "MSFIEGSGFIFRIEIRISFEEEEIIIREFEFRRFRFSESEYFFSFREFEFIEFEFEFFRSIEMMYIESEEEEEFFRREMFSFIEESSREFSRFFEISRSIFFFFFFFFFFFFFFFFFFFF | Discriminator value -22.050338745117188\n",
      "MWSSCEFSIFESIIEEFFRFESFCFFSSIFSEYFIFFFFESFFIMFEESSFSSRRFYSMISSEEEFFFMFFFFEISFIEFSEFFFFFIFIFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -22.915475845336914\n",
      "Epoch 1400.0. Fineshed at 2018-04-29 06:15:14\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:3000 \td_loss:-24.5064 \tg_loss:22.4800\n",
      "MSIFFSFERIESYYFRIREPFCEFEFRMFEFRYFMFFSSRIFFFFSFFESFEFMYIESFFIIFRMSFSSRMEPEFFRFSEFEFEEREEERRFMRFIIIFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -22.61797332763672\n",
      "MFFPSFMFYIEERFIEFEFRFESFSIFIFSSSEEYFSFEYFFSFEFFFSIFEIFIEESEFYYREEESSESPREESE0ERSSFEPFEFFSISYFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -23.70786476135254\n",
      "Epoch 1500.0. Fineshed at 2018-04-29 06:16:01\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:3200 \td_loss:-24.5545 \tg_loss:24.0130\n",
      "MSETFESSSFFYEFFERFIEICFRMFEESEFRSIIFFFFGSFESSISFEEIFIFPEESFFSMSSF0SSIISPSSRIFRSFFSFESEISSSEFSFFSIRFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.214815139770508\n",
      "MFEPSPRSIIFFFMETYFIFFSESFCEIFFEFMFFESFSFSFFESIEFFYMEEFSFIFEESESFSEEPPFFEFSSISFEEFEIEYIFFEFSFFFRFFIFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.030874252319336\n",
      "Epoch 1600.0. Fineshed at 2018-04-29 06:16:48\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:3400 \td_loss:-24.5037 \tg_loss:24.8741\n",
      "MSRFESFERIEEIYFEFRFFEIEGFFREFSEREFMFSSSRFSFFFSFFESFEFMSIESFEIIFRMSFWSRMEPPFFMFEEFEFEEEREFSRFERFIIMFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.43306541442871\n",
      "MSFFCMYRFEGIFSFIEFRFRFYFFFESREFEFFESIRFSPFIRFEFEFEEEEFFEIFYFMSEMSGESIFEGEESFEFIEFSFFFEFPF0FFMSYFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.32024574279785\n",
      "Epoch 1700.0. Fineshed at 2018-04-29 06:17:35\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:3600 \td_loss:-24.5040 \tg_loss:24.1060\n",
      "MSEFIESSSIFFEIFIRFIEFFFRSYSIFEFSSIEFFGWFCFESSISFEIICIGPEESISSMSSFSSSIISPSSRIFRSFFSFESEIFSSEYSFFSIRSFFFFFFFFFFFFFFFFFFFFF | Discriminator value -23.182592391967773\n",
      "MEFRCSSEIIEEIIFFRFFRFFSIRGFESSESEEEGRFRRFEEEIFYFFEEEFMCIIYIFYMFREGRFFEEEEEIFEFFEISFEFFRISEFFC0FFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.152889251708984\n",
      "Epoch 1800.0. Fineshed at 2018-04-29 06:18:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:3800 \td_loss:-24.5060 \tg_loss:24.0900\n",
      "MSIRFYFSISESFIEFFFRFSSSEIFIESGYSEFIRF0FFERFEFCFSGESEFFIFSIFYCREEPEMFMFSEFFYSIIEFEEEFSRFSFPYFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -23.87957191467285\n",
      "MSEEIIYSRYFFSFRFIFFEFRSSEEEEFSESEYEFSFFFFFFFEFMFYEESEEFSISEESSYSESEEFEGEEEEIEESIFEEISFFRFFSSFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.687694549560547\n",
      "Epoch 1900.0. Fineshed at 2018-04-29 06:19:09\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:4000 \td_loss:-24.5164 \tg_loss:24.8600\n",
      "MPSESYSFIFEFEEEIFEFEFRSFERCRFSESESSEFFFFMFFIRFSFFFIEPRFFCISSSISSIGFSEEIRFFSFFFFSSISEEIIEEFSERFF0FFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.961938858032227\n",
      "MSSESMSFSISYIIGYFRFFFCEEFRESIISIEFFFFPSFYFYEFFSGEEFFSCSFFEFISSEEMFSSFESFSSEIMSGSFEFESFEFSSFFSFFYIISFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.696165084838867\n",
      "Epoch 2000.0. Fineshed at 2018-04-29 06:19:56\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:4200 \td_loss:-24.4981 \tg_loss:25.5735\n",
      "M0EIEYIFFIRGIEIEFRYFEERIFMFMFIFEEFRFEFFERYEFYIFIFFGIFEFSMSSRREPREFRGEFFFSCERSSSESEEFFYIFEISFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -24.609580993652344\n",
      "MSSIIEEFIIEERPIEFEFRYSSIMEFEFYESEFYESFFSFESGIIFFEFFESFSMFFEEEEFFRIPSSSYSIICMFSESEIFESFFIREFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.36602210998535\n",
      "Epoch 2100.0. Fineshed at 2018-04-29 06:20:43\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:4400 \td_loss:-24.5097 \tg_loss:25.2350\n",
      "MPYESSRYGFSIEFIIIEFRSSEESIFRESSSEEFGSFFFFFRFEFSSEIEESFIFYEGMFSIFFMSSRSSSFISPSSRIFRSSFSFESEISSSFFSEFSERYFFFFFFFFFFFFFFFFF | Discriminator value -25.158802032470703\n",
      "MIESFFMMSPSFRFEISFSFIEFFFRSFEIFIFYSFFYSESFSFEFFESFSFSISFIFYYEFEFEFFSFISIFESFSFFFSEFCRFSSIFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.961637496948242\n",
      "Epoch 2200.0. Fineshed at 2018-04-29 06:21:30\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:4600 \td_loss:-24.5436 \tg_loss:25.6465\n",
      "MSSEEESIFEFSISIRIIIGIFRFWSRSRFSESISSEFFFFCEFGRFIFFFIESREFCERSSESSEEEFSPIRFFSFIFFWSFFREIIEIFIERFEEERFSECFMEFREFFSFMIRFFFF | Discriminator value -24.378931045532227\n",
      "MSEEEFFRFESRIEEEFRSMSSEFFISYEFEEYFSFMFFSSIFIYFEEESFSFFSFFSYIESMSSFFFYSFYEMISFFSSEEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.69757652282715\n",
      "Epoch 2300.0. Fineshed at 2018-04-29 06:22:17\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:4800 \td_loss:-24.5270 \tg_loss:25.4268\n",
      "MSERYICYSFIISIMFIEFIFRSFEECRFYEYESSEFFFFMFFFRFSFFFIEPRFFCISSSISSIGFSSEGRFFSFFFFSSISEEIIEEFSERFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -25.457048416137695\n",
      "MIISRFIFSESFIEFIFRFFESYIFSSSGISEYIMFMFFISFFISFIESFFFSFFSEFWSSIESEFFSIIFGSREFMFFFFFFFFFEPFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -26.519119262695312\n",
      "Epoch 2400.0. Fineshed at 2018-04-29 06:23:04\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:5000 \td_loss:-24.5090 \tg_loss:25.9830\n",
      "MSFEPEFRSEFFFMERFIIFGFRFFERSRFSESGSSEFFFFSPFIRIIFFFIESREFCERSSESSEIEFSRFRFFSFFFFSSFFREIIEEFEERISEFFFMFSSFFFFFFFFFFFFFFFF | Discriminator value -25.7574405670166\n",
      "MMFSFSISIEFIEFFFRFFGIREFR0SEMSEFSFFESFESFSWSFFERFEFFFEEEEFRIEIFSSESRMSSEPSYFEFEIIEEFFFPFREYFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -26.743547439575195\n",
      "Epoch 2500.0. Fineshed at 2018-04-29 06:23:51\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:5200 \td_loss:-24.5374 \tg_loss:26.6839\n",
      "MRFEFMESIEFIFSGYREFFEFRFSFSISSESFEFSEFSEFIFFYFFESFIFM0IEFIEFFFRMIIRERSESEFSEFSIEFEFPSIFFFSFEISSFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -26.462369918823242\n",
      "MFSMFRFRCYISERFIEIYFRSSERESFSEYIISEIFRFSFFFSEEIFFEEEEFYFEFSYESCESEEREFIEPEEPFEFEEESFEPEFYFEFRFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -27.24962615966797\n",
      "Epoch 2600.0. Fineshed at 2018-04-29 06:24:38\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:5400 \td_loss:-24.5530 \tg_loss:26.9968\n",
      "MSFFSSESSFEISESFIEFIFRYSERSEFFEYFYSIYFFFMMFIRFCIFFFEFEFFCIISSFSSEERFEPFFIFRESFIEIWEEPRFFEEFFERFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -26.66238021850586\n",
      "MSSIIRFIEIIEEIFIIEFYSFFFFIEEERSSFEEFFEFIEFRFCFFSEFEFFSFEEFFFCSRSESRFRREFFESFEEEISEEYFFFRIFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -27.38620376586914\n",
      "Epoch 2700.0. Fineshed at 2018-04-29 06:25:25\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:5600 \td_loss:-24.5509 \tg_loss:27.9152\n",
      "MSFFCIIFSIYERFIEFEFRFSSEREFCISESSEYFCF0FFESFEIMFIFEEEFSFSFIFFISSEPSPECRIEEGYIYSEFEGEFRSSFFIFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -27.83629035949707\n",
      "MEFSSEISISIRIEFEEERFSFSEEFSFSISEGFERFRFFGFFEFGFSIYFEFFFFPFSSIEIFESYECFESSEIRYFIFSEFRFFFIREFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -28.796127319335938\n",
      "Epoch 2800.0. Fineshed at 2018-04-29 06:26:13\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:5800 \td_loss:-24.5672 \tg_loss:28.4742\n",
      "MRMIE0IEFEREEEIEFRYFSIRIFMFYFIFEEIIFFFFYFEIYFIFFFFFIERFIIIIIEIFSPFSFISSMISEESEYFESYSFFRSIFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -27.706466674804688\n",
      "MFPSIIFRIEFEFFISFEEFEYRMSEFFEFERSEISGREYFMSRFEFYFIIEEIFFSSIFSFEREGSFFFPISFSEFEYFEEEEEFFEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -28.840242385864258\n",
      "Epoch 2900.0. Fineshed at 2018-04-29 06:27:00\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:6000 \td_loss:-24.5206 \tg_loss:29.2605\n",
      "MEEFFSFESRISYRFFFEIRIIFIFFRYSSFFEFSISFSSFFFRFSPFIRFEFIFEEFRFIIEFMISSEEIEPFFEIEEFISSEESFEFEFFFESFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -30.771568298339844\n",
      "MFIFRFMSRIYERFIEFEFRFESFIEFSESESSEYFRFSFFISFEFYFIIEEEEFFEYISSFMEEPRSFSFSEPRRSSSEEFFFFEFFSIFEFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -31.908077239990234\n",
      "Epoch 3000.0. Fineshed at 2018-04-29 06:27:47\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:6200 \td_loss:-24.5158 \tg_loss:29.3180\n",
      "MISSFFSRFSISFRISFIIFIFRSFSRRRFSMSEYSIFFFFCEFIRFEFFFIESREFCERSSISSEIEFSPFRFFSFIFFWSFFRIIIEIFMERFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -29.644451141357422\n",
      "MIEFSFEEFFFFERIEFEFEFERYFEGEEIEEEFEGEFYIFSEFEEGFFFFEERMFIYEEYEFS0EEEPSRERPEEFIEFEEFESEFEFMFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -30.624248504638672\n",
      "Epoch 3100.0. Fineshed at 2018-04-29 06:28:34\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:6400 \td_loss:-24.5256 \tg_loss:30.5573\n",
      "MMYFRFESFIRESFIEFFFRFSERFIFSRFIFFGSFRF0PFERIEFFFSFEEIFFERSMESIRIGEERFFRFFRSSEEPYPFEEFESFSIRYFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -30.52756118774414\n",
      "MESFSSSFFFEI0SSSFEFIEFRYFIEERFSMSERFEFYSFSRFEEFFRFFEIEEIFIIEESFSREEEFSEERESEEIIEESFIERMFRSFIISFSFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -31.631065368652344\n",
      "Epoch 3200.0. Fineshed at 2018-04-29 06:29:21\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:6600 \td_loss:-24.5185 \tg_loss:30.8399\n",
      "MYCYEIIISESFIEFYFRFFCSYIFSSSSSEEYFEFSFFEIFFIEFIEFESSIRSFSSSISSEFGFSEIISIFESESSRIFESFFSFESEMS0FFF0FFFSFFFFFFFFFFFFFFFFFFF | Discriminator value -28.99503517150879\n",
      "MSFFEGFSSIEFMIEIFRFFEEEEFEEYGIFESFEFEFFFSEEFSFEIIFFEIEFFGEESESFYIEEEFSEEEIEPSSREFRSSFSFSSEYSS0FFEEFFSFFFFFFFFFFFFFFFFFFF | Discriminator value -30.041114807128906\n",
      "Epoch 3300.0. Fineshed at 2018-04-29 06:30:08\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:6800 \td_loss:-24.5085 \tg_loss:30.5701\n",
      "MSFGFGRSEFSFEEFPIEFIFRFIEIFEFESYIEESISFSFFERFEFFFCESEFSSEEFYEFSISIPSFFRPFGCEREFSESEFYISFFIFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -29.858367919921875\n",
      "MEERFFESRYIIIIFEYFRSESSESFSESEFSESIRFIMFESIEFFFSFESEFFFFSIMMYMSFSRFFRFFEFSSFISEFFESFSFEFFFEFSEFSEFSFFFFFFFFFFFFFFFFFFFFF | Discriminator value -30.621408462524414\n",
      "Epoch 3400.0. Fineshed at 2018-04-29 06:30:55\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:7000 \td_loss:-24.5227 \tg_loss:29.7779\n",
      "MPFSEEISISIRFEFFFSIRFIFIFFRYSSIFSFSI0FFEFSFSSEGFFEYFFCEEEFSIMISSSRSFIEPEGFFFSIIEYSEEFRFFEIFFERFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -27.678016662597656\n",
      "MSEESFFESEEFIEIEYEFFEESEFFIERIEGEGEFSFCFFGSEEGFFIIEEIIFYSSFEESSSEGPREFMEFRSSEEEEEFFFYIIFEFEFSFFIYFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -28.876596450805664\n",
      "Epoch 3500.0. Fineshed at 2018-04-29 06:31:42\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:7200 \td_loss:-24.5409 \tg_loss:29.1005\n",
      "MEEESFERIYYREFIEPEFRYFSMREFRRFYGFISFSFSPFFRISFFIEFFFFFSMFIEFSYRFIIREPSESEFSEFSIEWEFESEFFREFEISSFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -28.31536102294922\n",
      "MSEFEESSSFFYEFFERGIEIMFRMIEFFEIRSIEFFESFRESFSESFEEEFEFPIFSGEFIEESSESFESPSSEEEYSFFFFEEEEFFFMEFFFFICSFFFFFFFFFFFFFFFFFFFFF | Discriminator value -29.20589828491211\n",
      "Epoch 3600.0. Fineshed at 2018-04-29 06:32:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:7400 \td_loss:-24.5395 \tg_loss:28.8634\n",
      "MSRYEMSFFIRIEIFIRPIFGIFRMFSEFEFRSIEFIISGSFSSSFEFSEIFIEEEMSFFSMSSFSSSIISPSSRIFRSFFSFESEISSSEFSFFSIRFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -28.85667610168457\n",
      "MSFEGEESSSFEIEFEFFEFEFRFMSRFSFCESRSSFRFFFFEEFEFFFEGEEMSSESYYESISSEEEFFEIERSREFIEEEEFFFSFFRY0FFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -29.639999389648438\n",
      "Epoch 3700.0. Fineshed at 2018-04-29 06:33:16\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:7600 \td_loss:-24.5344 \tg_loss:29.4405\n",
      "MISFEYFFSISFIEFFFRFSERIRFSE0FSEEYFEFMFFFSFFIMFEGEFFFEFIFIEEEFSFFFMSSSSSSIESPSSRIFRSYFSFESEISS0FF0FFSSRFFFFFFFFFFFFFFFFFF | Discriminator value -29.45011329650879\n",
      "MYSYSFFISEIFIFFEFRFSESFYFFFSEISEYFRFIFFESFEISFMFFEESSFEFYSFYRSGRMFRSFFEFSIYEEFEISEEFFFSYFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -30.175785064697266\n",
      "Epoch 3800.0. Fineshed at 2018-04-29 06:34:03\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:7800 \td_loss:-24.5054 \tg_loss:29.6348\n",
      "MSFPFCR0SFSIMIFGCIFEFMFRSYMIFEERSFIIFFSFSESSSISFEEIEIEFIFSEFYIFRM0FSFRMEPPFFMISEFEFEEREFFSEESFFIISSFSFF0FPMMIFIFSSSMMFSF | Discriminator value -30.57710838317871\n",
      "MESSCESFIISEMGEFFIFREFEMEEFRRFERSFPSEFFSFESFISFSYIFSEIEFFYSSSCESFFFSFFEMSIFSRF0RFFMSFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -31.783254623413086\n",
      "Epoch 3900.0. Fineshed at 2018-04-29 06:34:50\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:8000 \td_loss:-24.5193 \tg_loss:30.2172\n",
      "MEESEGFSIFFFFFFIGFEFRSFERFSF0EIIISSEFFSFSFFESFISIFRESEFFCEESSFSSEFFSSEERFFSFEFFESISRGIFEEFSERFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -28.91526985168457\n",
      "MFEERRISEIEGEIIEFRYMESRSFFSSEYSGYIRFSMFEEFEIFFIEEFSESESFYESYSSESEPFFSEFSIIEIEEMECFEFFFISYYFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -29.75067710876465\n",
      "Epoch 4000.0. Fineshed at 2018-04-29 06:35:37\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n",
      "steps:8200 \td_loss:-24.5395 \tg_loss:29.9219\n",
      "MFMIFEFMIRSEFFGIFESFIEISFRFFEIRIFFIYISFESIRFRFFESFEFFFF0EFSFSYEEE0FRFEFFEFIWIEEFE0SPFYEFSYRFFFFFFFFFFFFFFFFFFFFFFFFFFFFF | Discriminator value -29.757328033447266\n",
      "MSRFSIYFEERFIFIYFRFFIIESFSSRESFGYFEFFFFESFEIIFEEEFSSFYYFFSSFSFSEERFFSIEFIEESSYEEEFIFSFFRFFEFFSFSSF0FFFFFFFFFFFFFFFFFFFFF | Discriminator value -30.77481460571289\n",
      "Epoch 4100.0. Fineshed at 2018-04-29 06:36:24\n",
      "Model saved in path: ../weights/wgan_sequence/version_6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-81771c20350d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0md_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgen_iterations\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgen_iterations\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainer_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mdLosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print (\"Start training with batch size: {}, epoch num: {}\".format(BATCH_SIZE, NUM_EPOCH))\n",
    "sess.run(iterator.initializer, feed_dict={real_sequences: train_data})\n",
    "steps, gen_iterations = 0, 0\n",
    "dLosses, gLosses = [], [] \n",
    "while True:\n",
    "    try:\n",
    "        d_iters = (100 if gen_iterations < 25 or gen_iterations % 500 == 0 else 5)\n",
    "        for k in range(d_iters): # Discriminator\n",
    "            _, dLoss = sess.run([trainer_d, d_loss], feed_dict={is_training: True})\n",
    "            steps = steps + 1\n",
    "            dLosses.append(dLoss)\n",
    "            dLosses, gLosses = print_summary(steps, dLosses, gLosses)\n",
    "            save_model(saver, sess)\n",
    "\n",
    "        # Generator\n",
    "        _, gLoss = sess.run([trainer_g, g_loss], feed_dict={is_training: True})\n",
    "        gLosses.append(gLoss)\n",
    "        steps = steps + 1\n",
    "        gen_iterations = gen_iterations + 1\n",
    "        dLosses, gLosses = print_summary(steps, dLosses, gLosses)\n",
    "        save_model(saver, sess)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print (\"Training is finished\")\n",
    "        break;            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_embedding_lookup(acid_embeddings, embedded_sequence):\n",
    "    acid_embeddings_expanded = tf.tile(tf.expand_dims(acid_embeddings, axis = 0), [BATCH_SIZE, 1,1])\n",
    "    emb_distances = tf.matmul(\n",
    "        tf.nn.l2_normalize(acid_embeddings_expanded, axis=1),\n",
    "        tf.nn.l2_normalize(embedded_sequence, axis=1),\n",
    "        transpose_b=True)\n",
    "    return tf.argmax(emb_distances, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_real = discriminator(real_reshaped, is_training, reuse=True)\n",
    "val_fake = discriminator(embedded_random_sequences, is_training, reuse=True)\n",
    "val_loss = tf.reduce_mean(val_real-val_fake)\n",
    "real_predictions = tf.rint(val_real)\n",
    "fake_predictions = tf.rint(val_fake)\n",
    "correct_real_predictions = tf.equal(real_predictions, tf.zeros([BATCH_SIZE], dtype=tf.float32))\n",
    "correct_fake_predictions = tf.equal(fake_predictions, tf.ones([BATCH_SIZE], dtype=tf.float32))\n",
    "casted_real = tf.cast(correct_real_predictions, tf.float32)\n",
    "casted_fake = tf.cast(correct_fake_predictions, tf.float32)\n",
    "accuracy = (tf.reduce_mean(casted_real) + tf.reduce_mean(casted_fake))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate discriminator by giving from validate data set and randomly generated\n",
    "print ('validating discriminator...')\n",
    "sess.run(iterator.initializer, \n",
    "         feed_dict={real_sequences: val_data, random_sequences: get_random_sequence(val_data.shape[0])})\n",
    "losses = []\n",
    "accuracies = []\n",
    "while True:\n",
    "    try:\n",
    "        v_loss, v_accuracy = sess.run([val_loss, accuracy], feed_dict={is_training: False})\n",
    "        losses.append(v_loss)\n",
    "        accuracies.append(v_accuracy)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print ('Validation g_loss:{:.4f} ,accuracy :{:.4f}'.format(mean(losses), mean(accuracies)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_weights(saver, sess, path):\n",
    "    saver.restore(sess, path)\n",
    "    print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../weights/wgan_sequence/version_6\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "restore_weights(saver, sess, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 48)\n"
     ]
    }
   ],
   "source": [
    "sequences = reverse_embedding_lookup(acid_embeddings, tf.squeeze(fake))\n",
    "print (sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequences...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15,  7, 17, ..., 15, 15, 15],\n",
       "       [15, 15, 15, ...,  7, 17, 15],\n",
       "       [15, 15, 18, ..., 15, 17, 15],\n",
       "       ...,\n",
       "       [15, 15, 15, ..., 17, 11, 15],\n",
       "       [17, 17, 15, ...,  5, 17, 11],\n",
       "       [17, 17, 15, ..., 17,  6, 15]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Generating sequences...')\n",
    "generated_sequences = sess.run([sequences], feed_dict={is_training: False})\n",
    "generated_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexToLetter= {0: '0', 1: 'A', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L', 11: 'M', 12: 'N', \n",
    "                13: 'P', 14: 'Q', 15: 'R', 16: 'S', 17: 'T', 18: 'V', 19: 'W', 20: 'Y'}\n",
    "print(\"\".join([ indexToLetter[acid_index] for acid_index in s ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RHTRRRVTTTTMTRRRRRTRTHTTRRRRRRRTHRMTTMMRTTRTTRRR\n",
      "\n",
      "RHTRRRVTTTTMTRRRRRTRTHTTRRRRRRRTHRMTTMMRTTRTTRRR\n",
      "---------------------\n",
      "RRRMRRHRRRTRTTVRWTHTRHRRCRRRRRHTTHRRRRTTTRRVRHTR\n",
      "\n",
      "RRRMRRHRRRTRTTVRWTHTRHRRCRRRRRHTTHRRRRTTTRRVRHTR\n",
      "---------------------\n",
      "RRVRRRTTHRRHRTYRTRTMTRRMRVRRFRTMRRRRHRTRTTTTRRTR\n",
      "\n",
      "RRVRRRTTHRRHRTYRTRTMTRRMRVRRFRTMRRRRHRTRTTTTRRTR\n",
      "---------------------\n",
      "RRMRRRVTRRRRRRFVRTRMTRRTTTTHMRRTMTVTRRRTRRRRRTRR\n",
      "\n",
      "RRMRRRVTRRRRRRFVRTRMTRRTTTTHMRRTMTVTRRRTRRRRRTRR\n",
      "---------------------\n",
      "RRTMRFRTTTYTTTMTGRRTTTTRTMTTRRRRRRRRVRRRTRVTTRTT\n",
      "\n",
      "RRTMRFRTTTYTTTMTGRRTTTTRTMTTRRRRRRRRVRRRTRVTTRTT\n",
      "---------------------\n",
      "MRRRRTRRTRVMVVRMTRTRRRVRRRRRTFHRRRRRRRTRVTRRRRTR\n",
      "\n",
      "MRRRRTRRTRVMVVRMTRTRRRVRRRRRTFHRRRRRRRTRVTRRRRTR\n",
      "---------------------\n",
      "TRRRRVRRRRTRTRRRRRRTTHRTRTTRRMRTRRVVITTRRRFRRRRR\n",
      "\n",
      "TRRRRVRRRRTRTRRRRRRTTHRTRTTRRMRTRRVVITTRRRFRRRRR\n",
      "---------------------\n",
      "MTTTRRRFRRRTGRRTRRTFVRTTTTRTRRRVRHTRTRRTRRRTTMRR\n",
      "\n",
      "MTTTRRRFRRRTGRRTRRTFVRTTTTRTRRRVRHTRTRRTRRRTTMRR\n",
      "---------------------\n",
      "RTRRTVTTHRTRTTRTTRTRTRTRRMRTMTFHRTRMRRMRMWHRRMRR\n",
      "\n",
      "RTRRTVTTHRTRTTRTTRTRTRTRRMRTMTFHRTRMRRMRMWHRRMRR\n",
      "---------------------\n",
      "SRRRTMFRRTRTMRRTTRTMTMTRTTRRRTVRTRHTRTTRTTHTTRMR\n",
      "\n",
      "SRRRTMFRRTRTMRRTTRTMTMTRTTRRRTVRTRHTRTTRTTHTTRMR\n",
      "---------------------\n",
      "RRRRRSRRRTTTTRRVTRRRRRTRTMTFTMRMMRTRFTRTTRVVTHRT\n",
      "\n",
      "RRRRRSRRRTTTTRRVTRRRRRTRTMTFTMRMMRTRFTRTTRVVTHRT\n",
      "---------------------\n",
      "MWRRMRTTTTRTTRTTSRRRRRMRRTRRTTMRVRSMRRRTTRRMTMTT\n",
      "\n",
      "MWRRMRTTTTRTTRTTSRRRRRMRRTRRTTMRVRSMRRRTTRRMTMTT\n",
      "---------------------\n",
      "RRTTFFTRTWTRTRVMRRTRRRRRRRRHRRRMVRMRRTHTRRRRRRRT\n",
      "\n",
      "RRTTFFTRTWTRTRVMRRTRRRRRRRRHRRRMVRMRRTHTRRRRRRRT\n",
      "---------------------\n",
      "RTRRRRTTVTRVRTRRRFRTMTTRMTRTRTTHHTRRTTRRFRRVRTRR\n",
      "\n",
      "RTRRRRTTVTRVRTRRRFRTMTTRMTRTRTTHHTRRTTRRFRRVRTRR\n",
      "---------------------\n",
      "RRRRVMRRRTTRTHRRRRHHRTRRVMRVTTRRFRRFRTRTVTTTRRMR\n",
      "\n",
      "RRRRVMRRRTTRTHRRRRHHRTRRVMRVTTRRFRRFRTRTVTTTRRMR\n",
      "---------------------\n",
      "RRRTTTTTRRRTMRRRVTRRVRMRTTRRRMTMRRTTRRRTTTTTRTRT\n",
      "\n",
      "RRRTTTTTRRRTMRRRVTRRVRMRTTRRRMTMRRTTRRRTTTTTRTRT\n",
      "---------------------\n",
      "HRRRRRRMRTRTGRTRRTRRRTTRTTRRTRMFTTRTFMTMTRVRVTRT\n",
      "\n",
      "HRRRRRRMRTRTGRTRRTRRRTTRTTRRTRMFTTRTFMTMTRVRVTRT\n",
      "---------------------\n",
      "RFVRTRTTGRRTTRRWTRTRRRTHTRTHTRMRVMRMRRRFRRRTRTTR\n",
      "\n",
      "RFVRTRTTGRRTTRRWTRTRRRTHTRTHTRMRVMRMRRRFRRRTRTTR\n",
      "---------------------\n",
      "VTTRVRMRRTRRTTRTRMMTRRRRTRRRVRTTRTRRRRRTRRRTRTTV\n",
      "\n",
      "VTTRVRMRRTRRTTRTRMMTRRRRTRRRVRTTRTRRRRRTRRRTRTTV\n",
      "---------------------\n",
      "TRRTHRRTRTTRMRRTRTVRRVTWTSTFTMMRHRRHTTRTVRRRTMRR\n",
      "\n",
      "TRRTHRRTRTTRMRRTRTVRRVTWTSTFTMMRHRRHTTRTVRRRTMRR\n",
      "---------------------\n",
      "RRRTTHTRTRRTRVVTRRTTRRMTTRRTRTRRRRTMFVTTRRRTTRRR\n",
      "\n",
      "RRRTTHTRTRRTRVVTRRTTRRMTTRRTRTRRRRTMFVTTRRRTTRRR\n",
      "---------------------\n",
      "MTTTMRRTRMRRRMTRTRTTTTRRRRRTMTRVFTRRTRRRRRHVRVTR\n",
      "\n",
      "MTTTMRRTRMRRRMTRTRTTTTRRRRRTMTRVFTRRTRRRRRHVRVTR\n",
      "---------------------\n",
      "MRRTRTRTTTRVTRRRRRTRTTRRTRRTTTRTRRRHRRTVRWMRWTRR\n",
      "\n",
      "MRRTRTRTTTRVTRRRRRTRTTRRTRRTTTRTRRRHRRTVRWMRWTRR\n",
      "---------------------\n",
      "TRTTRRTTRRRHTRMTRHMRRTRTMHTRTFTRTRTRRTRVTRRRHRRR\n",
      "\n",
      "TRTTRRTTRRRHTRMTRHMRRTRTMHTRTFTRTRTRRTRVTRRRHRRR\n",
      "---------------------\n",
      "RTVRRTTTRTRRRRMRRRRRVVTRRTRRRRRRTRTTVHVRRRTRRTRR\n",
      "\n",
      "RTVRRTTTRTRRRRMRRRRRVVTRRTRRRRRRTRTTVHVRRRTRRTRR\n",
      "---------------------\n",
      "RVTRRMRMTRTRTRMRTRTTVRRTRTRMRTTRTRMRRFRRRTTTRTTR\n",
      "\n",
      "RVTRRMRMTRTRTRMRTRTTVRRTRTRMRTTRTRMRRFRRRTTTRTTR\n",
      "---------------------\n",
      "VMRTRRRRRTRTTRTRTTMCTRRMVTRRVRFFTRHRRTMTRRRTTTRR\n",
      "\n",
      "VMRTRRRRRTRTTRTRTTMCTRRMVTRRVRFFTRHRRTMTRRRTTTRR\n",
      "---------------------\n",
      "VTRRRRTRRVRTRRRRRRTRRTRMMRTRVRRTRRVHTRRTHTRTRVRT\n",
      "\n",
      "VTRRRRTRRVRTRRRRRRTRRTRMMRTRVRRTRRVHTRRTHTRTRVRT\n",
      "---------------------\n",
      "TRRVRMRRIMRTRRRRRMRTRTRRRTRRRTRRTRRRRTHTRRTRTTRV\n",
      "\n",
      "TRRVRMRRIMRTRRRRRMRTRTRRRTRRRTRRTRRRRTHTRRTRTTRV\n",
      "---------------------\n",
      "TRRVTWRMRRTRRRRTTVRRTRTRRTRMRRRTRRTRTRHRTTRTTRTT\n",
      "\n",
      "TRRVTWRMRRTRRRRTTVRRTRTRRTRMRRRTRRTRTRHRTTRTTRTT\n",
      "---------------------\n",
      "RMRRRTRTWTTRRRRTRTRMTRRRRRRTRRTRTTRTTRTRRTHRRVTR\n",
      "\n",
      "RMRRRTRTWTTRRRRTRTRMTRRRRRRTRRTRTTRTTRTRRTHRRVTR\n",
      "---------------------\n",
      "RVRTRTTTHTVRRTRRTRTRRRRTRTRVTRTRRRRRRRTRRRRTRRTT\n",
      "\n",
      "RVRTRTTTHTVRRTRRTRTRRRRTRTRVTRTRRRRRRRTRRRRTRRTT\n",
      "---------------------\n",
      "TRRRTRTRMTTTRRRTTTRRTTRRRRMRTTTRTVRRRVFTRRRRRVVR\n",
      "\n",
      "TRRRTRTRMTTTRRRTTTRRTTRRRRMRTTTRTVRRRVFTRRRRRVVR\n",
      "---------------------\n",
      "TTHRRMTMVTRTMRRTRTRRTMTWRRTVFRRTTRTTWTMRRTTVRRMT\n",
      "\n",
      "TTHRRMTMVTRTMRRTRTRRTMTWRRTVFRRTTRTTWTMRRTTVRRMT\n",
      "---------------------\n",
      "RRTFTRTTTTTTRTTTTMTTRMRVRRRRMTTRTGMRRTRMTRRRRRRT\n",
      "\n",
      "RRTFTRTTTTTTRTTTTMTTRMRVRRRRMTTRTGMRRTRMTRRRRRRT\n",
      "---------------------\n",
      "MFTHTRRVTRTRRRRRRTRTVFRTMVHRRTRTRRMRGRRRRRRVWMRR\n",
      "\n",
      "MFTHTRRVTRTRRRRRRTRTVFRTMVHRRTRTRRMRGRRRRRRVWMRR\n",
      "---------------------\n",
      "WTTRRTTRRMMTVTRTRRRTRRRRTRTRRRRTFTRRSMTRRTVTTRRT\n",
      "\n",
      "WTTRRTTRRMMTVTRTRRRTRRRRTRTRRRRTFTRRSMTRRTVTTRRT\n",
      "---------------------\n",
      "RTTTFMMVRRMRTVRRTMTVRRRVRTRRVTGRTFTRRTRRRRRRGRRF\n",
      "\n",
      "RTTTFMMVRRMRTVRRTMTVRRRVRTRRVTGRTFTRRTRRRRRRGRRF\n",
      "---------------------\n",
      "TTFVRRRMMRVRRTRTRRRTTRRRVVRRRTRTRRRRTRFMRTTRFTRR\n",
      "\n",
      "TTFVRRRMMRVRRTRTRRRTTRRRVVRRRTRTRRRRTRFMRTTRFTRR\n",
      "---------------------\n",
      "TVTRRRRRRMRRTTRVMRRRHVTVHRMTTRRTRHRMRTRRRRTTRRMV\n",
      "\n",
      "TVTRRRRRRMRRTTRVMRRRHVTVHRMTTRRTRHRMRTRRRRTTRRMV\n",
      "---------------------\n",
      "RTRRGRFRRHHRRRVMTRRRTTRTMMVTFRRWRTRTSTRRRHTVTVTT\n",
      "\n",
      "RTRRGRFRRHHRRRVMTRRRTTRTMMVTFRRWRTRTSTRRRHTVTVTT\n",
      "---------------------\n",
      "TTTRVRRRTTRRTTMTRRRMTTRWRRRRHTTVTRRTRTTRRVTVTRTT\n",
      "\n",
      "TTTRVRRRTTRRTTMTRRRMTTRWRRRRHTTVTRRTRTTRRVTVTRTT\n",
      "---------------------\n",
      "FRRRRFTTRMRRTRTTRRVTFMRRTTVMTTTRRRTTRHTRRRTRRRRM\n",
      "\n",
      "FRRRRFTTRMRRTRTTRRVTFMRRTTVMTTTRRRTTRHTRRRTRRRRM\n",
      "---------------------\n",
      "RTRRVTRRRTRRVMRRRRRRRVMTRTRRRRRTTRMTHMRTRRRRMRRT\n",
      "\n",
      "RTRRVTRRRTRRVMRRRRRRRVMTRTRRRRRTTRMTHMRTRRRRMRRT\n",
      "---------------------\n",
      "RMRRRRRRRRTRRTRTRHTTRRRTTRTRRTTTRRRTVRTMTTTFRRRR\n",
      "\n",
      "RMRRRRRRRRTRRTRTRHTTRRRTTRTRRTTTRRRTVRTMTTTFRRRR\n",
      "---------------------\n",
      "TRRRRRTMTTRWMRRRTRMWRMTRRRRVTRRRTRRTHTRTMRRRRRFR\n",
      "\n",
      "TRRRRRTMTTRWMRRRTRMWRMTRRRRVTRRRTRRTHTRTMRRRRRFR\n",
      "---------------------\n",
      "RRTTRRRTRRMVRTRTTRTRTRTGFTRRTTTWHRRRRFRRTRRMRTVH\n",
      "\n",
      "RRTTRRRTRRMVRTRTTRTRTRTGFTRRTTTWHRRRRFRRTRRMRTVH\n",
      "---------------------\n",
      "TMMRVRFRRRRTRRVRTTRRRTRRTRTRTRRTRTRHTRRRVVVRRRRT\n",
      "\n",
      "TMMRVRFRRRRTRRVRTTRRRTRRTRTRTRRTRTRHTRRRVVVRRRRT\n",
      "---------------------\n",
      "HTTMVRTMRRTRRMRHRRRRTRVRRTTRVTTRRTRCRHRTRTMHTMVT\n",
      "\n",
      "HTTMVRTMRRTRRMRHRRRRTRVRRTTRVTTRRTRCRHRTRTMHTMVT\n",
      "---------------------\n",
      "RTRTTTVTRHRHRWTRTMTTMRVTTRRRRRRRTTRTRRRRRRTTRTRT\n",
      "\n",
      "RTRTTTVTRHRHRWTRTMTTMRVTTRRRRRRRTTRTRRRRRRTTRTRT\n",
      "---------------------\n",
      "RRTRRTTRRRRVTRRRVTTRRRTTTTTTTRTRRRRRRTRRRRRTRRRR\n",
      "\n",
      "RRTRRTTRRRRVTRRRVTTRRRTTTTTTTRTRRRRRRTRRRRRTRRRR\n",
      "---------------------\n",
      "TRHRTTRTFMTRRRMTRTRRMRRRRHTRVTRRMRRRVVFMTVTRRRTV\n",
      "\n",
      "TRHRTTRTFMTRRRMTRTRRMRRRRHTRVTRRMRRRVVFMTVTRRRTV\n",
      "---------------------\n",
      "TVRTMRRMRRTRTRTRRRVRHRTTRRHRTTMFMTRMRRRRTTTMTTTT\n",
      "\n",
      "TVRTMRRMRRTRTRTRRRVRHRTTRRHRTTMFMTRMRRRRTTTMTTTT\n",
      "---------------------\n",
      "RTRFHRTTTRTRTMTTTRRRTTTTRRRVTVRRFTMRTRVRRTVTRTRR\n",
      "\n",
      "RTRFHRTTTRTRTMTTTRRRTTTTRRRVTVRRFTMRTRVRRTVTRTRR\n",
      "---------------------\n",
      "RTRFRVTRTTTRRRTTRRRMRTRRRRRRTRHTTVRVGRTRGRTRTRRR\n",
      "\n",
      "RTRFRVTRTTTRRRTTRRRMRTRRRRRRTRHTTVRVGRTRGRTRTRRR\n",
      "---------------------\n",
      "TRTVRTRTRVRRMTMRRRRRTRRHMTTTTTVTTRRTRVRRRFMRRTRR\n",
      "\n",
      "TRTVRTRTRVRRMTMRRRRRTRRHMTTTTTVTTRRTRVRRRFMRRTRR\n",
      "---------------------\n",
      "RTRTRVRRRRTRTRRRRRRRMFRHRTRRTTTTTMRTRRRFTRRTTVTT\n",
      "\n",
      "RTRTRVRRRRTRTRRRRRRRMFRHRTRRTTTTTMRTRRRFTRRTTVTT\n",
      "---------------------\n",
      "RFVRVRTRTTTRTTRMTRRRTTTVRTTRTTTRRRTTRMTRRRRRTRRR\n",
      "\n",
      "RFVRVRTRTTTRTTRMTRRRTTTVRTTRTTTRRRTTRMTRRRRRTRRR\n",
      "---------------------\n",
      "RRRTRRMMTRMTTRMRRTRVRHSRTTRRTRTTRVRRRFTRVTRRVRRR\n",
      "\n",
      "RRRTRRMMTRMTTRMRRTRVRHSRTTRRTRTTRVRRRFTRVTRRVRRR\n",
      "---------------------\n",
      "FVRRRRTTTRRRRRTTVRTTTMMTRRRMRTTRHRRVTTRRRRTTRTRR\n",
      "\n",
      "FVRRRRTTTRRRRRTTVRTTTMMTRRRMRTTRHRRVTTRRRRTTRTRR\n",
      "---------------------\n",
      "RRRTRRTRTRTRHMHRTTTVTRRVIHRRHITHRRRRRCRRRRTRVVRT\n",
      "\n",
      "RRRTRRTRTRTRHMHRTTTVTRRVIHRRHITHRRRRRCRRRRTRVVRT\n",
      "---------------------\n",
      "RRRRRHTRRTRTTMTRRRTTRVRTTTTTHRRRTRRRTRRRTWTVRTMR\n",
      "\n",
      "RRRRRHTRRTRTTMTRRRTTRVRTTTTTHRRRTRRRTRRRTWTVRTMR\n",
      "---------------------\n",
      "TTRRTRTTTRRRTRTRRTVRRRRRRRRRTCRTTRRRRTRVRMRRRFTM\n",
      "\n",
      "TTRRTRTTTRRRTRTRRTVRRRRRRRRRTCRTTRRRRTRVRMRRRFTM\n",
      "---------------------\n",
      "TTRRGRTRTRRRRTTRTHWTRRRRRRTTRTTRVRTFRRRTRRTRRTGR\n",
      "\n",
      "TTRRGRTRTRRRRTTRTHWTRRRRRRTTRTTRVRTFRRRTRRTRRTGR\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for s in generated_sequences[0]:\n",
    "    print(\"\".join([ indexToLetter[acid_index] for acid_index in s ]))\n",
    "    print(\"\")\n",
    "    print(\"\".join([ indexToLetter[acid_index] for acid_index in s if acid_index != 0 ]))\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
